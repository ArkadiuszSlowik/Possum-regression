{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> All-purpose </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes(attribute = {}):\n",
    "    \n",
    "    \"\"\" f.e.\n",
    "    attribute = {'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "     'criterion': ['friedman_mse', 'squared_error', 'mse'],\n",
    "     'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    attribute_names = []\n",
    "    attribute_values = []\n",
    "    final_attr_list = []\n",
    "    \n",
    "    for k,v in sorted(attribute.items()):\n",
    "        attribute_names.append(k)\n",
    "        attribute_values.append(v)\n",
    "    \n",
    "    for attr_composition in itertools.product(*attribute_values):\n",
    "        new_dic = {}\n",
    "        for i in range(len(attribute_names)):\n",
    "            new_dic[attribute_names[i]] = attr_composition[i]\n",
    "        final_attr_list.append(new_dic)\n",
    "        \n",
    "    return final_attr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Regression </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_randomized_tuning(X, y, distributions, model, n_iter=1, r_state=None, cv=4):\n",
    "\n",
    "    reg = RandomizedSearchCV(model, distributions, n_iter=n_iter, random_state=r_state)\n",
    "\n",
    "    reg.fit(X, y)\n",
    "\n",
    "    predictions = reg.predict(X)\n",
    "    train_mse = mean_squared_error(predictions, y)\n",
    "    rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "    scores = cross_val_score(reg, X, np.ravel(y),\n",
    "                                  scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "    rmse_cv = np.sqrt(-scores).mean()\n",
    "    \n",
    "    return rmse_training, rmse_cv, reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_linear_models(train_set_ready, train_set_labels, cv=4):\n",
    "    \n",
    "    models = {'LinearRegression': {'attr': [{}]},\n",
    "               'Ridge': {'attr': [{'solver':'svd'}, {'solver':'cholesky'},\n",
    "                                  {'solver':'lsqr'}, {'solver':'sparse_cg'},\n",
    "                                  {'solver':'sag'}, {'solver':'saga'}]},\n",
    "               'Lasso': {'attr': [{'selection': 'cyclic'}, {'selection': 'random'}]},\n",
    "               'ElasticNet': {'attr': [{'selection': 'cyclic'}, {'selection': 'random'}]},\n",
    "               'Lars': {'attr': [{}]},\n",
    "               'LassoLars': {'attr': [{}]},\n",
    "               'OrthogonalMatchingPursuit': {'attr': [{}]},\n",
    "               'BayesianRidge': {'attr': [{}]},\n",
    "               'ARDRegression': {'attr': [{}]},\n",
    "               'LogisticRegression': {'attr': [{'penalty': 'l1', 'solver': 'liblinear'},\n",
    "                                              {'penalty': 'l1', 'solver': 'saga'},\n",
    "                                              {'penalty': 'l2', 'solver': 'newton-cg'},\n",
    "                                              {'penalty': 'l2', 'solver': 'lbfgs'},\n",
    "                                              {'penalty': 'l2', 'solver': 'liblinear'},\n",
    "                                              {'penalty': 'l2', 'solver': 'sag'},\n",
    "                                              {'penalty': 'l2', 'solver': 'saga'},\n",
    "                                              {'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio':0.5},\n",
    "                                              {'penalty': 'none', 'solver': 'newton-cg'},\n",
    "                                              {'penalty': 'none', 'solver': 'lbfgs'},\n",
    "                                              {'penalty': 'none', 'solver': 'sag'},\n",
    "                                              {'penalty': 'none', 'solver': 'saga'}]},\n",
    "               'SGDRegressor': {'attr': [{'penalty': 'l1', 'learning_rate': 'constant'},\n",
    "                                         {'penalty': 'l1', 'learning_rate': 'optimal'},\n",
    "                                         {'penalty': 'l1', 'learning_rate': 'invscaling'},\n",
    "                                         {'penalty': 'l1', 'learning_rate': 'adaptive'},\n",
    "                                         {'penalty': 'l2', 'learning_rate': 'constant'},\n",
    "                                         {'penalty': 'l2', 'learning_rate': 'optimal'},\n",
    "                                         {'penalty': 'l2', 'learning_rate': 'invscaling'},\n",
    "                                         {'penalty': 'l2', 'learning_rate': 'adaptive'},\n",
    "                                         {'penalty': 'elasticnet', 'learning_rate': 'adaptive'},\n",
    "                                         {'penalty': 'elasticnet', 'learning_rate': 'adaptive'},\n",
    "                                         {'penalty': 'elasticnet', 'learning_rate': 'adaptive'},\n",
    "                                         {'penalty': 'elasticnet', 'learning_rate': 'adaptive'}]},\n",
    "               'PassiveAggressiveRegressor': {'attr': [{'loss': 'epsilon_insensitive'},\n",
    "                                                       {'loss': 'squared_epsilon_insensitive'}]},\n",
    "               'HuberRegressor': {'attr': [{}]},\n",
    "               'TweedieRegressor': {'attr': [{'link': 'identity'}, {'link': 'log'}]},\n",
    "               'TheilSenRegressor': {'attr': [{}]},\n",
    "               'RANSACRegressor': {'attr': [{}]}\n",
    "              }\n",
    "\n",
    "    final_models = {}\n",
    "    \n",
    "    train_set_labels = np.ravel(train_set_labels)\n",
    "    for k,v in sorted(models.items()):\n",
    "        print(k,': ')\n",
    "        print(v['attr'])\n",
    "        for i in range(len(v['attr'])):\n",
    "            fun = getattr(linear_model, k)\n",
    "            reg = fun(**v['attr'][i])\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_ready)\n",
    "\n",
    "            train_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "            scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                                          scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-scores).mean()\n",
    "            \n",
    "            model_name = str(k) + str(v['attr'][i])\n",
    "            \n",
    "            final_models[model_name] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF, Sum, ConstantKernel, DotProduct, ExpSineSquared, Matern, PairwiseKernel, RationalQuadratic, RBF, WhiteKernel\n",
    "\n",
    "def regression_kernelridge(train_set_ready, train_set_labels, cv=4):\n",
    "    \n",
    "    kernels = [ConstantKernel(), DotProduct(), ExpSineSquared(), Matern(),\n",
    "              PairwiseKernel(), RationalQuadratic(), RBF(), WhiteKernel(),\n",
    "              'linear']\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    for kernel in kernels:\n",
    "\n",
    "        reg = KernelRidge(kernel=kernel)\n",
    "        reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "        predictions = reg.predict(train_set_new_ready)\n",
    "\n",
    "        reg_mse = mean_squared_error(predictions, train_set_labels)\n",
    "        rmse_training = np.sqrt(reg_mse)\n",
    "\n",
    "        reg_scores = cross_val_score(reg, train_set_new_ready, train_set_labels,\n",
    "                                     scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "        rmse_cv = np.sqrt(-reg_scores).mean()\n",
    "        \n",
    "        final_models['KernelRidge ' + str(kernel)] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_svm(train_set_ready, train_set_labels, cv=4):\n",
    "    \n",
    "    models = {'SVR': {'attr': [{'kernel': 'linear'},\n",
    "                               {'kernel': 'poly'},\n",
    "                               {'kernel': 'rbf'},\n",
    "                               {'kernel': 'sigmoid'},\n",
    "                               {'kernel': 'linear'}]},\n",
    "              'NuSVR': {'attr': [{'kernel': 'linear'},\n",
    "                               {'kernel': 'poly'},\n",
    "                               {'kernel': 'rbf'},\n",
    "                               {'kernel': 'sigmoid'},\n",
    "                               {'kernel': 'linear'}]},\n",
    "              'LinearSVR': {'attr': [{'loss': 'epsilon_insensitive'},\n",
    "                                     {'loss': 'squared_epsilon_insensitive'}]},\n",
    "             }\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    train_set_labels = np.ravel(train_set_labels)\n",
    "    for k,v in sorted(models.items()):\n",
    "        print(k,': ')\n",
    "        print(v['attr'])\n",
    "        for i in range(len(v['attr'])):\n",
    "            fun = getattr(svm, k)\n",
    "            reg = fun(**v['attr'][i])\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_ready)\n",
    "\n",
    "            train_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "            scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                                          scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-scores).mean()\n",
    "            \n",
    "            model_name = str(k) + str(v['attr'][i])\n",
    "            \n",
    "            final_models[model_name] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gaussianprocess(train_set_ready, train_set_labels, cv=4):\n",
    "\n",
    "    kernels = [ConstantKernel(), DotProduct(), ExpSineSquared(), Matern(),\n",
    "              PairwiseKernel(), RationalQuadratic(), RBF(), WhiteKernel()]\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        try:\n",
    "            reg = GaussianProcessRegressor(kernel=kernel)\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_new_ready)\n",
    "\n",
    "            reg_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(reg_mse)\n",
    "\n",
    "            reg_scores = cross_val_score(reg, train_set_new_ready, train_set_labels,\n",
    "                                         scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-reg_scores).mean()\n",
    "\n",
    "            final_models['GaussianProcessRegressor ' + str(kernel)] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        except Exception as e: print(e)\n",
    "            \n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_crossdecomposition(train_set_ready, train_set_labels, cv=4):\n",
    "    \n",
    "    models = {'PLSRegression': {'attr': [{}]},\n",
    "              'PLSCanonical': {'attr': [{'algorithm': 'nipals'},\n",
    "                                        {'algorithm': 'svd'}]},\n",
    "              'CCA': {'attr': [{}]}\n",
    "             }\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    train_set_labels = np.ravel(train_set_labels)\n",
    "    for k,v in sorted(models.items()):\n",
    "        print(k,': ')\n",
    "        print(v['attr'])\n",
    "        for i in range(len(v['attr'])):\n",
    "            fun = getattr(cross_decomposition, k)\n",
    "            reg = fun(**v['attr'][i])\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_ready)\n",
    "\n",
    "            train_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "            scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                                          scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-scores).mean()\n",
    "            \n",
    "            model_name = str(k) + str(v['attr'][i])\n",
    "            \n",
    "            final_models[model_name] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_decisiontree(train_set_ready, train_set_labels, cv=4):\n",
    "    \n",
    "    criterion = ['mse', 'friedman_mse', 'mae', 'poisson']\n",
    "    splitter = ['best','random']\n",
    "    max_features = [None, 'auto', 'sqrt', 'log2']\n",
    "    \n",
    "    attributes = []\n",
    "    \n",
    "    for i in range(len(criterion)):\n",
    "        for j in range(len(splitter)):\n",
    "            for k in range(len(max_features)):\n",
    "                new_dic = {'criterion': criterion[i], 'splitter': splitter[j],\n",
    "                            'max_features': max_features[k]}\n",
    "                \n",
    "                attributes.append(new_dic)      \n",
    "                \n",
    "    final_models = {}\n",
    "    \n",
    "    for attr in attributes:\n",
    "\n",
    "        reg = tree.DecisionTreeRegressor(**attr)\n",
    "        reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "        predictions = reg.predict(train_set_new_ready)\n",
    "\n",
    "        reg_mse = mean_squared_error(predictions, train_set_labels)\n",
    "        rmse_training = np.sqrt(reg_mse)\n",
    "\n",
    "        reg_scores = cross_val_score(reg, train_set_new_ready, train_set_labels,\n",
    "                                     scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "        rmse_cv = np.sqrt(-reg_scores).mean()\n",
    "        \n",
    "        final_models['DecisionTreeRegressor ' + str(attr)] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_ensemble(train_set_ready, train_set_labels, cv=4):\n",
    "    \n",
    "    estimators = [('ridge', RidgeCV()),\n",
    "          ('lasso', LassoCV(random_state=42)),\n",
    "          ('knr', KNeighborsRegressor(n_neighbors=20,\n",
    "                                      metric='euclidean'))]\n",
    "    \n",
    "    gbr_attributes = {'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "     'criterion': ['friedman_mse', 'mse'],\n",
    "     'max_features': [None, 'auto', 'sqrt', 'log2']}\n",
    "    \n",
    "    rf_attributes = {'criterion': ['mse', 'mae', 'poisson'],\n",
    "                      'max_features': ['sqrt', 'log2', None, 1]}   \n",
    "    \n",
    "    models = {'AdaBoostRegressor': {'attr': [{'loss': 'linear'},\n",
    "                                             {'loss': 'square'},\n",
    "                                             {'loss': 'exponential'}]},\n",
    "              'BaggingRegressor': {'attr': [{}]},\n",
    "              'ExtraTreesRegressor': {'attr': [{'criterion': 'mse', 'max_features': 'sqrt'},\n",
    "                                               {'criterion': 'mae', 'max_features': 'sqrt'},\n",
    "                                               {'criterion': 'mse', 'max_features': 'log2'},\n",
    "                                               {'criterion': 'mae', 'max_features': 'log2'},\n",
    "                                               {'criterion': 'mse', 'max_features': None},\n",
    "                                               {'criterion': 'mae', 'max_features': None},\n",
    "                                               {'criterion': 'mse', 'max_features': 1},\n",
    "                                               {'criterion': 'mae', 'max_features': 1}]},\n",
    "              'GradientBoostingRegressor': {'attr': attributes(gbr_attributes)},\n",
    "              'IsolationForest': {'attr': [{}]},\n",
    "              'RandomForestRegressor': {'attr': attributes(rf_attributes)},\n",
    "              'VotingRegressor': {'attr': [{'estimators': estimators}]},\n",
    "              'StackingRegressor': {'attr': [{'estimators': estimators}]}\n",
    "              }\n",
    "    \n",
    "    final_models = {}\n",
    "    \n",
    "    train_set_labels = np.ravel(train_set_labels)\n",
    "    for k,v in sorted(models.items()):\n",
    "        print(k,': ')\n",
    "        print(v['attr'])\n",
    "        for i in range(len(v['attr'])):\n",
    "            fun = getattr(ensemble, k)\n",
    "            reg = fun(**v['attr'][i])\n",
    "            reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "            predictions = reg.predict(train_set_ready)\n",
    "\n",
    "            train_mse = mean_squared_error(predictions, train_set_labels)\n",
    "            rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "            scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                                          scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "            rmse_cv = np.sqrt(-scores).mean()\n",
    "            \n",
    "            model_name = str(k) + str(v['attr'][i])\n",
    "            \n",
    "            final_models[model_name] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_neuralnetwork(train_set_ready, train_set_labels, cv=4):\n",
    "\n",
    "    nn_attributes = {'activation': ['identity', 'logistic', 'relu', 'tanh'],\n",
    "     'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "     'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "    attributes_list = attributes(nn_attributes)\n",
    "                \n",
    "    final_models = {}\n",
    "    \n",
    "    for attr in attributes_list:\n",
    "\n",
    "        reg = MLPRegressor(**attr)\n",
    "        reg.fit(train_set_ready, train_set_labels)\n",
    "\n",
    "        predictions = reg.predict(train_set_new_ready)\n",
    "\n",
    "        reg_mse = mean_squared_error(predictions, train_set_labels)\n",
    "        rmse_training = np.sqrt(reg_mse)\n",
    "\n",
    "        reg_scores = cross_val_score(reg, train_set_new_ready, train_set_labels,\n",
    "                                     scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "\n",
    "        rmse_cv = np.sqrt(-reg_scores).mean()\n",
    "        \n",
    "        final_models['MLPRegressor ' + str(attr)] = {'rmse_training': rmse_training, 'rmse_cv': rmse_cv}\n",
    "        \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
