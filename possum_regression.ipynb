{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bd7b0f-a5a6-4799-a15e-7f1b29e9f5a5",
   "metadata": {},
   "source": [
    "<h1> Possum Regression </h1>\n",
    "https://www.kaggle.com/datasets/abrambeyer/openintro-possum?datasetId=1534513&sortBy=voteCount\n",
    "<h2> Introduction </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829a5ef-3bc7-434c-9bb5-66815e9ed0f0",
   "metadata": {},
   "source": [
    "An objective of this work is to consolidate and use part of the knowledge gained from the book \"Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow\".\n",
    "\n",
    "Our goal is to predict the age of given possum. The problem is supervised and multiple regression type. I will use batch learning, because there is no particular need to adjust to changing data rapidly, the dataset is small and there is no continous stream of data coming.\n",
    "\n",
    "Root Mean Square Error (RMSE) as a performance measure is a common cost function in regression tasks, so that will be my choice."
   ]
  },
  {
   "attachments": {
    "bd767c60-3101-48d6-850a-808976ce6450.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "cd3d2ed6-96ca-4037-b15d-6b1f01cbb1e2",
   "metadata": {},
   "source": [
    "![image.png](attachment:bd767c60-3101-48d6-850a-808976ce6450.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b9f60-82c1-46ac-a80c-4300f9c5822c",
   "metadata": {},
   "source": [
    "<h2> Libraries and settings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3466d9-07d7-4f37-9e38-1048a3331555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "from scipy.stats import wasserstein_distance\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "%run ml_functions.ipynb\n",
    "%run custom_transformers.ipynb\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = './sound/mixkit-game-notification-wave-alarm-987.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6e14b-edf7-4bd6-944d-3ba912be07d6",
   "metadata": {},
   "source": [
    "<h2>Load the data <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41cc1f8-5ad7-4210-a5a3-e879125fe7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/possum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f221ea0-597b-4389-b1ef-72aabf6971a2",
   "metadata": {},
   "source": [
    "<h3> Take a quick look </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "531dfa56-9eee-4578-ae2a-386b013d0f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>site</th>\n",
       "      <th>Pop</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>m</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94.1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>54.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>57.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>52.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.5</td>\n",
       "      <td>56.3</td>\n",
       "      <td>85.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case  site  Pop sex  age  hdlngth  skullw  totlngth  taill  footlgth  \\\n",
       "0     1     1  Vic   m  8.0     94.1    60.4      89.0   36.0      74.5   \n",
       "1     2     1  Vic   f  6.0     92.5    57.6      91.5   36.5      72.5   \n",
       "2     3     1  Vic   f  6.0     94.0    60.0      95.5   39.0      75.4   \n",
       "3     4     1  Vic   f  6.0     93.2    57.1      92.0   38.0      76.1   \n",
       "4     5     1  Vic   f  2.0     91.5    56.3      85.5   36.0      71.0   \n",
       "\n",
       "   earconch   eye  chest  belly  \n",
       "0      54.5  15.2   28.0   36.0  \n",
       "1      51.2  16.0   28.5   33.0  \n",
       "2      51.9  15.5   30.0   34.0  \n",
       "3      52.2  15.2   28.0   34.0  \n",
       "4      53.2  15.1   28.5   33.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2d0913-05b1-4745-ba8e-d35fb9db3069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case', 'site', 'Pop', 'sex', 'age', 'hdlngth', 'skullw', 'totlngth',\n",
       "       'taill', 'footlgth', 'earconch', 'eye', 'chest', 'belly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5eb777e-a642-4a9e-83de-7f6f2e99909d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed578d-6bf3-432b-b555-eceb36f202bf",
   "metadata": {},
   "source": [
    "There are 14 attributes including one dependent variable - 'age' and 104 instances. It means dataset is very small by ML standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc70230a-d28e-4da8-a778-e2b297ec6b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   case      104 non-null    int64  \n",
      " 1   site      104 non-null    int64  \n",
      " 2   Pop       104 non-null    object \n",
      " 3   sex       104 non-null    object \n",
      " 4   age       102 non-null    float64\n",
      " 5   hdlngth   104 non-null    float64\n",
      " 6   skullw    104 non-null    float64\n",
      " 7   totlngth  104 non-null    float64\n",
      " 8   taill     104 non-null    float64\n",
      " 9   footlgth  103 non-null    float64\n",
      " 10  earconch  104 non-null    float64\n",
      " 11  eye       104 non-null    float64\n",
      " 12  chest     104 non-null    float64\n",
      " 13  belly     104 non-null    float64\n",
      "dtypes: float64(10), int64(2), object(2)\n",
      "memory usage: 11.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c745e-01af-46c2-86b6-e91cc91730c7",
   "metadata": {},
   "source": [
    "<h3>Some at first glance data cleaning</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65485af-e6c6-4a76-806b-3de2f9802925",
   "metadata": {},
   "source": [
    "In column 'age' 2 entries are missing and in column footlngth 1 entry is missing. There are no missing values in other columns. Because the gaps in the data are insignificant, we are not doing anything about it at the moment.\n",
    "\n",
    "10 of columns are float-type. Columns of object-type are: Pop, sex. Columns of int-type are: case, site. from a dataset description we know in real that Pop, sex and site are categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ed1b9b-e28e-4735-aa1d-27e20555bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pop\"] = df[\"Pop\"].astype('category')\n",
    "df[\"sex\"] = df[\"sex\"].astype('category')\n",
    "df[\"site\"] = df[\"site\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90abe670-d188-4f95-938c-280aecf88247",
   "metadata": {},
   "source": [
    "We can also change 'Pop' name column to 'pop', which fits better to other column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7effd91d-efac-4974-9aea-2c4629caab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Pop\":\"pop\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2ddde-3cc8-495b-85dd-d45417c782b2",
   "metadata": {},
   "source": [
    "The next point is, case column is useless, because rows have indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5851880d-5e6b-425c-b6b2-6506f8d8431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"case\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb845be3-5803-4045-b1aa-d7162c169a30",
   "metadata": {},
   "source": [
    "Now we have 10 float type and 3 category type attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a0daf66-864c-41de-a3c3-4ba959b2d53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>pop</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>m</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94.1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>54.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>57.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>52.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.5</td>\n",
       "      <td>56.3</td>\n",
       "      <td>85.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site  pop sex  age  hdlngth  skullw  totlngth  taill  footlgth  earconch  \\\n",
       "0    1  Vic   m  8.0     94.1    60.4      89.0   36.0      74.5      54.5   \n",
       "1    1  Vic   f  6.0     92.5    57.6      91.5   36.5      72.5      51.2   \n",
       "2    1  Vic   f  6.0     94.0    60.0      95.5   39.0      75.4      51.9   \n",
       "3    1  Vic   f  6.0     93.2    57.1      92.0   38.0      76.1      52.2   \n",
       "4    1  Vic   f  2.0     91.5    56.3      85.5   36.0      71.0      53.2   \n",
       "\n",
       "    eye  chest  belly  \n",
       "0  15.2   28.0   36.0  \n",
       "1  16.0   28.5   33.0  \n",
       "2  15.5   30.0   34.0  \n",
       "3  15.2   28.0   34.0  \n",
       "4  15.1   28.5   33.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9ba672b-3f96-4d02-9fda-801b23b199ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m    61\n",
      "f    43\n",
      "Name: sex, dtype: int64\n",
      "other    58\n",
      "Vic      46\n",
      "Name: pop, dtype: int64\n",
      "1    33\n",
      "7    18\n",
      "2    13\n",
      "5    13\n",
      "6    13\n",
      "3     7\n",
      "4     7\n",
      "Name: site, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"sex\"].value_counts())\n",
    "print(df[\"pop\"].value_counts())\n",
    "print(df[\"site\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40fca1c-d436-4aea-a1a5-d415c08620db",
   "metadata": {},
   "source": [
    "We can see that both 'sex' and 'pop' categorical attributes are of a binary type and both values are nearly equally distributed in them. 'site' attribute is a little bit imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d82cfcf-6bd5-4405-b517-33c9cb6af44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.833333</td>\n",
       "      <td>92.602885</td>\n",
       "      <td>56.883654</td>\n",
       "      <td>87.088462</td>\n",
       "      <td>37.009615</td>\n",
       "      <td>68.459223</td>\n",
       "      <td>48.130769</td>\n",
       "      <td>15.046154</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>32.586538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.909244</td>\n",
       "      <td>3.573349</td>\n",
       "      <td>3.113426</td>\n",
       "      <td>4.310549</td>\n",
       "      <td>1.959518</td>\n",
       "      <td>4.395306</td>\n",
       "      <td>4.109380</td>\n",
       "      <td>1.050374</td>\n",
       "      <td>2.045597</td>\n",
       "      <td>2.761949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>40.300000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.250000</td>\n",
       "      <td>90.675000</td>\n",
       "      <td>54.975000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>35.875000</td>\n",
       "      <td>64.600000</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>92.800000</td>\n",
       "      <td>56.350000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>46.800000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>32.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>94.725000</td>\n",
       "      <td>58.100000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>15.725000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>103.100000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>77.900000</td>\n",
       "      <td>56.200000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age     hdlngth      skullw    totlngth       taill    footlgth  \\\n",
       "count  102.000000  104.000000  104.000000  104.000000  104.000000  103.000000   \n",
       "mean     3.833333   92.602885   56.883654   87.088462   37.009615   68.459223   \n",
       "std      1.909244    3.573349    3.113426    4.310549    1.959518    4.395306   \n",
       "min      1.000000   82.500000   50.000000   75.000000   32.000000   60.300000   \n",
       "25%      2.250000   90.675000   54.975000   84.000000   35.875000   64.600000   \n",
       "50%      3.000000   92.800000   56.350000   88.000000   37.000000   68.000000   \n",
       "75%      5.000000   94.725000   58.100000   90.000000   38.000000   72.500000   \n",
       "max      9.000000  103.100000   68.600000   96.500000   43.000000   77.900000   \n",
       "\n",
       "         earconch         eye       chest       belly  \n",
       "count  104.000000  104.000000  104.000000  104.000000  \n",
       "mean    48.130769   15.046154   27.000000   32.586538  \n",
       "std      4.109380    1.050374    2.045597    2.761949  \n",
       "min     40.300000   12.800000   22.000000   25.000000  \n",
       "25%     44.800000   14.400000   25.500000   31.000000  \n",
       "50%     46.800000   14.900000   27.000000   32.500000  \n",
       "75%     52.000000   15.725000   28.000000   34.125000  \n",
       "max     56.200000   17.800000   32.000000   40.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98302b4-6861-463d-88f0-17fd12f1eedc",
   "metadata": {},
   "source": [
    "Summary of the numerical attributes may be useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d9f68ec-ecff-4d10-a80a-b2963d637aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'age'}>,\n",
       "        <AxesSubplot:title={'center':'hdlngth'}>,\n",
       "        <AxesSubplot:title={'center':'skullw'}>],\n",
       "       [<AxesSubplot:title={'center':'totlngth'}>,\n",
       "        <AxesSubplot:title={'center':'taill'}>,\n",
       "        <AxesSubplot:title={'center':'footlgth'}>],\n",
       "       [<AxesSubplot:title={'center':'earconch'}>,\n",
       "        <AxesSubplot:title={'center':'eye'}>,\n",
       "        <AxesSubplot:title={'center':'chest'}>],\n",
       "       [<AxesSubplot:title={'center':'belly'}>, <AxesSubplot:>,\n",
       "        <AxesSubplot:>]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize=(12,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67253bd-21c0-46cd-94f7-6239faea38a4",
   "metadata": {},
   "source": [
    "Histograms show us that we shouldn't really be concerned about aspects such as: attributes of very different scales or tail heavy data. However, we will take a better look at these histograms later, during preprocessing process. Additionally, we can see that data doesn't contain outliers, what is one of the factors in favor of changing rmse to another performance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca20a40-ef82-44c9-bc57-a8c36f3236e8",
   "metadata": {},
   "source": [
    "<h3> Test set and training set </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d7460-222a-4420-8187-529ca5b9e8d3",
   "metadata": {},
   "source": [
    "Now, let's check if any of attributes is highly correlated with dependent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28e06898-4b0c-49cd-be1b-88916261901b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         1.000000\n",
       "belly       0.354298\n",
       "chest       0.334209\n",
       "hdlngth     0.319022\n",
       "skullw      0.285107\n",
       "totlngth    0.260280\n",
       "eye         0.235553\n",
       "footlgth    0.126190\n",
       "taill       0.118241\n",
       "earconch    0.053405\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix[\"age\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f545721-dd99-4d18-bd2d-db38e8e39f3b",
   "metadata": {},
   "source": [
    "No, there is no high correlation, so we don't need to be aware of sampling bias using standard random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf9b3c31-2aa0-4ece-9fb3-3b6407f34a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b333092-96da-46eb-bd5b-bc1f3c68931b",
   "metadata": {},
   "source": [
    "Now we put test_set aside and start working on train_set only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348658ed-af3d-408d-93d2-0081d888d694",
   "metadata": {},
   "source": [
    "<h2> Discover and visualize </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9705e3c3-6de2-4e67-8fba-fc72f2719b61",
   "metadata": {},
   "source": [
    "<h3> Histograms </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e38846-cc5a-4b8c-b545-7d0455767214",
   "metadata": {},
   "source": [
    "At first, let's deduce something from histograms of the train_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1573037-d7fd-4893-8b9b-186b82398325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'age'}>,\n",
       "        <AxesSubplot:title={'center':'hdlngth'}>,\n",
       "        <AxesSubplot:title={'center':'skullw'}>],\n",
       "       [<AxesSubplot:title={'center':'totlngth'}>,\n",
       "        <AxesSubplot:title={'center':'taill'}>,\n",
       "        <AxesSubplot:title={'center':'footlgth'}>],\n",
       "       [<AxesSubplot:title={'center':'earconch'}>,\n",
       "        <AxesSubplot:title={'center':'eye'}>,\n",
       "        <AxesSubplot:title={'center':'chest'}>],\n",
       "       [<AxesSubplot:title={'center':'belly'}>, <AxesSubplot:>,\n",
       "        <AxesSubplot:>]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set.hist(figsize=(12,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555820cf-b3f0-4d02-bf3a-11c160d3cf91",
   "metadata": {},
   "source": [
    "Wasserstein distance is a metric in the space of probability measures, which can measure distance between histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7626ce98-7fdf-406a-a5d0-cb41948ccdb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  age  and  hdlngth Wasserstein distance is  nan\n",
      "For  age  and  skullw Wasserstein distance is  nan\n",
      "For  age  and  totlngth Wasserstein distance is  nan\n",
      "For  age  and  taill Wasserstein distance is  nan\n",
      "For  age  and  footlgth Wasserstein distance is  nan\n",
      "For  age  and  earconch Wasserstein distance is  nan\n",
      "For  age  and  eye Wasserstein distance is  nan\n",
      "For  age  and  chest Wasserstein distance is  nan\n",
      "For  age  and  belly Wasserstein distance is  nan\n",
      "For  hdlngth  and  skullw Wasserstein distance is  35.628915662650606\n",
      "For  hdlngth  and  totlngth Wasserstein distance is  5.381927710843373\n",
      "For  hdlngth  and  taill Wasserstein distance is  55.46265060240963\n",
      "For  hdlngth  and  footlgth Wasserstein distance is  nan\n",
      "For  hdlngth  and  earconch Wasserstein distance is  44.42168674698795\n",
      "For  hdlngth  and  eye Wasserstein distance is  77.43855421686749\n",
      "For  hdlngth  and  chest Wasserstein distance is  65.55903614457831\n",
      "For  hdlngth  and  belly Wasserstein distance is  60.046987951807225\n",
      "For  skullw  and  totlngth Wasserstein distance is  30.246987951807228\n",
      "For  skullw  and  taill Wasserstein distance is  19.83373493975904\n",
      "For  skullw  and  footlgth Wasserstein distance is  nan\n",
      "For  skullw  and  earconch Wasserstein distance is  8.79277108433735\n",
      "For  skullw  and  eye Wasserstein distance is  41.80963855421686\n",
      "For  skullw  and  chest Wasserstein distance is  29.93012048192771\n",
      "For  skullw  and  belly Wasserstein distance is  24.418072289156626\n",
      "For  totlngth  and  taill Wasserstein distance is  50.08072289156626\n",
      "For  totlngth  and  footlgth Wasserstein distance is  nan\n",
      "For  totlngth  and  earconch Wasserstein distance is  39.039759036144574\n",
      "For  totlngth  and  eye Wasserstein distance is  72.0566265060241\n",
      "For  totlngth  and  chest Wasserstein distance is  60.177108433734944\n",
      "For  totlngth  and  belly Wasserstein distance is  54.665060240963854\n",
      "For  taill  and  footlgth Wasserstein distance is  nan\n",
      "For  taill  and  earconch Wasserstein distance is  11.040963855421685\n",
      "For  taill  and  eye Wasserstein distance is  21.97590361445783\n",
      "For  taill  and  chest Wasserstein distance is  10.096385542168676\n",
      "For  taill  and  belly Wasserstein distance is  4.584337349397591\n",
      "For  footlgth  and  earconch Wasserstein distance is  nan\n",
      "For  footlgth  and  eye Wasserstein distance is  nan\n",
      "For  footlgth  and  chest Wasserstein distance is  nan\n",
      "For  footlgth  and  belly Wasserstein distance is  nan\n",
      "For  earconch  and  eye Wasserstein distance is  33.016867469879514\n",
      "For  earconch  and  chest Wasserstein distance is  21.137349397590363\n",
      "For  earconch  and  belly Wasserstein distance is  15.625301204819277\n",
      "For  eye  and  chest Wasserstein distance is  11.879518072289155\n",
      "For  eye  and  belly Wasserstein distance is  17.391566265060238\n",
      "For  chest  and  belly Wasserstein distance is  5.512048192771085\n"
     ]
    }
   ],
   "source": [
    "columns = train_set.columns\n",
    "\n",
    "for i in range(len(train_set.columns)):\n",
    "    if is_numeric_dtype(train_set[train_set.columns[i]]):\n",
    "        for j in range(i+1,len(train_set.columns)):\n",
    "            if is_numeric_dtype(train_set[train_set.columns[j]]):\n",
    "                print('For ', train_set.columns[i], ' and ', train_set.columns[j], 'Wasserstein distance is ', wasserstein_distance(train_set[train_set.columns[i]], train_set[train_set.columns[j]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1418f9f-10f0-4fc3-a4d7-987efe85e4bb",
   "metadata": {},
   "source": [
    "Pairs of histograms close to each other are: (hdlngth, totlngth), (taill, belly) and (chest, belly). Potentially we can use this information during feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc592b4-5749-4f1f-a10e-df8fc65b9a9b",
   "metadata": {},
   "source": [
    "<h3> Correlations </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc2e57-d97a-4b1c-bada-8c2ea1db952e",
   "metadata": {},
   "source": [
    "Let's check a correlation for numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5729db72-8b8c-44b7-95b6-894a7e969d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         1.000000\n",
       "hdlngth     0.254740\n",
       "skullw      0.192840\n",
       "totlngth    0.244830\n",
       "taill       0.098013\n",
       "footlgth    0.045257\n",
       "earconch    0.037012\n",
       "eye         0.220969\n",
       "chest       0.204392\n",
       "belly       0.283273\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.corr()[\"age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa86796-c4c3-435f-b187-d7666d4d137f",
   "metadata": {},
   "source": [
    "As we can see, correlation levels are very low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b9254-17e3-4563-afaf-657506fe55e7",
   "metadata": {},
   "source": [
    "Now, let's check a correlation for categorical attributes (pop, sex, site). Function that we are going to use requires that data has no nans, so let's just drop them for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11f3c36d-41cc-4b74-9763-8d818610ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new = train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2630de9e-10b7-4215-83e4-1312f4b4434f",
   "metadata": {},
   "source": [
    "Let's add binary columns that respond columns 'pop' and 'sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17119028-ead5-413c-a438-06959349d82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>pop</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "      <th>pop-bin</th>\n",
       "      <th>sex-bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>57.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>52.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.1</td>\n",
       "      <td>54.8</td>\n",
       "      <td>90.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>73.2</td>\n",
       "      <td>53.6</td>\n",
       "      <td>14.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>m</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.3</td>\n",
       "      <td>58.2</td>\n",
       "      <td>89.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site  pop sex  age  hdlngth  skullw  totlngth  taill  footlgth  earconch  \\\n",
       "1    1  Vic   f  6.0     92.5    57.6      91.5   36.5      72.5      51.2   \n",
       "2    1  Vic   f  6.0     94.0    60.0      95.5   39.0      75.4      51.9   \n",
       "3    1  Vic   f  6.0     93.2    57.1      92.0   38.0      76.1      52.2   \n",
       "5    1  Vic   f  1.0     93.1    54.8      90.5   35.5      73.2      53.6   \n",
       "6    1  Vic   m  2.0     95.3    58.2      89.5   36.0      71.5      52.0   \n",
       "\n",
       "    eye  chest  belly pop-bin sex-bin  \n",
       "1  16.0   28.5   33.0     1.0       1  \n",
       "2  15.5   30.0   34.0     1.0       1  \n",
       "3  15.2   28.0   34.0     1.0       1  \n",
       "5  14.2   30.0   32.0     1.0       1  \n",
       "6  14.2   30.0   34.5     1.0       0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = pd.get_dummies(train_set_new[\"pop\"])\n",
    "train_set_new = pd.concat((train_set_new, dummy), axis=1)\n",
    "del train_set_new[\"other\"]\n",
    "train_set_new = train_set_new.rename(columns={\"Vic\":\"pop-bin\"})\n",
    "\n",
    "dummy = pd.get_dummies(df[\"sex\"])\n",
    "train_set_new = pd.concat((train_set_new, dummy), axis=1)\n",
    "del train_set_new['m']\n",
    "train_set_new = train_set_new.rename(columns={\"f\":\"sex-bin\"})\n",
    "train_set_new.head()\n",
    "\n",
    "train_set_new[\"pop-bin\"] = train_set_new[\"pop-bin\"].astype('category')\n",
    "train_set_new[\"sex-bin\"] = train_set_new[\"sex-bin\"].astype('category')\n",
    "\n",
    "train_set_new = train_set_new.dropna()\n",
    "train_set_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a620143e-7641-4834-9ef6-cd7304960dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointbiserialrResult(correlation=0.08370838421598426, pvalue=0.4574990767891822)\n",
      "PointbiserialrResult(correlation=0.09748964259300605, pvalue=0.38658098861846485)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pointbiserialr(train_set_new[\"pop-bin\"], train_set_new[\"age\"]))\n",
    "print(stats.pointbiserialr(train_set_new[\"sex-bin\"], train_set_new[\"age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531f8d31-e4b6-437a-bf79-5055463b3809",
   "metadata": {},
   "source": [
    "So even if assumtions of this method are fulfilled, these correlations are not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625aca3-80f0-421d-933b-5fb2fd12eaff",
   "metadata": {},
   "source": [
    "For a multi categorical attribute we will try ruskal-Wallis H-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d10b7f76-39d2-4b1c-b9c0-0059fa56e1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25\n",
       "7    13\n",
       "5    11\n",
       "6    11\n",
       "2     9\n",
       "3     6\n",
       "4     6\n",
       "Name: site, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_new[\"site\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05a7ac49-b0ce-4308-967c-2496f38076ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KruskalResult(statistic=0.3395172088593224, pvalue=0.5601080307426141)\n",
      "KruskalResult(statistic=0.1417795109924597, pvalue=0.7065183074614497)\n",
      "KruskalResult(statistic=0.561735433647231, pvalue=0.4535618539169247)\n",
      "KruskalResult(statistic=2.005456853621326, pvalue=0.15673406872991036)\n",
      "KruskalResult(statistic=1.2790622918879813, pvalue=0.2580734590616538)\n",
      "KruskalResult(statistic=0.008454874681601976, pvalue=0.9267374535850667)\n",
      "KruskalResult(statistic=1.136838159720179, pvalue=0.28632143298397716)\n"
     ]
    }
   ],
   "source": [
    "group = [None] * 7\n",
    "\n",
    "for i in range(1,8):\n",
    "    group[i-1] = train_set_new[[\"age\"]].where(train_set_new[\"site\"] == i).dropna()[\"age\"].tolist()\n",
    "    print(stats.kruskal(group[i-1], train_set_new[\"age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa602941-8c9d-4565-829a-de20bcd816c5",
   "metadata": {},
   "source": [
    "Since for every group p-value is less than 0.05, we don't reject the null hypothesis that the median of group is same as in train_set for each group. So, we can expect that, site-grouping does not explain the variance to a great extent, hence correlation is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9fef5-8b7f-4ef3-b8f8-adb80a8123f1",
   "metadata": {},
   "source": [
    "<h3> Attribute Combinations </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e0c24a-a5ec-4c29-80b8-51ab112ff7e3",
   "metadata": {},
   "source": [
    "Since we have only 9 attributes describing possums body, let's just compute ratios between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ab06a42-27a7-44d0-b205-2cb0ac1b1156",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new = train_set.copy()\n",
    "\n",
    "body_columns = ['hdlngth', 'skullw', 'totlngth', 'taill', 'footlgth', 'earconch', 'eye', 'chest', 'belly']\n",
    "\n",
    "for i in range(9):\n",
    "    for j in range(i+1,9):\n",
    "        new_column = body_columns[i] + \" / \" + body_columns[j]\n",
    "        train_set_new[new_column] = train_set_new[body_columns[i]] / train_set_new[body_columns[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ee7791f-12fc-483b-9660-06eb3da959c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                    1.000000\n",
       "belly                  0.283273\n",
       "hdlngth                0.254740\n",
       "totlngth               0.244830\n",
       "eye                    0.220969\n",
       "chest                  0.204392\n",
       "skullw                 0.192840\n",
       "totlngth / footlgth    0.162309\n",
       "totlngth / taill       0.147566\n",
       "hdlngth / footlgth     0.141474\n",
       "skullw / footlgth      0.120056\n",
       "totlngth / earconch    0.099592\n",
       "taill                  0.098013\n",
       "hdlngth / earconch     0.087937\n",
       "skullw / earconch      0.084262\n",
       "hdlngth / taill        0.083814\n",
       "skullw / taill         0.081666\n",
       "footlgth               0.045257\n",
       "earconch               0.037012\n",
       "taill / footlgth       0.025634\n",
       "taill / earconch       0.018716\n",
       "hdlngth / skullw      -0.024388\n",
       "skullw / totlngth     -0.024991\n",
       "totlngth / eye        -0.027085\n",
       "eye / chest           -0.028092\n",
       "footlgth / earconch   -0.034156\n",
       "skullw / eye          -0.051047\n",
       "hdlngth / totlngth    -0.057181\n",
       "hdlngth / eye         -0.068390\n",
       "totlngth / chest      -0.074794\n",
       "eye / belly           -0.091034\n",
       "skullw / chest        -0.098670\n",
       "earconch / eye        -0.107609\n",
       "chest / belly         -0.110646\n",
       "hdlngth / chest       -0.111580\n",
       "taill / eye           -0.116237\n",
       "footlgth / eye        -0.125232\n",
       "taill / chest         -0.147681\n",
       "earconch / chest      -0.153394\n",
       "totlngth / belly      -0.163507\n",
       "skullw / belly        -0.167239\n",
       "hdlngth / belly       -0.198297\n",
       "footlgth / chest      -0.202875\n",
       "earconch / belly      -0.208473\n",
       "taill / belly         -0.218608\n",
       "footlgth / belly      -0.263342\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = train_set_new.corr()\n",
    "corr_matrix[\"age\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5e069-a902-4d78-ac32-fe6814613796",
   "metadata": {},
   "source": [
    "Again, correlations are on very low level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca6387-b60b-44f3-8fbe-4b6cfa0bfef7",
   "metadata": {},
   "source": [
    "<h2> Prepare the data for ML algorithms </h2>\n",
    "<h3> Data Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2601a2f8-62ee-452b-a521-9746f01b8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new = train_set.copy()\n",
    "train_set_new = train_set_new[train_set_new['age'].notna()]\n",
    "train_set_labels = train_set_new[\"age\"].copy()\n",
    "train_set_new = train_set_new.drop(\"age\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac7d57-a2e5-434e-80fc-4e32da285f83",
   "metadata": {},
   "source": [
    "Since there is only one nan label, we've just dropped it.\n",
    "\n",
    "Most ML algorithms cannot deal with missing values and we are not sure that there won't be any missing values in new data, let's take a stretegy to replace numerical missing instances with the median of an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4671ed4f-2e58-4eb8-a9a5-911e58586480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "train_set_new_num = train_set_new.drop([\"site\", \"pop\", \"sex\"], axis=1)\n",
    "imputer.fit(train_set_new_num)\n",
    "X = imputer.transform(train_set_new_num)\n",
    "train_set_new_transformed = pd.DataFrame(X, columns=train_set_new_num.columns)\n",
    "\n",
    "train_set_new_transformed.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db181a62-bef6-47b1-ad7c-57b72b60b072",
   "metadata": {},
   "source": [
    "Since ML algorithms prefer to work with number rather than with categogorical attributes, we will convert them to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "eb92a133-9850-440b-8fe2-234d5a4e720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new_cat = train_set_new[[\"site\", \"pop\", \"sex\"]]\n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "train_set_new_cat_encoded = cat_encoder.fit_transform(train_set_new_cat)\n",
    "\n",
    "train_set_new_cat_encoded = train_set_new_cat_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f058b06f-92d3-4846-9ffd-112367fb6f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       " array(['Vic', 'other'], dtype=object),\n",
       " array(['f', 'm'], dtype=object)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfeeb7b-bcc2-468a-a39a-77073f5a2eae",
   "metadata": {},
   "source": [
    "Let's create a Pipeline, to hold our transformations in more readable way. Despite the fact that, our data is very good scaled, we can additionaly do standarization, beacuse dataset is very small and it cost almost no time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3254c0e1-cd1a-453c-83b1-0962f5a67bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "num_attribs = list(train_set_new_num.columns)\n",
    "cat_attribs = [\"site\", \"pop\", \"sex\"]\n",
    "\n",
    "pipeline = ColumnTransformer([\n",
    " (\"num\", num_pipeline, num_attribs),\n",
    " (\"cat\", OneHotEncoder(), cat_attribs),\n",
    " (\"r-skewed\", FunctionTransformer(func=np.log1p), ['totlngth', 'belly']),\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c8aa6-2035-42cc-a6bd-ca1fb63d282d",
   "metadata": {},
   "source": [
    "Additionally we did appropriate transformation to right skewed features. Now, we will use our transformated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4c407f6e-1611-46e5-982a-c7b8efd576dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 58)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_new_ready = pipeline.fit_transform(train_set_new)\n",
    "train_set_new_ready.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639af556-12cb-485c-8391-e9132d5d4790",
   "metadata": {},
   "source": [
    "We finished this section with set that contains 58 columns, ready to put into ML algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f74ce-98e5-4a03-9dc0-589f97e1c6cd",
   "metadata": {},
   "source": [
    "<h2> Select and train a model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5f8b66a3-70b3-45be-bcce-2f276fe9ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn import ensemble\n",
    "from sklearn import isotonic\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69385e8b-ffbd-4c0a-aee4-fbade7f2509c",
   "metadata": {},
   "source": [
    "Our plan is to test as many as possible models, with some different settings, in a short time, then choose a few most promising for hyperparameter tuning, based on rmse measure for training set and cross-validation.\n",
    "\n",
    "Let's calculate RMSE for training data and mean value of RMSE for Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72ce73-74f7-4952-a70b-407e0d88b624",
   "metadata": {},
   "source": [
    "<h2> Finding promising models </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e548fb1-3350-47d6-8a86-7dbadb30875d",
   "metadata": {},
   "source": [
    "<h3> Linear Models </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5567700f-6493-4434-a269-f68ce3368215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARDRegression{}</th>\n",
       "      <th>BayesianRidge{}</th>\n",
       "      <th>ElasticNet{'selection': 'cyclic'}</th>\n",
       "      <th>ElasticNet{'selection': 'random'}</th>\n",
       "      <th>HuberRegressor{}</th>\n",
       "      <th>Lars{}</th>\n",
       "      <th>Lasso{'selection': 'cyclic'}</th>\n",
       "      <th>Lasso{'selection': 'random'}</th>\n",
       "      <th>LassoLars{}</th>\n",
       "      <th>LinearRegression{}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'saga'}</th>\n",
       "      <th>OrthogonalMatchingPursuit{}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>RANSACRegressor{}</th>\n",
       "      <th>Ridge{'solver': 'svd'}</th>\n",
       "      <th>Ridge{'solver': 'cholesky'}</th>\n",
       "      <th>Ridge{'solver': 'lsqr'}</th>\n",
       "      <th>Ridge{'solver': 'sparse_cg'}</th>\n",
       "      <th>Ridge{'solver': 'sag'}</th>\n",
       "      <th>Ridge{'solver': 'saga'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>TheilSenRegressor{}</th>\n",
       "      <th>TweedieRegressor{'link': 'identity'}</th>\n",
       "      <th>TweedieRegressor{'link': 'log'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.500612</td>\n",
       "      <td>1.720985</td>\n",
       "      <td>1.807324</td>\n",
       "      <td>1.807324</td>\n",
       "      <td>1.275551</td>\n",
       "      <td>72.090142</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>0.850896</td>\n",
       "      <td>1.678414</td>\n",
       "      <td>1.728527</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.530184</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.649094</td>\n",
       "      <td>1.637964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594692</td>\n",
       "      <td>1.444080</td>\n",
       "      <td>1.485704</td>\n",
       "      <td>1.570558</td>\n",
       "      <td>2.043614</td>\n",
       "      <td>2.612285</td>\n",
       "      <td>2.601949</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>1.391946</td>\n",
       "      <td>1.390878</td>\n",
       "      <td>1.404288</td>\n",
       "      <td>1.417763</td>\n",
       "      <td>1.890971</td>\n",
       "      <td>4.681458e+13</td>\n",
       "      <td>1.587441</td>\n",
       "      <td>1.469083</td>\n",
       "      <td>2.353110</td>\n",
       "      <td>1.172988e+14</td>\n",
       "      <td>1.632409</td>\n",
       "      <td>1.497848</td>\n",
       "      <td>1.454201</td>\n",
       "      <td>1.070829</td>\n",
       "      <td>1.639399</td>\n",
       "      <td>1.524623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.936501</td>\n",
       "      <td>1.849728</td>\n",
       "      <td>1.854198</td>\n",
       "      <td>1.854542</td>\n",
       "      <td>2.580660</td>\n",
       "      <td>13222.012598</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>8.022427</td>\n",
       "      <td>1.986954</td>\n",
       "      <td>2.064786</td>\n",
       "      <td>2.362686</td>\n",
       "      <td>2.362686</td>\n",
       "      <td>2.156346</td>\n",
       "      <td>2.246902</td>\n",
       "      <td>2.246902</td>\n",
       "      <td>2.179860</td>\n",
       "      <td>2.738958</td>\n",
       "      <td>2.357410</td>\n",
       "      <td>2.554081</td>\n",
       "      <td>2.393976</td>\n",
       "      <td>1.945627</td>\n",
       "      <td>2.294083</td>\n",
       "      <td>2.186708</td>\n",
       "      <td>15.167141</td>\n",
       "      <td>2.012011</td>\n",
       "      <td>2.012011</td>\n",
       "      <td>2.009908</td>\n",
       "      <td>2.012133</td>\n",
       "      <td>2.012058</td>\n",
       "      <td>2.009161</td>\n",
       "      <td>2.787248</td>\n",
       "      <td>1.011803e+14</td>\n",
       "      <td>1.948427</td>\n",
       "      <td>1.995468</td>\n",
       "      <td>2.293446</td>\n",
       "      <td>8.042401e+13</td>\n",
       "      <td>1.944068</td>\n",
       "      <td>1.950731</td>\n",
       "      <td>1.952146</td>\n",
       "      <td>8.693768</td>\n",
       "      <td>1.851942</td>\n",
       "      <td>2.114590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ARDRegression{}  BayesianRidge{}  \\\n",
       "rmse_training         1.500612         1.720985   \n",
       "rmse_cv               1.936501         1.849728   \n",
       "\n",
       "               ElasticNet{'selection': 'cyclic'}  \\\n",
       "rmse_training                           1.807324   \n",
       "rmse_cv                                 1.854198   \n",
       "\n",
       "               ElasticNet{'selection': 'random'}  HuberRegressor{}  \\\n",
       "rmse_training                           1.807324          1.275551   \n",
       "rmse_cv                                 1.854542          2.580660   \n",
       "\n",
       "                     Lars{}  Lasso{'selection': 'cyclic'}  \\\n",
       "rmse_training     72.090142                      1.809692   \n",
       "rmse_cv        13222.012598                      1.844538   \n",
       "\n",
       "               Lasso{'selection': 'random'}  LassoLars{}  LinearRegression{}  \\\n",
       "rmse_training                      1.809692     1.809692            0.850896   \n",
       "rmse_cv                            1.844538     1.844538            8.022427   \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}  \\\n",
       "rmse_training                                           1.678414            \n",
       "rmse_cv                                                 1.986954            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.728527       \n",
       "rmse_cv                                                 2.064786       \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}  \\\n",
       "rmse_training                                           1.542092            \n",
       "rmse_cv                                                 2.362686            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.542092        \n",
       "rmse_cv                                                 2.362686        \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}  \\\n",
       "rmse_training                                           1.530184            \n",
       "rmse_cv                                                 2.156346            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'sag'}  \\\n",
       "rmse_training                                           1.542092      \n",
       "rmse_cv                                                 2.246902      \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.649094       \n",
       "rmse_cv                                                 2.246902       \n",
       "\n",
       "               LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}  \\\n",
       "rmse_training                                           1.637964                                \n",
       "rmse_cv                                                 2.179860                                \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}  \\\n",
       "rmse_training                                           0.000000              \n",
       "rmse_cv                                                 2.738958              \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.594692          \n",
       "rmse_cv                                                 2.357410          \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'sag'}  \\\n",
       "rmse_training                                           1.444080        \n",
       "rmse_cv                                                 2.554081        \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.485704         \n",
       "rmse_cv                                                 2.393976         \n",
       "\n",
       "               OrthogonalMatchingPursuit{}  \\\n",
       "rmse_training                     1.570558   \n",
       "rmse_cv                           1.945627   \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_training                                           2.043614           \n",
       "rmse_cv                                                 2.294083           \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_training                                           2.612285                   \n",
       "rmse_cv                                                 2.186708                   \n",
       "\n",
       "               RANSACRegressor{}  Ridge{'solver': 'svd'}  \\\n",
       "rmse_training           2.601949                1.390836   \n",
       "rmse_cv                15.167141                2.012011   \n",
       "\n",
       "               Ridge{'solver': 'cholesky'}  Ridge{'solver': 'lsqr'}  \\\n",
       "rmse_training                     1.390836                 1.391946   \n",
       "rmse_cv                           2.012011                 2.009908   \n",
       "\n",
       "               Ridge{'solver': 'sparse_cg'}  Ridge{'solver': 'sag'}  \\\n",
       "rmse_training                      1.390878                1.404288   \n",
       "rmse_cv                            2.012133                2.012058   \n",
       "\n",
       "               Ridge{'solver': 'saga'}  \\\n",
       "rmse_training                 1.417763   \n",
       "rmse_cv                       2.009161   \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}  \\\n",
       "rmse_training                                           1.890971            \n",
       "rmse_cv                                                 2.787248            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}  \\\n",
       "rmse_training                                       4.681458e+13           \n",
       "rmse_cv                                             1.011803e+14           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_training                                           1.587441              \n",
       "rmse_cv                                                 1.948427              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.469083            \n",
       "rmse_cv                                                 1.995468            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}  \\\n",
       "rmse_training                                           2.353110            \n",
       "rmse_cv                                                 2.293446            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}  \\\n",
       "rmse_training                                       1.172988e+14           \n",
       "rmse_cv                                             8.042401e+13           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_training                                           1.632409              \n",
       "rmse_cv                                                 1.944068              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.497848            \n",
       "rmse_cv                                                 1.950731            \n",
       "\n",
       "               SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.454201                    \n",
       "rmse_cv                                                 1.952146                    \n",
       "\n",
       "               TheilSenRegressor{}  TweedieRegressor{'link': 'identity'}  \\\n",
       "rmse_training             1.070829                              1.639399   \n",
       "rmse_cv                   8.693768                              1.851942   \n",
       "\n",
       "               TweedieRegressor{'link': 'log'}  \n",
       "rmse_training                         1.524623  \n",
       "rmse_cv                               2.114590  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_lm = regression_linear_models(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_lm = pd.DataFrame.from_dict(result_lm)\n",
    "result_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aff8b1-d93f-4d7c-80a5-9926ebaddd29",
   "metadata": {},
   "source": [
    "<h3> KernelRidge </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a07b2aec-841f-4eb5-80bb-3271c7c419ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KernelRidge 1**2</th>\n",
       "      <th>KernelRidge DotProduct(sigma_0=1)</th>\n",
       "      <th>KernelRidge ExpSineSquared(length_scale=1, periodicity=1)</th>\n",
       "      <th>KernelRidge Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>KernelRidge PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>KernelRidge RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>KernelRidge RBF(length_scale=1)</th>\n",
       "      <th>KernelRidge WhiteKernel(noise_level=1)</th>\n",
       "      <th>KernelRidge linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.810247</td>\n",
       "      <td>1.390653</td>\n",
       "      <td>3.318812</td>\n",
       "      <td>2.023938</td>\n",
       "      <td>1.390648</td>\n",
       "      <td>1.218348</td>\n",
       "      <td>2.055960</td>\n",
       "      <td>4.136394</td>\n",
       "      <td>1.390648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.842443</td>\n",
       "      <td>2.011974</td>\n",
       "      <td>15.776251</td>\n",
       "      <td>4.042328</td>\n",
       "      <td>2.011973</td>\n",
       "      <td>2.578366</td>\n",
       "      <td>4.083858</td>\n",
       "      <td>4.099670</td>\n",
       "      <td>2.011973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               KernelRidge 1**2  KernelRidge DotProduct(sigma_0=1)  \\\n",
       "rmse_training          1.810247                           1.390653   \n",
       "rmse_cv                1.842443                           2.011974   \n",
       "\n",
       "               KernelRidge ExpSineSquared(length_scale=1, periodicity=1)  \\\n",
       "rmse_training                                           3.318812           \n",
       "rmse_cv                                                15.776251           \n",
       "\n",
       "               KernelRidge Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_training                                    2.023938   \n",
       "rmse_cv                                          4.042328   \n",
       "\n",
       "               KernelRidge PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_training                                           1.390648      \n",
       "rmse_cv                                                 2.011973      \n",
       "\n",
       "               KernelRidge RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_training                                           1.218348        \n",
       "rmse_cv                                                 2.578366        \n",
       "\n",
       "               KernelRidge RBF(length_scale=1)  \\\n",
       "rmse_training                         2.055960   \n",
       "rmse_cv                               4.083858   \n",
       "\n",
       "               KernelRidge WhiteKernel(noise_level=1)  KernelRidge linear  \n",
       "rmse_training                                4.136394            1.390648  \n",
       "rmse_cv                                      4.099670            2.011973  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_kr = regression_kernelridge(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_kr = pd.DataFrame.from_dict(result_kr)\n",
    "result_kr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7469a3c-5c39-4edf-b591-3ea6b498ed1d",
   "metadata": {},
   "source": [
    "<h3> SVM </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2286bf4-9a60-4819-a0b9-93bc8b149dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearSVR{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>LinearSVR{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>NuSVR{'kernel': 'linear'}</th>\n",
       "      <th>NuSVR{'kernel': 'poly'}</th>\n",
       "      <th>NuSVR{'kernel': 'rbf'}</th>\n",
       "      <th>NuSVR{'kernel': 'sigmoid'}</th>\n",
       "      <th>SVR{'kernel': 'linear'}</th>\n",
       "      <th>SVR{'kernel': 'poly'}</th>\n",
       "      <th>SVR{'kernel': 'rbf'}</th>\n",
       "      <th>SVR{'kernel': 'sigmoid'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.500873</td>\n",
       "      <td>1.343088</td>\n",
       "      <td>1.476317</td>\n",
       "      <td>1.377438</td>\n",
       "      <td>1.481749</td>\n",
       "      <td>1.837184</td>\n",
       "      <td>1.496323</td>\n",
       "      <td>1.43371</td>\n",
       "      <td>1.489761</td>\n",
       "      <td>1.877357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.166390</td>\n",
       "      <td>2.052075</td>\n",
       "      <td>1.916470</td>\n",
       "      <td>1.770307</td>\n",
       "      <td>1.742634</td>\n",
       "      <td>1.851783</td>\n",
       "      <td>2.133088</td>\n",
       "      <td>1.82145</td>\n",
       "      <td>1.720149</td>\n",
       "      <td>1.933953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LinearSVR{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_training                                  1.500873   \n",
       "rmse_cv                                        2.166390   \n",
       "\n",
       "               LinearSVR{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_training                                          1.343088   \n",
       "rmse_cv                                                2.052075   \n",
       "\n",
       "               NuSVR{'kernel': 'linear'}  NuSVR{'kernel': 'poly'}  \\\n",
       "rmse_training                   1.476317                 1.377438   \n",
       "rmse_cv                         1.916470                 1.770307   \n",
       "\n",
       "               NuSVR{'kernel': 'rbf'}  NuSVR{'kernel': 'sigmoid'}  \\\n",
       "rmse_training                1.481749                    1.837184   \n",
       "rmse_cv                      1.742634                    1.851783   \n",
       "\n",
       "               SVR{'kernel': 'linear'}  SVR{'kernel': 'poly'}  \\\n",
       "rmse_training                 1.496323                1.43371   \n",
       "rmse_cv                       2.133088                1.82145   \n",
       "\n",
       "               SVR{'kernel': 'rbf'}  SVR{'kernel': 'sigmoid'}  \n",
       "rmse_training              1.489761                  1.877357  \n",
       "rmse_cv                    1.720149                  1.933953  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_svm = regression_svm(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_svm = pd.DataFrame.from_dict(result_svm)\n",
    "result_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c2afd-59da-4837-bf7c-553632aca616",
   "metadata": {},
   "source": [
    "<h3> Gaussian Process </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac1aca39-84c6-408c-8391-37cd20cf0b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GaussianProcessRegressor 1**2</th>\n",
       "      <th>GaussianProcessRegressor DotProduct(sigma_0=1)</th>\n",
       "      <th>GaussianProcessRegressor Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor RBF(length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor WhiteKernel(noise_level=1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.809692</td>\n",
       "      <td>0.850870</td>\n",
       "      <td>3.182825e-10</td>\n",
       "      <td>0.851026</td>\n",
       "      <td>2.213020e-10</td>\n",
       "      <td>4.607285e-10</td>\n",
       "      <td>4.136394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>3.456524</td>\n",
       "      <td>8.021744</td>\n",
       "      <td>1.773059e+00</td>\n",
       "      <td>8.021249</td>\n",
       "      <td>1.705117e+00</td>\n",
       "      <td>2.039888e+00</td>\n",
       "      <td>4.099670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GaussianProcessRegressor 1**2  \\\n",
       "rmse_training                       1.809692   \n",
       "rmse_cv                             3.456524   \n",
       "\n",
       "               GaussianProcessRegressor DotProduct(sigma_0=1)  \\\n",
       "rmse_training                                        0.850870   \n",
       "rmse_cv                                              8.021744   \n",
       "\n",
       "               GaussianProcessRegressor Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_training                                       3.182825e-10         \n",
       "rmse_cv                                             1.773059e+00         \n",
       "\n",
       "               GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_training                                           0.851026                   \n",
       "rmse_cv                                                 8.021249                   \n",
       "\n",
       "               GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_training                                       2.213020e-10                     \n",
       "rmse_cv                                             1.705117e+00                     \n",
       "\n",
       "               GaussianProcessRegressor RBF(length_scale=1)  \\\n",
       "rmse_training                                  4.607285e-10   \n",
       "rmse_cv                                        2.039888e+00   \n",
       "\n",
       "               GaussianProcessRegressor WhiteKernel(noise_level=1)  \n",
       "rmse_training                                           4.136394    \n",
       "rmse_cv                                                 4.099670    "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_gpr = regression_gaussianprocess(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_gpr = pd.DataFrame.from_dict(result_gpr)\n",
    "result_gpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309d691-bb9b-4ff5-9521-18d3a32dbdd8",
   "metadata": {},
   "source": [
    "<h3> Cross Decomposition </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72a67d4d-5ee1-4714-80eb-538ef1576912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCA{}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'nipals'}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'svd'}</th>\n",
       "      <th>PLSRegression{}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.788298</td>\n",
       "      <td>4.701129</td>\n",
       "      <td>4.701129</td>\n",
       "      <td>1.586375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.841178</td>\n",
       "      <td>4.974416</td>\n",
       "      <td>4.974416</td>\n",
       "      <td>1.890073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CCA{}  PLSCanonical{'algorithm': 'nipals'}  \\\n",
       "rmse_training  1.788298                             4.701129   \n",
       "rmse_cv        1.841178                             4.974416   \n",
       "\n",
       "               PLSCanonical{'algorithm': 'svd'}  PLSRegression{}  \n",
       "rmse_training                          4.701129         1.586375  \n",
       "rmse_cv                                4.974416         1.890073  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_cd = regression_crossdecomposition(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_cd = pd.DataFrame.from_dict(result_cd)\n",
    "result_cd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32336f-e3ac-4b8a-a383-11f256528c21",
   "metadata": {},
   "source": [
    "<h3> Decision Tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddf85a83-27ca-4753-8b8f-b7049038b959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.233843</td>\n",
       "      <td>2.271042</td>\n",
       "      <td>2.212846</td>\n",
       "      <td>2.183563</td>\n",
       "      <td>2.478414</td>\n",
       "      <td>2.767762</td>\n",
       "      <td>2.531771</td>\n",
       "      <td>2.25333</td>\n",
       "      <td>2.210463</td>\n",
       "      <td>2.267652</td>\n",
       "      <td>2.33212</td>\n",
       "      <td>2.106171</td>\n",
       "      <td>2.229213</td>\n",
       "      <td>2.398755</td>\n",
       "      <td>2.500572</td>\n",
       "      <td>2.412046</td>\n",
       "      <td>2.464264</td>\n",
       "      <td>2.213631</td>\n",
       "      <td>2.50611</td>\n",
       "      <td>2.181833</td>\n",
       "      <td>2.439564</td>\n",
       "      <td>2.138197</td>\n",
       "      <td>2.323329</td>\n",
       "      <td>2.685324</td>\n",
       "      <td>2.75459</td>\n",
       "      <td>2.602973</td>\n",
       "      <td>2.543508</td>\n",
       "      <td>2.540274</td>\n",
       "      <td>2.624218</td>\n",
       "      <td>2.472819</td>\n",
       "      <td>2.444517</td>\n",
       "      <td>2.495016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                      \n",
       "rmse_cv                                                 2.233843                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.271042                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.212846                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.183563                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.478414                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.767762                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.531771                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                            0.00000                                          \n",
       "rmse_cv                                                  2.25333                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                               \n",
       "rmse_cv                                                 2.210463                                               \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.267652                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                            0.00000                                                 \n",
       "rmse_cv                                                  2.33212                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.106171                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.229213                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.398755                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.500572                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.412046                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                      \n",
       "rmse_cv                                                 2.464264                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.213631                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                            0.00000                                        \n",
       "rmse_cv                                                  2.50611                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.181833                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.439564                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.138197                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.323329                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.685324                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                            0.00000                                          \n",
       "rmse_cv                                                  2.75459                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.602973                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.543508                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.540274                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.624218                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.472819                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.444517                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}  \n",
       "rmse_training                                           0.000000                                             \n",
       "rmse_cv                                                 2.495016                                             "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tree = regression_decisiontree(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_tree = pd.DataFrame.from_dict(result_tree)\n",
    "result_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7738c198-9f33-4fae-afb8-b2eb024593ba",
   "metadata": {},
   "source": [
    "<h3> Ensemble Methods </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b093ada-54f0-4cc6-a208-3d7f265f49c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor{'loss': 'linear'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'square'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'exponential'}</th>\n",
       "      <th>BaggingRegressor{}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>IsolationForest{}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}</th>\n",
       "      <th>StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "      <th>VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>0.748394</td>\n",
       "      <td>0.752847</td>\n",
       "      <td>0.813556</td>\n",
       "      <td>0.709689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.175867</td>\n",
       "      <td>0.172554</td>\n",
       "      <td>0.782008</td>\n",
       "      <td>0.867638</td>\n",
       "      <td>0.787688</td>\n",
       "      <td>0.838049</td>\n",
       "      <td>0.336339</td>\n",
       "      <td>0.339343</td>\n",
       "      <td>0.360592</td>\n",
       "      <td>0.371980</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>2.90500</td>\n",
       "      <td>1.770743</td>\n",
       "      <td>1.843639</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>0.162377</td>\n",
       "      <td>0.163356</td>\n",
       "      <td>0.786237</td>\n",
       "      <td>0.846086</td>\n",
       "      <td>0.778843</td>\n",
       "      <td>0.979175</td>\n",
       "      <td>0.344708</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.379605</td>\n",
       "      <td>0.358401</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>2.90500</td>\n",
       "      <td>1.851697</td>\n",
       "      <td>1.636451</td>\n",
       "      <td>3.525171</td>\n",
       "      <td>0.647693</td>\n",
       "      <td>0.633147</td>\n",
       "      <td>0.625064</td>\n",
       "      <td>0.646255</td>\n",
       "      <td>0.633280</td>\n",
       "      <td>0.662081</td>\n",
       "      <td>0.659908</td>\n",
       "      <td>0.693101</td>\n",
       "      <td>0.771076</td>\n",
       "      <td>0.766170</td>\n",
       "      <td>0.780420</td>\n",
       "      <td>0.647580</td>\n",
       "      <td>2.022631</td>\n",
       "      <td>1.581238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.760326</td>\n",
       "      <td>1.812322</td>\n",
       "      <td>1.787383</td>\n",
       "      <td>1.822539</td>\n",
       "      <td>1.669964</td>\n",
       "      <td>1.708569</td>\n",
       "      <td>1.668885</td>\n",
       "      <td>1.678114</td>\n",
       "      <td>1.719614</td>\n",
       "      <td>1.730097</td>\n",
       "      <td>1.662910</td>\n",
       "      <td>1.701542</td>\n",
       "      <td>1.788450</td>\n",
       "      <td>1.762106</td>\n",
       "      <td>1.726689</td>\n",
       "      <td>1.718209</td>\n",
       "      <td>1.720116</td>\n",
       "      <td>1.712542</td>\n",
       "      <td>1.705946</td>\n",
       "      <td>1.727104</td>\n",
       "      <td>1.707595</td>\n",
       "      <td>1.709394</td>\n",
       "      <td>1.698285</td>\n",
       "      <td>1.704229</td>\n",
       "      <td>2.933611</td>\n",
       "      <td>2.93433</td>\n",
       "      <td>2.178177</td>\n",
       "      <td>2.108735</td>\n",
       "      <td>1.769831</td>\n",
       "      <td>1.784594</td>\n",
       "      <td>1.756995</td>\n",
       "      <td>1.734954</td>\n",
       "      <td>1.711839</td>\n",
       "      <td>1.717866</td>\n",
       "      <td>1.722055</td>\n",
       "      <td>1.767350</td>\n",
       "      <td>1.717599</td>\n",
       "      <td>1.701336</td>\n",
       "      <td>1.722730</td>\n",
       "      <td>1.741788</td>\n",
       "      <td>2.926688</td>\n",
       "      <td>2.92617</td>\n",
       "      <td>2.200880</td>\n",
       "      <td>2.151828</td>\n",
       "      <td>3.646324</td>\n",
       "      <td>1.725150</td>\n",
       "      <td>1.700438</td>\n",
       "      <td>1.694973</td>\n",
       "      <td>1.705529</td>\n",
       "      <td>1.705437</td>\n",
       "      <td>1.703849</td>\n",
       "      <td>1.725070</td>\n",
       "      <td>1.718557</td>\n",
       "      <td>2.048090</td>\n",
       "      <td>2.007084</td>\n",
       "      <td>2.202913</td>\n",
       "      <td>1.786684</td>\n",
       "      <td>1.836144</td>\n",
       "      <td>1.815186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AdaBoostRegressor{'loss': 'linear'}  \\\n",
       "rmse_training                             0.748394   \n",
       "rmse_cv                                   1.760326   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'square'}  \\\n",
       "rmse_training                             0.752847   \n",
       "rmse_cv                                   1.812322   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'exponential'}  BaggingRegressor{}  \\\n",
       "rmse_training                                  0.813556            0.709689   \n",
       "rmse_cv                                        1.787383            1.822539   \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.669964                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.708569                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.668885                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.678114                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000               \n",
       "rmse_cv                                                 1.719614               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000               \n",
       "rmse_cv                                                 1.730097               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_training                                           0.023599            \n",
       "rmse_cv                                                 1.662910            \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_training                                           0.000000            \n",
       "rmse_cv                                                 1.701542            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_training                                           0.117268                                            \n",
       "rmse_cv                                                 1.788450                                            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.117268                                              \n",
       "rmse_cv                                                 1.762106                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.175867                                              \n",
       "rmse_cv                                                 1.726689                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.172554                                              \n",
       "rmse_cv                                                 1.718209                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_training                                           0.782008                                             \n",
       "rmse_cv                                                 1.720116                                             \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.867638                                               \n",
       "rmse_cv                                                 1.712542                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.787688                                               \n",
       "rmse_cv                                                 1.705946                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.838049                                               \n",
       "rmse_cv                                                 1.727104                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_training                                           0.336339                                               \n",
       "rmse_cv                                                 1.707595                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.339343                                                 \n",
       "rmse_cv                                                 1.709394                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.360592                                                 \n",
       "rmse_cv                                                 1.698285                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.371980                                                 \n",
       "rmse_cv                                                 1.704229                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_training                                           2.905000                                                  \n",
       "rmse_cv                                                 2.933611                                                  \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_training                                            2.90500                                                    \n",
       "rmse_cv                                                  2.93433                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           1.770743                                                    \n",
       "rmse_cv                                                 2.178177                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           1.843639                                                    \n",
       "rmse_cv                                                 2.108735                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_training                                           0.117268                                   \n",
       "rmse_cv                                                 1.769831                                   \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.119379                                     \n",
       "rmse_cv                                                 1.784594                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.162377                                     \n",
       "rmse_cv                                                 1.756995                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.163356                                     \n",
       "rmse_cv                                                 1.734954                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_training                                           0.786237                                    \n",
       "rmse_cv                                                 1.711839                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.846086                                      \n",
       "rmse_cv                                                 1.717866                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.778843                                      \n",
       "rmse_cv                                                 1.722055                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.979175                                      \n",
       "rmse_cv                                                 1.767350                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_training                                           0.344708                                      \n",
       "rmse_cv                                                 1.717599                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.344400                                        \n",
       "rmse_cv                                                 1.701336                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.379605                                        \n",
       "rmse_cv                                                 1.722730                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.358401                                        \n",
       "rmse_cv                                                 1.741788                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_training                                           2.905000                                         \n",
       "rmse_cv                                                 2.926688                                         \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_training                                            2.90500                                           \n",
       "rmse_cv                                                  2.92617                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           1.851697                                           \n",
       "rmse_cv                                                 2.200880                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           1.636451                                           \n",
       "rmse_cv                                                 2.151828                                           \n",
       "\n",
       "               IsolationForest{}  \\\n",
       "rmse_training           3.525171   \n",
       "rmse_cv                 3.646324   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.647693                   \n",
       "rmse_cv                                                 1.725150                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.633147                   \n",
       "rmse_cv                                                 1.700438                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_training                                           0.625064                 \n",
       "rmse_cv                                                 1.694973                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_training                                           0.646255              \n",
       "rmse_cv                                                 1.705529              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.633280                   \n",
       "rmse_cv                                                 1.705437                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.662081                   \n",
       "rmse_cv                                                 1.703849                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_training                                           0.659908                 \n",
       "rmse_cv                                                 1.725070                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_training                                           0.693101              \n",
       "rmse_cv                                                 1.718557              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.771076                       \n",
       "rmse_cv                                                 2.048090                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.766170                       \n",
       "rmse_cv                                                 2.007084                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': None}  \\\n",
       "rmse_training                                           0.780420                     \n",
       "rmse_cv                                                 2.202913                     \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}  \\\n",
       "rmse_training                                           0.647580                  \n",
       "rmse_cv                                                 1.786684                  \n",
       "\n",
       "               StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \\\n",
       "rmse_training                                           2.022631                                                                                                                                                \n",
       "rmse_cv                                                 1.836144                                                                                                                                                \n",
       "\n",
       "               VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \n",
       "rmse_training                                           1.581238                                                                                                                                             \n",
       "rmse_cv                                                 1.815186                                                                                                                                             "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "result_ens = regression_ensemble(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_ens = pd.DataFrame.from_dict(result_ens)\n",
    "result_ens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ea7c2-c25e-4f49-b31d-fad91d46d77a",
   "metadata": {},
   "source": [
    "<h3> Neural Network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54417a6d-20ba-4aa8-a831-d52d4cc43b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.110997</td>\n",
       "      <td>1.540442</td>\n",
       "      <td>1.714567</td>\n",
       "      <td>1.092933</td>\n",
       "      <td>2.230803</td>\n",
       "      <td>1.796151</td>\n",
       "      <td>1.109937</td>\n",
       "      <td>1.537323</td>\n",
       "      <td>1.704259</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>1.902836</td>\n",
       "      <td>1.468405</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>2.108634</td>\n",
       "      <td>1.462730</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>1.790982</td>\n",
       "      <td>1.472237</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>1.159269</td>\n",
       "      <td>0.727872</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>1.832320</td>\n",
       "      <td>0.704637</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>1.137023</td>\n",
       "      <td>0.796294</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>1.20581</td>\n",
       "      <td>0.768564</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.739974</td>\n",
       "      <td>0.596877</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.642388</td>\n",
       "      <td>0.557992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.546353</td>\n",
       "      <td>1.954729</td>\n",
       "      <td>2.063249</td>\n",
       "      <td>2.568573</td>\n",
       "      <td>2.036573</td>\n",
       "      <td>2.024734</td>\n",
       "      <td>2.556467</td>\n",
       "      <td>1.933823</td>\n",
       "      <td>2.055150</td>\n",
       "      <td>2.188122</td>\n",
       "      <td>1.988777</td>\n",
       "      <td>1.892070</td>\n",
       "      <td>2.303547</td>\n",
       "      <td>2.014445</td>\n",
       "      <td>1.875351</td>\n",
       "      <td>2.160220</td>\n",
       "      <td>1.816630</td>\n",
       "      <td>1.882380</td>\n",
       "      <td>2.316952</td>\n",
       "      <td>1.879775</td>\n",
       "      <td>1.945397</td>\n",
       "      <td>2.302232</td>\n",
       "      <td>1.950482</td>\n",
       "      <td>1.985905</td>\n",
       "      <td>2.428734</td>\n",
       "      <td>1.847557</td>\n",
       "      <td>1.998403</td>\n",
       "      <td>2.317594</td>\n",
       "      <td>1.90734</td>\n",
       "      <td>1.841177</td>\n",
       "      <td>2.319088</td>\n",
       "      <td>1.831010</td>\n",
       "      <td>1.813912</td>\n",
       "      <td>2.063213</td>\n",
       "      <td>1.777582</td>\n",
       "      <td>1.839730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.110997                                         \n",
       "rmse_cv                                                 2.546353                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.540442                                       \n",
       "rmse_cv                                                 1.954729                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.714567                                        \n",
       "rmse_cv                                                 2.063249                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.092933                                           \n",
       "rmse_cv                                                 2.568573                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.230803                                         \n",
       "rmse_cv                                                 2.036573                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.796151                                          \n",
       "rmse_cv                                                 2.024734                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.109937                                         \n",
       "rmse_cv                                                 2.556467                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.537323                                       \n",
       "rmse_cv                                                 1.933823                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.704259                                        \n",
       "rmse_cv                                                 2.055150                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001391                                         \n",
       "rmse_cv                                                 2.188122                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.902836                                       \n",
       "rmse_cv                                                 1.988777                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.468405                                        \n",
       "rmse_cv                                                 1.892070                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.002105                                           \n",
       "rmse_cv                                                 2.303547                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.108634                                         \n",
       "rmse_cv                                                 2.014445                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.462730                                          \n",
       "rmse_cv                                                 1.875351                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000876                                         \n",
       "rmse_cv                                                 2.160220                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.790982                                       \n",
       "rmse_cv                                                 1.816630                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.472237                                        \n",
       "rmse_cv                                                 1.882380                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000514                                     \n",
       "rmse_cv                                                 2.316952                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.159269                                   \n",
       "rmse_cv                                                 1.879775                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.727872                                    \n",
       "rmse_cv                                                 1.945397                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000968                                       \n",
       "rmse_cv                                                 2.302232                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.832320                                     \n",
       "rmse_cv                                                 1.950482                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.704637                                      \n",
       "rmse_cv                                                 1.985905                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000414                                     \n",
       "rmse_cv                                                 2.428734                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.137023                                   \n",
       "rmse_cv                                                 1.847557                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.796294                                    \n",
       "rmse_cv                                                 1.998403                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000730                                     \n",
       "rmse_cv                                                 2.317594                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                            1.20581                                   \n",
       "rmse_cv                                                  1.90734                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.768564                                    \n",
       "rmse_cv                                                 1.841177                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000521                                       \n",
       "rmse_cv                                                 2.319088                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.739974                                     \n",
       "rmse_cv                                                 1.831010                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.596877                                      \n",
       "rmse_cv                                                 1.813912                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000647                                     \n",
       "rmse_cv                                                 2.063213                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.642388                                   \n",
       "rmse_cv                                                 1.777582                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}  \n",
       "rmse_training                                           0.557992                                   \n",
       "rmse_cv                                                 1.839730                                   "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "regression_neuralnetwork\n",
    "result_nn = regression_neuralnetwork(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_nn = pd.DataFrame.from_dict(result_nn)\n",
    "result_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae4cced-0774-4225-80f8-d9f4f9137f7d",
   "metadata": {},
   "source": [
    "<h3> Summary </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "406c3440-5d39-48a3-b7d9-7137086aa00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARDRegression{}</th>\n",
       "      <th>BayesianRidge{}</th>\n",
       "      <th>ElasticNet{'selection': 'cyclic'}</th>\n",
       "      <th>ElasticNet{'selection': 'random'}</th>\n",
       "      <th>HuberRegressor{}</th>\n",
       "      <th>Lars{}</th>\n",
       "      <th>Lasso{'selection': 'cyclic'}</th>\n",
       "      <th>Lasso{'selection': 'random'}</th>\n",
       "      <th>LassoLars{}</th>\n",
       "      <th>LinearRegression{}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'saga'}</th>\n",
       "      <th>OrthogonalMatchingPursuit{}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>RANSACRegressor{}</th>\n",
       "      <th>Ridge{'solver': 'svd'}</th>\n",
       "      <th>Ridge{'solver': 'cholesky'}</th>\n",
       "      <th>Ridge{'solver': 'lsqr'}</th>\n",
       "      <th>Ridge{'solver': 'sparse_cg'}</th>\n",
       "      <th>Ridge{'solver': 'sag'}</th>\n",
       "      <th>Ridge{'solver': 'saga'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>TheilSenRegressor{}</th>\n",
       "      <th>TweedieRegressor{'link': 'identity'}</th>\n",
       "      <th>TweedieRegressor{'link': 'log'}</th>\n",
       "      <th>KernelRidge 1**2</th>\n",
       "      <th>KernelRidge DotProduct(sigma_0=1)</th>\n",
       "      <th>KernelRidge ExpSineSquared(length_scale=1, periodicity=1)</th>\n",
       "      <th>KernelRidge Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>KernelRidge PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>KernelRidge RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>KernelRidge RBF(length_scale=1)</th>\n",
       "      <th>KernelRidge WhiteKernel(noise_level=1)</th>\n",
       "      <th>KernelRidge linear</th>\n",
       "      <th>LinearSVR{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>LinearSVR{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>NuSVR{'kernel': 'linear'}</th>\n",
       "      <th>NuSVR{'kernel': 'poly'}</th>\n",
       "      <th>NuSVR{'kernel': 'rbf'}</th>\n",
       "      <th>NuSVR{'kernel': 'sigmoid'}</th>\n",
       "      <th>SVR{'kernel': 'linear'}</th>\n",
       "      <th>SVR{'kernel': 'poly'}</th>\n",
       "      <th>SVR{'kernel': 'rbf'}</th>\n",
       "      <th>SVR{'kernel': 'sigmoid'}</th>\n",
       "      <th>GaussianProcessRegressor 1**2</th>\n",
       "      <th>GaussianProcessRegressor DotProduct(sigma_0=1)</th>\n",
       "      <th>GaussianProcessRegressor Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor RBF(length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor WhiteKernel(noise_level=1)</th>\n",
       "      <th>CCA{}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'nipals'}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'svd'}</th>\n",
       "      <th>PLSRegression{}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'linear'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'square'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'exponential'}</th>\n",
       "      <th>BaggingRegressor{}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>IsolationForest{}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}</th>\n",
       "      <th>StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "      <th>VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.500612</td>\n",
       "      <td>1.720985</td>\n",
       "      <td>1.807324</td>\n",
       "      <td>1.807324</td>\n",
       "      <td>1.275551</td>\n",
       "      <td>72.090142</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>0.850896</td>\n",
       "      <td>1.678414</td>\n",
       "      <td>1.728527</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.530184</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.588833</td>\n",
       "      <td>1.637964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594692</td>\n",
       "      <td>1.444080</td>\n",
       "      <td>1.485704</td>\n",
       "      <td>1.570558</td>\n",
       "      <td>2.263896</td>\n",
       "      <td>2.016098</td>\n",
       "      <td>2.396556</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>1.391946</td>\n",
       "      <td>1.390878</td>\n",
       "      <td>1.404341</td>\n",
       "      <td>1.417386</td>\n",
       "      <td>2.366189</td>\n",
       "      <td>1.302198e+14</td>\n",
       "      <td>1.545895</td>\n",
       "      <td>1.450133</td>\n",
       "      <td>1.728587</td>\n",
       "      <td>9.334734e+13</td>\n",
       "      <td>1.563265</td>\n",
       "      <td>1.476197</td>\n",
       "      <td>1.448635</td>\n",
       "      <td>1.059510</td>\n",
       "      <td>1.639399</td>\n",
       "      <td>1.524623</td>\n",
       "      <td>1.810247</td>\n",
       "      <td>1.390653</td>\n",
       "      <td>3.318812</td>\n",
       "      <td>2.023938</td>\n",
       "      <td>1.390648</td>\n",
       "      <td>1.218348</td>\n",
       "      <td>2.055960</td>\n",
       "      <td>4.136394</td>\n",
       "      <td>1.390648</td>\n",
       "      <td>1.500873</td>\n",
       "      <td>1.343088</td>\n",
       "      <td>1.476317</td>\n",
       "      <td>1.377438</td>\n",
       "      <td>1.481749</td>\n",
       "      <td>1.837184</td>\n",
       "      <td>1.496323</td>\n",
       "      <td>1.43371</td>\n",
       "      <td>1.489761</td>\n",
       "      <td>1.877357</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>0.850870</td>\n",
       "      <td>3.182825e-10</td>\n",
       "      <td>0.851026</td>\n",
       "      <td>2.213020e-10</td>\n",
       "      <td>4.607285e-10</td>\n",
       "      <td>4.136394</td>\n",
       "      <td>1.788298</td>\n",
       "      <td>4.701129</td>\n",
       "      <td>4.701129</td>\n",
       "      <td>1.586375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748394</td>\n",
       "      <td>0.752847</td>\n",
       "      <td>0.813556</td>\n",
       "      <td>0.709689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.175867</td>\n",
       "      <td>0.172554</td>\n",
       "      <td>0.782008</td>\n",
       "      <td>0.867638</td>\n",
       "      <td>0.787688</td>\n",
       "      <td>0.838049</td>\n",
       "      <td>0.336339</td>\n",
       "      <td>0.339343</td>\n",
       "      <td>0.360592</td>\n",
       "      <td>0.371980</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>2.90500</td>\n",
       "      <td>1.770743</td>\n",
       "      <td>1.843639</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>0.162377</td>\n",
       "      <td>0.163356</td>\n",
       "      <td>0.786237</td>\n",
       "      <td>0.846086</td>\n",
       "      <td>0.778843</td>\n",
       "      <td>0.979175</td>\n",
       "      <td>0.344708</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.379605</td>\n",
       "      <td>0.358401</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>2.90500</td>\n",
       "      <td>1.851697</td>\n",
       "      <td>1.636451</td>\n",
       "      <td>3.525171</td>\n",
       "      <td>0.647693</td>\n",
       "      <td>0.633147</td>\n",
       "      <td>0.625064</td>\n",
       "      <td>0.646255</td>\n",
       "      <td>0.633280</td>\n",
       "      <td>0.662081</td>\n",
       "      <td>0.659908</td>\n",
       "      <td>0.693101</td>\n",
       "      <td>0.771076</td>\n",
       "      <td>0.766170</td>\n",
       "      <td>0.780420</td>\n",
       "      <td>0.647580</td>\n",
       "      <td>2.022631</td>\n",
       "      <td>1.581238</td>\n",
       "      <td>1.110997</td>\n",
       "      <td>1.540442</td>\n",
       "      <td>1.714567</td>\n",
       "      <td>1.092933</td>\n",
       "      <td>2.230803</td>\n",
       "      <td>1.796151</td>\n",
       "      <td>1.109937</td>\n",
       "      <td>1.537323</td>\n",
       "      <td>1.704259</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>1.902836</td>\n",
       "      <td>1.468405</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>2.108634</td>\n",
       "      <td>1.462730</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>1.790982</td>\n",
       "      <td>1.472237</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>1.159269</td>\n",
       "      <td>0.727872</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>1.832320</td>\n",
       "      <td>0.704637</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>1.137023</td>\n",
       "      <td>0.796294</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>1.20581</td>\n",
       "      <td>0.768564</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>1.739974</td>\n",
       "      <td>0.596877</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>1.642388</td>\n",
       "      <td>0.557992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.936501</td>\n",
       "      <td>1.849728</td>\n",
       "      <td>1.854198</td>\n",
       "      <td>1.854204</td>\n",
       "      <td>2.580660</td>\n",
       "      <td>13222.012598</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>8.022427</td>\n",
       "      <td>1.986954</td>\n",
       "      <td>2.064786</td>\n",
       "      <td>2.362686</td>\n",
       "      <td>2.362686</td>\n",
       "      <td>2.156346</td>\n",
       "      <td>2.246902</td>\n",
       "      <td>2.246902</td>\n",
       "      <td>2.179860</td>\n",
       "      <td>2.738958</td>\n",
       "      <td>2.357410</td>\n",
       "      <td>2.554081</td>\n",
       "      <td>2.393976</td>\n",
       "      <td>1.945627</td>\n",
       "      <td>2.399318</td>\n",
       "      <td>2.471910</td>\n",
       "      <td>16.906513</td>\n",
       "      <td>2.012011</td>\n",
       "      <td>2.012011</td>\n",
       "      <td>2.009908</td>\n",
       "      <td>2.012133</td>\n",
       "      <td>2.011828</td>\n",
       "      <td>2.009079</td>\n",
       "      <td>2.407536</td>\n",
       "      <td>1.019496e+14</td>\n",
       "      <td>1.862837</td>\n",
       "      <td>1.940508</td>\n",
       "      <td>2.175050</td>\n",
       "      <td>1.153746e+14</td>\n",
       "      <td>1.895564</td>\n",
       "      <td>1.943922</td>\n",
       "      <td>1.980160</td>\n",
       "      <td>8.681994</td>\n",
       "      <td>1.851942</td>\n",
       "      <td>2.114590</td>\n",
       "      <td>1.842443</td>\n",
       "      <td>2.011974</td>\n",
       "      <td>15.776251</td>\n",
       "      <td>4.042328</td>\n",
       "      <td>2.011973</td>\n",
       "      <td>2.578366</td>\n",
       "      <td>4.083858</td>\n",
       "      <td>4.099670</td>\n",
       "      <td>2.011973</td>\n",
       "      <td>2.166390</td>\n",
       "      <td>2.052075</td>\n",
       "      <td>1.916470</td>\n",
       "      <td>1.770307</td>\n",
       "      <td>1.742634</td>\n",
       "      <td>1.851783</td>\n",
       "      <td>2.133088</td>\n",
       "      <td>1.82145</td>\n",
       "      <td>1.720149</td>\n",
       "      <td>1.933953</td>\n",
       "      <td>3.456524</td>\n",
       "      <td>8.021744</td>\n",
       "      <td>1.773059e+00</td>\n",
       "      <td>8.021249</td>\n",
       "      <td>1.705117e+00</td>\n",
       "      <td>2.039888e+00</td>\n",
       "      <td>4.099670</td>\n",
       "      <td>1.841178</td>\n",
       "      <td>4.974416</td>\n",
       "      <td>4.974416</td>\n",
       "      <td>1.890073</td>\n",
       "      <td>2.233843</td>\n",
       "      <td>2.271042</td>\n",
       "      <td>2.212846</td>\n",
       "      <td>2.183563</td>\n",
       "      <td>2.478414</td>\n",
       "      <td>2.767762</td>\n",
       "      <td>2.531771</td>\n",
       "      <td>2.25333</td>\n",
       "      <td>2.210463</td>\n",
       "      <td>2.267652</td>\n",
       "      <td>2.33212</td>\n",
       "      <td>2.106171</td>\n",
       "      <td>2.229213</td>\n",
       "      <td>2.398755</td>\n",
       "      <td>2.500572</td>\n",
       "      <td>2.412046</td>\n",
       "      <td>2.464264</td>\n",
       "      <td>2.213631</td>\n",
       "      <td>2.50611</td>\n",
       "      <td>2.181833</td>\n",
       "      <td>2.439564</td>\n",
       "      <td>2.138197</td>\n",
       "      <td>2.323329</td>\n",
       "      <td>2.685324</td>\n",
       "      <td>2.75459</td>\n",
       "      <td>2.602973</td>\n",
       "      <td>2.543508</td>\n",
       "      <td>2.540274</td>\n",
       "      <td>2.624218</td>\n",
       "      <td>2.472819</td>\n",
       "      <td>2.444517</td>\n",
       "      <td>2.495016</td>\n",
       "      <td>1.760326</td>\n",
       "      <td>1.812322</td>\n",
       "      <td>1.787383</td>\n",
       "      <td>1.822539</td>\n",
       "      <td>1.669964</td>\n",
       "      <td>1.708569</td>\n",
       "      <td>1.668885</td>\n",
       "      <td>1.678114</td>\n",
       "      <td>1.719614</td>\n",
       "      <td>1.730097</td>\n",
       "      <td>1.662910</td>\n",
       "      <td>1.701542</td>\n",
       "      <td>1.788450</td>\n",
       "      <td>1.762106</td>\n",
       "      <td>1.726689</td>\n",
       "      <td>1.718209</td>\n",
       "      <td>1.720116</td>\n",
       "      <td>1.712542</td>\n",
       "      <td>1.705946</td>\n",
       "      <td>1.727104</td>\n",
       "      <td>1.707595</td>\n",
       "      <td>1.709394</td>\n",
       "      <td>1.698285</td>\n",
       "      <td>1.704229</td>\n",
       "      <td>2.933611</td>\n",
       "      <td>2.93433</td>\n",
       "      <td>2.178177</td>\n",
       "      <td>2.108735</td>\n",
       "      <td>1.769831</td>\n",
       "      <td>1.784594</td>\n",
       "      <td>1.756995</td>\n",
       "      <td>1.734954</td>\n",
       "      <td>1.711839</td>\n",
       "      <td>1.717866</td>\n",
       "      <td>1.722055</td>\n",
       "      <td>1.767350</td>\n",
       "      <td>1.717599</td>\n",
       "      <td>1.701336</td>\n",
       "      <td>1.722730</td>\n",
       "      <td>1.741788</td>\n",
       "      <td>2.926688</td>\n",
       "      <td>2.92617</td>\n",
       "      <td>2.200880</td>\n",
       "      <td>2.151828</td>\n",
       "      <td>3.646324</td>\n",
       "      <td>1.725150</td>\n",
       "      <td>1.700438</td>\n",
       "      <td>1.694973</td>\n",
       "      <td>1.705529</td>\n",
       "      <td>1.705437</td>\n",
       "      <td>1.703849</td>\n",
       "      <td>1.725070</td>\n",
       "      <td>1.718557</td>\n",
       "      <td>2.048090</td>\n",
       "      <td>2.007084</td>\n",
       "      <td>2.202913</td>\n",
       "      <td>1.786684</td>\n",
       "      <td>1.836144</td>\n",
       "      <td>1.815186</td>\n",
       "      <td>2.546353</td>\n",
       "      <td>1.954729</td>\n",
       "      <td>2.063249</td>\n",
       "      <td>2.568573</td>\n",
       "      <td>2.036573</td>\n",
       "      <td>2.024734</td>\n",
       "      <td>2.556467</td>\n",
       "      <td>1.933823</td>\n",
       "      <td>2.055150</td>\n",
       "      <td>2.188122</td>\n",
       "      <td>1.988777</td>\n",
       "      <td>1.892070</td>\n",
       "      <td>2.303547</td>\n",
       "      <td>2.014445</td>\n",
       "      <td>1.875351</td>\n",
       "      <td>2.160220</td>\n",
       "      <td>1.816630</td>\n",
       "      <td>1.882380</td>\n",
       "      <td>2.316952</td>\n",
       "      <td>1.879775</td>\n",
       "      <td>1.945397</td>\n",
       "      <td>2.302232</td>\n",
       "      <td>1.950482</td>\n",
       "      <td>1.985905</td>\n",
       "      <td>2.428734</td>\n",
       "      <td>1.847557</td>\n",
       "      <td>1.998403</td>\n",
       "      <td>2.317594</td>\n",
       "      <td>1.90734</td>\n",
       "      <td>1.841177</td>\n",
       "      <td>2.319088</td>\n",
       "      <td>1.831010</td>\n",
       "      <td>1.813912</td>\n",
       "      <td>2.063213</td>\n",
       "      <td>1.777582</td>\n",
       "      <td>1.839730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ARDRegression{}  BayesianRidge{}  \\\n",
       "rmse_training         1.500612         1.720985   \n",
       "rmse_cv               1.936501         1.849728   \n",
       "\n",
       "               ElasticNet{'selection': 'cyclic'}  \\\n",
       "rmse_training                           1.807324   \n",
       "rmse_cv                                 1.854198   \n",
       "\n",
       "               ElasticNet{'selection': 'random'}  HuberRegressor{}  \\\n",
       "rmse_training                           1.807324          1.275551   \n",
       "rmse_cv                                 1.854204          2.580660   \n",
       "\n",
       "                     Lars{}  Lasso{'selection': 'cyclic'}  \\\n",
       "rmse_training     72.090142                      1.809692   \n",
       "rmse_cv        13222.012598                      1.844538   \n",
       "\n",
       "               Lasso{'selection': 'random'}  LassoLars{}  LinearRegression{}  \\\n",
       "rmse_training                      1.809692     1.809692            0.850896   \n",
       "rmse_cv                            1.844538     1.844538            8.022427   \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}  \\\n",
       "rmse_training                                           1.678414            \n",
       "rmse_cv                                                 1.986954            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.728527       \n",
       "rmse_cv                                                 2.064786       \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}  \\\n",
       "rmse_training                                           1.542092            \n",
       "rmse_cv                                                 2.362686            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.542092        \n",
       "rmse_cv                                                 2.362686        \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}  \\\n",
       "rmse_training                                           1.530184            \n",
       "rmse_cv                                                 2.156346            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'sag'}  \\\n",
       "rmse_training                                           1.542092      \n",
       "rmse_cv                                                 2.246902      \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.588833       \n",
       "rmse_cv                                                 2.246902       \n",
       "\n",
       "               LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}  \\\n",
       "rmse_training                                           1.637964                                \n",
       "rmse_cv                                                 2.179860                                \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}  \\\n",
       "rmse_training                                           0.000000              \n",
       "rmse_cv                                                 2.738958              \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.594692          \n",
       "rmse_cv                                                 2.357410          \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'sag'}  \\\n",
       "rmse_training                                           1.444080        \n",
       "rmse_cv                                                 2.554081        \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.485704         \n",
       "rmse_cv                                                 2.393976         \n",
       "\n",
       "               OrthogonalMatchingPursuit{}  \\\n",
       "rmse_training                     1.570558   \n",
       "rmse_cv                           1.945627   \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_training                                           2.263896           \n",
       "rmse_cv                                                 2.399318           \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_training                                           2.016098                   \n",
       "rmse_cv                                                 2.471910                   \n",
       "\n",
       "               RANSACRegressor{}  Ridge{'solver': 'svd'}  \\\n",
       "rmse_training           2.396556                1.390836   \n",
       "rmse_cv                16.906513                2.012011   \n",
       "\n",
       "               Ridge{'solver': 'cholesky'}  Ridge{'solver': 'lsqr'}  \\\n",
       "rmse_training                     1.390836                 1.391946   \n",
       "rmse_cv                           2.012011                 2.009908   \n",
       "\n",
       "               Ridge{'solver': 'sparse_cg'}  Ridge{'solver': 'sag'}  \\\n",
       "rmse_training                      1.390878                1.404341   \n",
       "rmse_cv                            2.012133                2.011828   \n",
       "\n",
       "               Ridge{'solver': 'saga'}  \\\n",
       "rmse_training                 1.417386   \n",
       "rmse_cv                       2.009079   \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}  \\\n",
       "rmse_training                                           2.366189            \n",
       "rmse_cv                                                 2.407536            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}  \\\n",
       "rmse_training                                       1.302198e+14           \n",
       "rmse_cv                                             1.019496e+14           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_training                                           1.545895              \n",
       "rmse_cv                                                 1.862837              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.450133            \n",
       "rmse_cv                                                 1.940508            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}  \\\n",
       "rmse_training                                           1.728587            \n",
       "rmse_cv                                                 2.175050            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}  \\\n",
       "rmse_training                                       9.334734e+13           \n",
       "rmse_cv                                             1.153746e+14           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_training                                           1.563265              \n",
       "rmse_cv                                                 1.895564              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.476197            \n",
       "rmse_cv                                                 1.943922            \n",
       "\n",
       "               SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.448635                    \n",
       "rmse_cv                                                 1.980160                    \n",
       "\n",
       "               TheilSenRegressor{}  TweedieRegressor{'link': 'identity'}  \\\n",
       "rmse_training             1.059510                              1.639399   \n",
       "rmse_cv                   8.681994                              1.851942   \n",
       "\n",
       "               TweedieRegressor{'link': 'log'}  KernelRidge 1**2  \\\n",
       "rmse_training                         1.524623          1.810247   \n",
       "rmse_cv                               2.114590          1.842443   \n",
       "\n",
       "               KernelRidge DotProduct(sigma_0=1)  \\\n",
       "rmse_training                           1.390653   \n",
       "rmse_cv                                 2.011974   \n",
       "\n",
       "               KernelRidge ExpSineSquared(length_scale=1, periodicity=1)  \\\n",
       "rmse_training                                           3.318812           \n",
       "rmse_cv                                                15.776251           \n",
       "\n",
       "               KernelRidge Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_training                                    2.023938   \n",
       "rmse_cv                                          4.042328   \n",
       "\n",
       "               KernelRidge PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_training                                           1.390648      \n",
       "rmse_cv                                                 2.011973      \n",
       "\n",
       "               KernelRidge RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_training                                           1.218348        \n",
       "rmse_cv                                                 2.578366        \n",
       "\n",
       "               KernelRidge RBF(length_scale=1)  \\\n",
       "rmse_training                         2.055960   \n",
       "rmse_cv                               4.083858   \n",
       "\n",
       "               KernelRidge WhiteKernel(noise_level=1)  KernelRidge linear  \\\n",
       "rmse_training                                4.136394            1.390648   \n",
       "rmse_cv                                      4.099670            2.011973   \n",
       "\n",
       "               LinearSVR{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_training                                  1.500873   \n",
       "rmse_cv                                        2.166390   \n",
       "\n",
       "               LinearSVR{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_training                                          1.343088   \n",
       "rmse_cv                                                2.052075   \n",
       "\n",
       "               NuSVR{'kernel': 'linear'}  NuSVR{'kernel': 'poly'}  \\\n",
       "rmse_training                   1.476317                 1.377438   \n",
       "rmse_cv                         1.916470                 1.770307   \n",
       "\n",
       "               NuSVR{'kernel': 'rbf'}  NuSVR{'kernel': 'sigmoid'}  \\\n",
       "rmse_training                1.481749                    1.837184   \n",
       "rmse_cv                      1.742634                    1.851783   \n",
       "\n",
       "               SVR{'kernel': 'linear'}  SVR{'kernel': 'poly'}  \\\n",
       "rmse_training                 1.496323                1.43371   \n",
       "rmse_cv                       2.133088                1.82145   \n",
       "\n",
       "               SVR{'kernel': 'rbf'}  SVR{'kernel': 'sigmoid'}  \\\n",
       "rmse_training              1.489761                  1.877357   \n",
       "rmse_cv                    1.720149                  1.933953   \n",
       "\n",
       "               GaussianProcessRegressor 1**2  \\\n",
       "rmse_training                       1.809692   \n",
       "rmse_cv                             3.456524   \n",
       "\n",
       "               GaussianProcessRegressor DotProduct(sigma_0=1)  \\\n",
       "rmse_training                                        0.850870   \n",
       "rmse_cv                                              8.021744   \n",
       "\n",
       "               GaussianProcessRegressor Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_training                                       3.182825e-10         \n",
       "rmse_cv                                             1.773059e+00         \n",
       "\n",
       "               GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_training                                           0.851026                   \n",
       "rmse_cv                                                 8.021249                   \n",
       "\n",
       "               GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_training                                       2.213020e-10                     \n",
       "rmse_cv                                             1.705117e+00                     \n",
       "\n",
       "               GaussianProcessRegressor RBF(length_scale=1)  \\\n",
       "rmse_training                                  4.607285e-10   \n",
       "rmse_cv                                        2.039888e+00   \n",
       "\n",
       "               GaussianProcessRegressor WhiteKernel(noise_level=1)     CCA{}  \\\n",
       "rmse_training                                           4.136394    1.788298   \n",
       "rmse_cv                                                 4.099670    1.841178   \n",
       "\n",
       "               PLSCanonical{'algorithm': 'nipals'}  \\\n",
       "rmse_training                             4.701129   \n",
       "rmse_cv                                   4.974416   \n",
       "\n",
       "               PLSCanonical{'algorithm': 'svd'}  PLSRegression{}  \\\n",
       "rmse_training                          4.701129         1.586375   \n",
       "rmse_cv                                4.974416         1.890073   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                      \n",
       "rmse_cv                                                 2.233843                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.271042                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.212846                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.183563                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.478414                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.767762                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.531771                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                            0.00000                                          \n",
       "rmse_cv                                                  2.25333                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                               \n",
       "rmse_cv                                                 2.210463                                               \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.267652                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                            0.00000                                                 \n",
       "rmse_cv                                                  2.33212                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.106171                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.229213                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.398755                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.500572                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.412046                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                      \n",
       "rmse_cv                                                 2.464264                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.213631                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                            0.00000                                        \n",
       "rmse_cv                                                  2.50611                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.181833                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.439564                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.138197                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.323329                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.685324                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                            0.00000                                          \n",
       "rmse_cv                                                  2.75459                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.602973                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.543508                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.540274                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.624218                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.472819                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.444517                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.495016                                              \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'linear'}  \\\n",
       "rmse_training                             0.748394   \n",
       "rmse_cv                                   1.760326   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'square'}  \\\n",
       "rmse_training                             0.752847   \n",
       "rmse_cv                                   1.812322   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'exponential'}  BaggingRegressor{}  \\\n",
       "rmse_training                                  0.813556            0.709689   \n",
       "rmse_cv                                        1.787383            1.822539   \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.669964                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.708569                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.668885                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.678114                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000               \n",
       "rmse_cv                                                 1.719614               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000               \n",
       "rmse_cv                                                 1.730097               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_training                                           0.023599            \n",
       "rmse_cv                                                 1.662910            \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_training                                           0.000000            \n",
       "rmse_cv                                                 1.701542            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_training                                           0.117268                                            \n",
       "rmse_cv                                                 1.788450                                            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.117268                                              \n",
       "rmse_cv                                                 1.762106                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.175867                                              \n",
       "rmse_cv                                                 1.726689                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.172554                                              \n",
       "rmse_cv                                                 1.718209                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_training                                           0.782008                                             \n",
       "rmse_cv                                                 1.720116                                             \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.867638                                               \n",
       "rmse_cv                                                 1.712542                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.787688                                               \n",
       "rmse_cv                                                 1.705946                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.838049                                               \n",
       "rmse_cv                                                 1.727104                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_training                                           0.336339                                               \n",
       "rmse_cv                                                 1.707595                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.339343                                                 \n",
       "rmse_cv                                                 1.709394                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.360592                                                 \n",
       "rmse_cv                                                 1.698285                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.371980                                                 \n",
       "rmse_cv                                                 1.704229                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_training                                           2.905000                                                  \n",
       "rmse_cv                                                 2.933611                                                  \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_training                                            2.90500                                                    \n",
       "rmse_cv                                                  2.93433                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           1.770743                                                    \n",
       "rmse_cv                                                 2.178177                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           1.843639                                                    \n",
       "rmse_cv                                                 2.108735                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_training                                           0.117268                                   \n",
       "rmse_cv                                                 1.769831                                   \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.119379                                     \n",
       "rmse_cv                                                 1.784594                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.162377                                     \n",
       "rmse_cv                                                 1.756995                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.163356                                     \n",
       "rmse_cv                                                 1.734954                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_training                                           0.786237                                    \n",
       "rmse_cv                                                 1.711839                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.846086                                      \n",
       "rmse_cv                                                 1.717866                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.778843                                      \n",
       "rmse_cv                                                 1.722055                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.979175                                      \n",
       "rmse_cv                                                 1.767350                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_training                                           0.344708                                      \n",
       "rmse_cv                                                 1.717599                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.344400                                        \n",
       "rmse_cv                                                 1.701336                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.379605                                        \n",
       "rmse_cv                                                 1.722730                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.358401                                        \n",
       "rmse_cv                                                 1.741788                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_training                                           2.905000                                         \n",
       "rmse_cv                                                 2.926688                                         \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_training                                            2.90500                                           \n",
       "rmse_cv                                                  2.92617                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           1.851697                                           \n",
       "rmse_cv                                                 2.200880                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           1.636451                                           \n",
       "rmse_cv                                                 2.151828                                           \n",
       "\n",
       "               IsolationForest{}  \\\n",
       "rmse_training           3.525171   \n",
       "rmse_cv                 3.646324   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.647693                   \n",
       "rmse_cv                                                 1.725150                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.633147                   \n",
       "rmse_cv                                                 1.700438                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_training                                           0.625064                 \n",
       "rmse_cv                                                 1.694973                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_training                                           0.646255              \n",
       "rmse_cv                                                 1.705529              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.633280                   \n",
       "rmse_cv                                                 1.705437                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.662081                   \n",
       "rmse_cv                                                 1.703849                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_training                                           0.659908                 \n",
       "rmse_cv                                                 1.725070                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_training                                           0.693101              \n",
       "rmse_cv                                                 1.718557              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.771076                       \n",
       "rmse_cv                                                 2.048090                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.766170                       \n",
       "rmse_cv                                                 2.007084                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': None}  \\\n",
       "rmse_training                                           0.780420                     \n",
       "rmse_cv                                                 2.202913                     \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}  \\\n",
       "rmse_training                                           0.647580                  \n",
       "rmse_cv                                                 1.786684                  \n",
       "\n",
       "               StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \\\n",
       "rmse_training                                           2.022631                                                                                                                                                \n",
       "rmse_cv                                                 1.836144                                                                                                                                                \n",
       "\n",
       "               VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \\\n",
       "rmse_training                                           1.581238                                                                                                                                              \n",
       "rmse_cv                                                 1.815186                                                                                                                                              \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.110997                                         \n",
       "rmse_cv                                                 2.546353                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.540442                                       \n",
       "rmse_cv                                                 1.954729                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.714567                                        \n",
       "rmse_cv                                                 2.063249                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.092933                                           \n",
       "rmse_cv                                                 2.568573                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.230803                                         \n",
       "rmse_cv                                                 2.036573                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.796151                                          \n",
       "rmse_cv                                                 2.024734                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.109937                                         \n",
       "rmse_cv                                                 2.556467                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.537323                                       \n",
       "rmse_cv                                                 1.933823                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.704259                                        \n",
       "rmse_cv                                                 2.055150                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001391                                         \n",
       "rmse_cv                                                 2.188122                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.902836                                       \n",
       "rmse_cv                                                 1.988777                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.468405                                        \n",
       "rmse_cv                                                 1.892070                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.002105                                           \n",
       "rmse_cv                                                 2.303547                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.108634                                         \n",
       "rmse_cv                                                 2.014445                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.462730                                          \n",
       "rmse_cv                                                 1.875351                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000876                                         \n",
       "rmse_cv                                                 2.160220                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.790982                                       \n",
       "rmse_cv                                                 1.816630                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.472237                                        \n",
       "rmse_cv                                                 1.882380                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000514                                     \n",
       "rmse_cv                                                 2.316952                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.159269                                   \n",
       "rmse_cv                                                 1.879775                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.727872                                    \n",
       "rmse_cv                                                 1.945397                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000968                                       \n",
       "rmse_cv                                                 2.302232                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.832320                                     \n",
       "rmse_cv                                                 1.950482                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.704637                                      \n",
       "rmse_cv                                                 1.985905                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000414                                     \n",
       "rmse_cv                                                 2.428734                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.137023                                   \n",
       "rmse_cv                                                 1.847557                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.796294                                    \n",
       "rmse_cv                                                 1.998403                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000730                                     \n",
       "rmse_cv                                                 2.317594                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                            1.20581                                   \n",
       "rmse_cv                                                  1.90734                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.768564                                    \n",
       "rmse_cv                                                 1.841177                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000521                                       \n",
       "rmse_cv                                                 2.319088                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.739974                                     \n",
       "rmse_cv                                                 1.831010                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.596877                                      \n",
       "rmse_cv                                                 1.813912                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000647                                     \n",
       "rmse_cv                                                 2.063213                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.642388                                   \n",
       "rmse_cv                                                 1.777582                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}  \n",
       "rmse_training                                           0.557992                                   \n",
       "rmse_cv                                                 1.839730                                   "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "result = pd.concat([result_lm, result_kr, result_svm, result_gpr, result_cd, result_tree, result_ens, result_nn] , axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90ab06-9b00-400d-9ade-b57d59efdc15",
   "metadata": {},
   "source": [
    "Somehow we have to decide to continue working with a few models. The models aren't good at the moment. Some of them overfits (cv error is high, training error low), when others underfit (validation and training error high) data. In fact, we don't want to prevent underfitting yet. To do it we should select model with more parameters (we've tested a lot of models), find better features (we've done some attribute combinations) or reduce regularization hyperparameter, what is harder than try to prevent overfitting in other models. At first, we will prevent oferfitting by reducing the number of attributes in the training data for a few models with best rmse_cv result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d5833df-b5a8-4029-a8eb-f7ba7f5cbceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}                                         1.662910\n",
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}                                    1.668885\n",
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}                                    1.669964\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}                                    1.678114\n",
       "RandomForestRegressor{'criterion': 'mse', 'max_features': None}                                    1.694973\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}    1.698285\n",
       "RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}                                  1.700438\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}             1.701336\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}                                         1.701542\n",
       "RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}                                  1.703849\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}    1.704229\n",
       "GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)                                1.705117\n",
       "RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}                                  1.705437\n",
       "RandomForestRegressor{'criterion': 'mse', 'max_features': 1}                                       1.705529\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}      1.705946\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}      1.707595\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}                                    1.708569\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}    1.709394\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}                 1.711839\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}      1.712542\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}               1.717599\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}               1.717866\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}       1.718209\n",
       "RandomForestRegressor{'criterion': 'mae', 'max_features': 1}                                       1.718557\n",
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}                                      1.719614\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}        1.720116\n",
       "SVR{'kernel': 'rbf'}                                                                               1.720149\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}               1.722055\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}             1.722730\n",
       "RandomForestRegressor{'criterion': 'mae', 'max_features': None}                                    1.725070\n",
       "Name: rmse_cv, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc['rmse_cv'].sort_values().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06bd93-bb00-49f9-9ee3-57211bce6753",
   "metadata": {},
   "source": [
    "Assuming our approach, let's prevent overfitting for GradientBoostingRegressor, ExtraTreesRegressor and RandomForestRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6090d451-7c25-44b3-990d-bbf415fb822b",
   "metadata": {},
   "source": [
    "<h2> Fine-tuning </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f5c3d-782e-48aa-afad-92c8277fadb1",
   "metadata": {},
   "source": [
    "<h3> GradientBoostingRegressor </h3>\n",
    "<h4> Feature Selection </h4>\n",
    "\n",
    "I've tested GradientBoosting from sklearn and from xgboost and preformance of model from xgboost module was much better, so I'will use XGBRegressor for better performance, even though tuning'll be more difficult.\n",
    "\n",
    "At first, I will find importance of each feature for the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3143e891-52a4-498f-a607-993763168568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.06029\n",
      "Feature: 1, Score: 0.02061\n",
      "Feature: 2, Score: 0.00414\n",
      "Feature: 3, Score: 0.00146\n",
      "Feature: 4, Score: 0.00931\n",
      "Feature: 5, Score: 0.00120\n",
      "Feature: 6, Score: 0.00188\n",
      "Feature: 7, Score: 0.04344\n",
      "Feature: 8, Score: 0.00167\n",
      "Feature: 9, Score: 0.01399\n",
      "Feature: 10, Score: 0.00176\n",
      "Feature: 11, Score: 0.00054\n",
      "Feature: 12, Score: 0.01152\n",
      "Feature: 13, Score: 0.00095\n",
      "Feature: 14, Score: 0.00169\n",
      "Feature: 15, Score: 0.05705\n",
      "Feature: 16, Score: 0.00108\n",
      "Feature: 17, Score: 0.00100\n",
      "Feature: 18, Score: 0.01185\n",
      "Feature: 19, Score: 0.01773\n",
      "Feature: 20, Score: 0.00560\n",
      "Feature: 21, Score: 0.00045\n",
      "Feature: 22, Score: 0.02307\n",
      "Feature: 23, Score: 0.00156\n",
      "Feature: 24, Score: 0.02694\n",
      "Feature: 25, Score: 0.00000\n",
      "Feature: 26, Score: 0.00001\n",
      "Feature: 27, Score: 0.02445\n",
      "Feature: 28, Score: 0.05424\n",
      "Feature: 29, Score: 0.00049\n",
      "Feature: 30, Score: 0.00146\n",
      "Feature: 31, Score: 0.02624\n",
      "Feature: 32, Score: 0.00004\n",
      "Feature: 33, Score: 0.01105\n",
      "Feature: 34, Score: 0.00013\n",
      "Feature: 35, Score: 0.00065\n",
      "Feature: 36, Score: 0.00924\n",
      "Feature: 37, Score: 0.00930\n",
      "Feature: 38, Score: 0.11161\n",
      "Feature: 39, Score: 0.00087\n",
      "Feature: 40, Score: 0.00293\n",
      "Feature: 41, Score: 0.01623\n",
      "Feature: 42, Score: 0.08160\n",
      "Feature: 43, Score: 0.00012\n",
      "Feature: 44, Score: 0.00068\n",
      "Feature: 45, Score: 0.00000\n",
      "Feature: 46, Score: 0.02383\n",
      "Feature: 47, Score: 0.28497\n",
      "Feature: 48, Score: 0.00000\n",
      "Feature: 49, Score: 0.00000\n",
      "Feature: 50, Score: 0.00000\n",
      "Feature: 51, Score: 0.00000\n",
      "Feature: 52, Score: 0.00000\n",
      "Feature: 53, Score: 0.00000\n",
      "Feature: 54, Score: 0.01909\n",
      "Feature: 55, Score: 0.00000\n",
      "Feature: 56, Score: 0.00000\n",
      "Feature: 57, Score: 0.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This part of code is from machinelearningmastery.com\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost\n",
    "\n",
    "X, y = train_set_new_ready, train_set_labels\n",
    "\n",
    "model = XGBRegressor()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "importance = model.feature_importances_\n",
    "\n",
    "gbr_importance = []\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    gbr_importance.append(v)\n",
    "    \n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155ad62b-503f-4c9c-acd1-3c429ac856bd",
   "metadata": {},
   "source": [
    "Let's choose the feature, which has best importance and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "61aa158e-0a0b-476a-aa83-3c1c18265e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8053254102355303\n",
      "1.708771909207174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([47], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_features = np.argsort(gbr_importance)[-1:]\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(X[:,gbr_features], y)\n",
    "predictions = model.predict(X[:,gbr_features])\n",
    "train_mse = mean_squared_error(predictions, y)\n",
    "rmse_training = np.sqrt(train_mse)\n",
    "print(rmse_training)\n",
    "\n",
    "scores = cross_val_score(model, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                              scoring=\"neg_mean_squared_error\", cv=4)\n",
    "\n",
    "rmse_cv = np.sqrt(-scores).mean()\n",
    "print(rmse_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e0863-fd8c-4d60-8987-26a8acf18065",
   "metadata": {},
   "source": [
    "As we can see, now model is underfitting. Let's add one more feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "21159275-95c9-4797-9643-251e6966be74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08084225097899564\n",
      "1.708771909207174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([38, 47], dtype=int64)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_features = np.argsort(gbr_importance)[-2:]\n",
    "\n",
    "model = XGBRegressor()\n",
    "model.fit(X[:,gbr_features], y)\n",
    "predictions = model.predict(X[:,gbr_features])\n",
    "train_mse = mean_squared_error(predictions, y)\n",
    "rmse_training = np.sqrt(train_mse)\n",
    "print(rmse_training)\n",
    "\n",
    "scores = cross_val_score(model, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                              scoring=\"neg_mean_squared_error\", cv=4)\n",
    "\n",
    "rmse_cv = np.sqrt(-scores).mean()\n",
    "print(rmse_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb7efa-cb66-4b5f-a33f-eab0e7d12d56",
   "metadata": {},
   "source": [
    "This time, model is overfitting. Now, let's do a grid search for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe45221-6eef-4ea5-adab-858b11e5f333",
   "metadata": {},
   "source": [
    "<h4> Randomized Search </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e781076-9bc9-456a-bd1b-b4f3807f7847",
   "metadata": {},
   "source": [
    "min_samples_split\n",
    "Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.\n",
    "Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "min_samples_leaf\n",
    "Defines the minimum samples (or observations) required in a terminal node or leaf.\n",
    "Used to control over-fitting similar to min_samples_split.\n",
    "Generally lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in majority will be very small.\n",
    "min_weight_fraction_leaf\n",
    "Similar to min_samples_leaf but defined as a fraction of the total number of observations instead of an integer.\n",
    "Only one of #2 and #3 should be defined.\n",
    "max_depth\n",
    "The maximum depth of a tree.\n",
    "Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "Should be tuned using CV.\n",
    "max_leaf_nodes\n",
    "The maximum number of terminal nodes or leaves in a tree.\n",
    "Can be defined in place of max_depth. Since binary trees are created, a depth of n would produce a maximum of 2^n leaves.\n",
    "If this is defined, GBM will ignore max_depth.\n",
    "max_features\n",
    "The number of features to consider while searching for a best split. These will be randomly selected.\n",
    "As a thumb-rule, square root of the total number of features works great but we should check upto 30-40% of the total number of features.\n",
    "Higher values can lead to over-fitting but depends on case to case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1ed0783c-8356-40d5-8f54-b0766e852604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38, 47], dtype=int64)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "\n",
    "# distributions = { 'n_estimators': randint(3,9),\n",
    "#                   'learning_rate': uniform(loc=0.01, scale=0.55),\n",
    "#                   'tree_method': [None, 'exact', 'approx', 'hist'],\n",
    "#                   'booster': [None, 'gbtree', 'gblinear', 'dart'],\n",
    "#                   'gamma': uniform(loc=0.01, scale=1.2),\n",
    "#                   'grow_policy': [None, 'depthwise', 'lossguide'],\n",
    "#                   'n_jobs': randint(1,9),\n",
    "#                   'min_child_weight': uniform(loc=0.01, scale=0.65),\n",
    "#                   'colsample_bytree': uniform(loc=0.3, scale=0.7),\n",
    "#                   'colsample_bylevel': uniform(loc=0.3, scale=0.7),\n",
    "#                   'colsample_bynode': uniform(loc=0.2, scale=0.7),\n",
    "#                   'reg_alpha': uniform(loc=0.1, scale=3)\n",
    "                 \n",
    "#                 }\n",
    "\n",
    "distributions = { 'learning_rate':[0.1], # typowo 0.1 moze byc generalnie z przedzialu 0.05-0.2 \n",
    "                  'n_estimators': randint(20,21), # typowo jest 40-70\n",
    "                  'max_depth': [5], # typowo jest 5-8\n",
    "                  'subsample': [0.8], # 0.8 is commonly used\n",
    "                }\n",
    "\n",
    "\n",
    "gbr_features = np.argsort(gbr_importance)[-2:]\n",
    "\n",
    "model = XGBRegressor()\n",
    "reg = RandomizedSearchCV(model, distributions, n_iter=2, random_state=42)\n",
    "\n",
    "reg.fit(X[:,gbr_features], y)\n",
    "\n",
    "predictions = reg.predict(X[:,gbr_features])\n",
    "train_mse = mean_squared_error(predictions, y)\n",
    "rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                              scoring=\"neg_mean_squared_error\", cv=4)\n",
    "\n",
    "rmse_cv = np.sqrt(-scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9392e6bb-ef6c-4d0a-978e-d60818ed5b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 20, 'subsample': 0.8}\n",
      "1.3541963580952017\n",
      "1.7473603230135484\n"
     ]
    }
   ],
   "source": [
    "print(reg.best_params_)\n",
    "print(rmse_training)\n",
    "print(rmse_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2e45bb18-221e-4399-a8db-d767ca32fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.67833\n",
      "Feature: 1, Score: 0.32167\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = reg.best_estimator_.feature_importances_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efb7d4d-ba2b-46ed-b306-f279d888f569",
   "metadata": {},
   "source": [
    "We can see, features get more importance, so let's test our model with more features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae9c9b-894b-449e-a3d3-b6888ff61b18",
   "metadata": {},
   "source": [
    "<h4> 3 features </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eaadd3c8-3089-4d87-80aa-7abae7411cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42, 38, 47], dtype=int64)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_features = np.argsort(gbr_importance)[-3:]\n",
    "\n",
    "distributions = { 'learning_rate':[0.1], # typowo 0.1 moze byc generalnie z przedzialu 0.05-0.2 \n",
    "                  'n_estimators': randint(20,21), # typowo jest 40-70\n",
    "                  'max_depth': [5], # typowo jest 5-8\n",
    "                  'subsample': [0.8], # 0.8 is commonly used\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = XGBRegressor()\n",
    "reg = RandomizedSearchCV(model, distributions, n_iter=2, random_state=42)\n",
    "\n",
    "reg.fit(X[:,gbr_features], y)\n",
    "\n",
    "predictions = reg.predict(X[:,gbr_features])\n",
    "train_mse = mean_squared_error(predictions, y)\n",
    "rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                              scoring=\"neg_mean_squared_error\", cv=4)\n",
    "\n",
    "rmse_cv = np.sqrt(-scores).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e32deb78-4492-438e-9a1f-984f193d64ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 20, 'subsample': 0.8}\n",
      "1.1590957727835844\n",
      "1.7473603230135484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([42, 38, 47], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reg.best_params_)\n",
    "print(rmse_training)\n",
    "print(rmse_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "346b9b00-c9c4-42e9-a501-721431fe8be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.35991\n",
      "Feature: 1, Score: 0.64009\n",
      "Feature: 2, Score: 0.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = reg.best_estimator_.feature_importances_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b2824-3342-4f66-b777-111a60e81f6f",
   "metadata": {},
   "source": [
    "<h4> 4 features </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d58b82be-45c3-490b-a94e-0122d835c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_features = np.argsort(gbr_importance)[-4:]\n",
    "\n",
    "distributions = { 'learning_rate':[0.1], # typowo 0.1 moze byc generalnie z przedzialu 0.05-0.2 \n",
    "                  'n_estimators': randint(20,21), # typowo jest 40-70\n",
    "                  'max_depth': [5], # typowo jest 5-8\n",
    "                  'subsample': [0.8], # 0.8 is commonly used\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = XGBRegressor()\n",
    "reg = RandomizedSearchCV(model, distributions, n_iter=2, random_state=42)\n",
    "\n",
    "reg.fit(X[:,gbr_features], y)\n",
    "\n",
    "predictions = reg.predict(X[:,gbr_features])\n",
    "train_mse = mean_squared_error(predictions, y)\n",
    "rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                              scoring=\"neg_mean_squared_error\", cv=4)\n",
    "\n",
    "rmse_cv = np.sqrt(-scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7bff13be-090b-4a61-8262-bf9bf1d27d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 20, 'subsample': 0.8}\n",
      "0.9579228378415066\n",
      "1.7473603230135484\n"
     ]
    }
   ],
   "source": [
    "print(reg.best_params_)\n",
    "print(rmse_training)\n",
    "print(rmse_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "509c9b7e-8c1f-4d74-8528-cad2a56eb735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.41099\n",
      "Feature: 1, Score: 0.21903\n",
      "Feature: 2, Score: 0.26392\n",
      "Feature: 3, Score: 0.10606\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = reg.best_estimator_.feature_importances_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208b8f1-e6f1-44e2-b6d1-7283aa34475e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a939c0-5603-43e2-bfb9-f46fb9d7beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mozliwe ze trzeba zaczac od wszystkich ficzerow ???? i dodawac tak jak w poradniku...\n",
    "Mozliwe ze trzeba zaczac od wszystkich ficzerow ???? i dodawac tak jak w poradniku...\n",
    "Mozliwe ze trzeba zaczac od wszystkich ficzerow ???? i dodawac tak jak w poradniku...\n",
    "Mozliwe ze trzeba zaczac od wszystkich ficzerow ???? i dodawac tak jak w poradniku...\n",
    "Mozliwe ze trzeba zaczac od wszystkich ficzerow ???? i dodawac tak jak w poradniku...\n",
    "Mozliwe ze trzeba zaczac od wszystkich ficzerow ???? i dodawac tak jak w poradniku...\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "LECIMY Z TEGO LINKUUUUUUUUUUUUUUUU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ef7a4-2fa9-4746-ba2c-c2b194381d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e05f2-769c-41bf-869e-0837477aae5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81028891-d68e-4478-982a-ffd2a4921e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d94f77-ae85-4579-b7fe-527d0f4fa8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f96d43f9-2ced-45b8-8767-cbfd40f9210a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gbr_importance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_32476/3879337693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgbr_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbr_importance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m distributions = { 'learning_rate':[0.1], # 0.1 is a good value to start with, generally use sth in 0.05-0.3\n\u001b[0;32m      4\u001b[0m                   \u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# typowo jest 40-70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# 5-8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gbr_importance' is not defined"
     ]
    }
   ],
   "source": [
    "gbr_features = np.argsort(gbr_importance)[:]\n",
    "\n",
    "distributions = { 'learning_rate':[0.1], # 0.1 is a good value to start with, generally use sth in 0.05-0.3\n",
    "                  'n_estimators': [33], # typowo jest 40-70\n",
    "                  'max_depth': [5], # 5-8\n",
    "                  'min_child_weight': [1], # dataset is very small\n",
    "                  'gamma': [0], # good value to start is 0, also in 0.1 to 0.2\n",
    "                  'subsample': [0.8], # value to start should be in 0.5-0.9\n",
    "                  'colsample_bytree': [0.8], # value to start should be in 0.5-0.9\n",
    "                 \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = XGBRegressor()\n",
    "reg = RandomizedSearchCV(model, distributions, n_iter=61, random_state=42)\n",
    "\n",
    "reg.fit(X[:,gbr_features], y)\n",
    "\n",
    "predictions = reg.predict(X[:,gbr_features])\n",
    "train_mse = mean_squared_error(predictions, y)\n",
    "rmse_training = np.sqrt(train_mse)\n",
    "\n",
    "scores = cross_val_score(reg, train_set_new_ready, np.ravel(train_set_labels),\n",
    "                              scoring=\"neg_mean_squared_error\", cv=4)\n",
    "\n",
    "rmse_cv = np.sqrt(-scores).mean()\n",
    "\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "919b61ec-edc2-4c82-9081-798623e7a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 33, 'subsample': 0.8}\n",
      "0.40678075938484787\n",
      "1.6578379026849261\n"
     ]
    }
   ],
   "source": [
    "print(reg.best_params_)\n",
    "print(rmse_training)\n",
    "print(rmse_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1cfac5c3-c302-4400-8a51-9a931bd147d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00175\n",
      "Feature: 1, Score: 0.00083\n",
      "Feature: 2, Score: 0.01962\n",
      "Feature: 3, Score: 0.00199\n",
      "Feature: 4, Score: 0.00219\n",
      "Feature: 5, Score: 0.00009\n",
      "Feature: 6, Score: 0.00179\n",
      "Feature: 7, Score: 0.00100\n",
      "Feature: 8, Score: 0.01574\n",
      "Feature: 9, Score: 0.00000\n",
      "Feature: 10, Score: 0.00367\n",
      "Feature: 11, Score: 0.00298\n",
      "Feature: 12, Score: 0.00558\n",
      "Feature: 13, Score: 0.00736\n",
      "Feature: 14, Score: 0.00377\n",
      "Feature: 15, Score: 0.03381\n",
      "Feature: 16, Score: 0.01115\n",
      "Feature: 17, Score: 0.00616\n",
      "Feature: 18, Score: 0.00517\n",
      "Feature: 19, Score: 0.01327\n",
      "Feature: 20, Score: 0.01914\n",
      "Feature: 21, Score: 0.02657\n",
      "Feature: 22, Score: 0.00299\n",
      "Feature: 23, Score: 0.01162\n",
      "Feature: 24, Score: 0.02494\n",
      "Feature: 25, Score: 0.01049\n",
      "Feature: 26, Score: 0.00569\n",
      "Feature: 27, Score: 0.00572\n",
      "Feature: 28, Score: 0.00000\n",
      "Feature: 29, Score: 0.00880\n",
      "Feature: 30, Score: 0.01126\n",
      "Feature: 31, Score: 0.01830\n",
      "Feature: 32, Score: 0.00669\n",
      "Feature: 33, Score: 0.00000\n",
      "Feature: 34, Score: 0.02322\n",
      "Feature: 35, Score: 0.01537\n",
      "Feature: 36, Score: 0.02609\n",
      "Feature: 37, Score: 0.00850\n",
      "Feature: 38, Score: 0.02668\n",
      "Feature: 39, Score: 0.00896\n",
      "Feature: 40, Score: 0.01156\n",
      "Feature: 41, Score: 0.01374\n",
      "Feature: 42, Score: 0.04634\n",
      "Feature: 43, Score: 0.01283\n",
      "Feature: 44, Score: 0.00000\n",
      "Feature: 45, Score: 0.07114\n",
      "Feature: 46, Score: 0.02446\n",
      "Feature: 47, Score: 0.01628\n",
      "Feature: 48, Score: 0.02039\n",
      "Feature: 49, Score: 0.01136\n",
      "Feature: 50, Score: 0.01398\n",
      "Feature: 51, Score: 0.03417\n",
      "Feature: 52, Score: 0.02804\n",
      "Feature: 53, Score: 0.07042\n",
      "Feature: 54, Score: 0.09212\n",
      "Feature: 55, Score: 0.04905\n",
      "Feature: 56, Score: 0.03840\n",
      "Feature: 57, Score: 0.04676\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = reg.best_estimator_.feature_importances_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b69c4c-dd4e-41bd-9517-46a5bb32be94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81bdb0a5-cd52-41ae-a966-4811d06d034d",
   "metadata": {},
   "source": [
    "<h2> Bibliography </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e310bd-c01d-45e9-a0a3-ec6769cbddeb",
   "metadata": {},
   "source": [
    "https://medium.com/@outside2SDs/an-overview-of-correlation-measures-between-categorical-and-continuous-variables-4c7f85610365\n",
    "\n",
    "https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "https://stats.stackexchange.com/questions/187335/validation-error-less-than-training-error\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/05/feature-transformations-in-data-science-a-detailed-walkthrough/\n",
    "\n",
    "https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb23ef3-786d-4a82-a410-84eee2c9e1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
