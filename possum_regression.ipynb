{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Possum Regression </h1>\n",
    "https://www.kaggle.com/datasets/abrambeyer/openintro-possum?datasetId=1534513&sortBy=voteCount\n",
    "<h2> Introduction </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An objective of this work is to consolidate and use part of the knowledge gained from the book \"Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow\".\n",
    "\n",
    "Our goal is to predict the age of given possum. The problem is supervised and multiple regression type. I will use batch learning, because there is no particular need to adjust to changing data rapidly, the dataset is small and there is no continous stream of data coming.\n",
    "\n",
    "Root Mean Square Error (RMSE) as a performance measure is a common cost function in regression tasks, so that will be our choice."
   ]
  },
  {
   "attachments": {
    "bd767c60-3101-48d6-850a-808976ce6450.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:bd767c60-3101-48d6-850a-808976ce6450.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Libraries and settings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "from scipy.stats import wasserstein_distance\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "%run ml_functions.ipynb\n",
    "%run custom_transformers.ipynb\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from IPython.display import Audio\n",
    "sound_file = './sound/short_sound.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load the data <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/possum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Take a quick look </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>site</th>\n",
       "      <th>Pop</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>m</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94.1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>54.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>57.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>52.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.5</td>\n",
       "      <td>56.3</td>\n",
       "      <td>85.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case  site  Pop sex  age  hdlngth  skullw  totlngth  taill  footlgth  \\\n",
       "0     1     1  Vic   m  8.0     94.1    60.4      89.0   36.0      74.5   \n",
       "1     2     1  Vic   f  6.0     92.5    57.6      91.5   36.5      72.5   \n",
       "2     3     1  Vic   f  6.0     94.0    60.0      95.5   39.0      75.4   \n",
       "3     4     1  Vic   f  6.0     93.2    57.1      92.0   38.0      76.1   \n",
       "4     5     1  Vic   f  2.0     91.5    56.3      85.5   36.0      71.0   \n",
       "\n",
       "   earconch   eye  chest  belly  \n",
       "0      54.5  15.2   28.0   36.0  \n",
       "1      51.2  16.0   28.5   33.0  \n",
       "2      51.9  15.5   30.0   34.0  \n",
       "3      52.2  15.2   28.0   34.0  \n",
       "4      53.2  15.1   28.5   33.0  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case', 'site', 'Pop', 'sex', 'age', 'hdlngth', 'skullw', 'totlngth',\n",
       "       'taill', 'footlgth', 'earconch', 'eye', 'chest', 'belly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 14)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 14 attributes including one dependent variable - 'age' and 104 instances. It means the dataset is very small by ML standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 14 columns):\n",
      "case        104 non-null int64\n",
      "site        104 non-null int64\n",
      "Pop         104 non-null object\n",
      "sex         104 non-null object\n",
      "age         102 non-null float64\n",
      "hdlngth     104 non-null float64\n",
      "skullw      104 non-null float64\n",
      "totlngth    104 non-null float64\n",
      "taill       104 non-null float64\n",
      "footlgth    103 non-null float64\n",
      "earconch    104 non-null float64\n",
      "eye         104 non-null float64\n",
      "chest       104 non-null float64\n",
      "belly       104 non-null float64\n",
      "dtypes: float64(10), int64(2), object(2)\n",
      "memory usage: 11.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Some at first glance data cleaning</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 of columns are float-type. Columns of object-type are: Pop, sex. Columns of int-type are: case, site. from a dataset description we know in real that Pop, sex and site are categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pop\"] = df[\"Pop\"].astype('category')\n",
    "df[\"sex\"] = df[\"sex\"].astype('category')\n",
    "df[\"site\"] = df[\"site\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change 'Pop' name column to 'pop', which fits better to other column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Pop\":\"pop\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next point is, case column is useless, because rows have indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"case\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 10 float type and 3 category type attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In column 'age' 2 entries are missing and in column footlngth 1 entry is missing. There are no missing values in other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22189349112426035"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 / np.product(df.shape) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the gaps in the data are insignificant (less than 1%), we are not doing anything about it at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>pop</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>m</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94.1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>54.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>57.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>52.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.5</td>\n",
       "      <td>56.3</td>\n",
       "      <td>85.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site  pop sex  age  hdlngth  skullw  totlngth  taill  footlgth  earconch  \\\n",
       "0    1  Vic   m  8.0     94.1    60.4      89.0   36.0      74.5      54.5   \n",
       "1    1  Vic   f  6.0     92.5    57.6      91.5   36.5      72.5      51.2   \n",
       "2    1  Vic   f  6.0     94.0    60.0      95.5   39.0      75.4      51.9   \n",
       "3    1  Vic   f  6.0     93.2    57.1      92.0   38.0      76.1      52.2   \n",
       "4    1  Vic   f  2.0     91.5    56.3      85.5   36.0      71.0      53.2   \n",
       "\n",
       "    eye  chest  belly  \n",
       "0  15.2   28.0   36.0  \n",
       "1  16.0   28.5   33.0  \n",
       "2  15.5   30.0   34.0  \n",
       "3  15.2   28.0   34.0  \n",
       "4  15.1   28.5   33.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m    61\n",
      "f    43\n",
      "Name: sex, dtype: int64\n",
      "other    58\n",
      "Vic      46\n",
      "Name: pop, dtype: int64\n",
      "1    33\n",
      "7    18\n",
      "6    13\n",
      "5    13\n",
      "2    13\n",
      "4     7\n",
      "3     7\n",
      "Name: site, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"sex\"].value_counts())\n",
    "print(df[\"pop\"].value_counts())\n",
    "print(df[\"site\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both 'sex' and 'pop' categorical attributes are of a binary type and both values are nearly equally distributed in them. 'site' attribute is a little bit imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.833333</td>\n",
       "      <td>92.602885</td>\n",
       "      <td>56.883654</td>\n",
       "      <td>87.088462</td>\n",
       "      <td>37.009615</td>\n",
       "      <td>68.459223</td>\n",
       "      <td>48.130769</td>\n",
       "      <td>15.046154</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>32.586538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.909244</td>\n",
       "      <td>3.573349</td>\n",
       "      <td>3.113426</td>\n",
       "      <td>4.310549</td>\n",
       "      <td>1.959518</td>\n",
       "      <td>4.395306</td>\n",
       "      <td>4.109380</td>\n",
       "      <td>1.050374</td>\n",
       "      <td>2.045597</td>\n",
       "      <td>2.761949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>40.300000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.250000</td>\n",
       "      <td>90.675000</td>\n",
       "      <td>54.975000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>35.875000</td>\n",
       "      <td>64.600000</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>92.800000</td>\n",
       "      <td>56.350000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>46.800000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>32.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>94.725000</td>\n",
       "      <td>58.100000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>15.725000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>103.100000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>77.900000</td>\n",
       "      <td>56.200000</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age     hdlngth      skullw    totlngth       taill    footlgth  \\\n",
       "count  102.000000  104.000000  104.000000  104.000000  104.000000  103.000000   \n",
       "mean     3.833333   92.602885   56.883654   87.088462   37.009615   68.459223   \n",
       "std      1.909244    3.573349    3.113426    4.310549    1.959518    4.395306   \n",
       "min      1.000000   82.500000   50.000000   75.000000   32.000000   60.300000   \n",
       "25%      2.250000   90.675000   54.975000   84.000000   35.875000   64.600000   \n",
       "50%      3.000000   92.800000   56.350000   88.000000   37.000000   68.000000   \n",
       "75%      5.000000   94.725000   58.100000   90.000000   38.000000   72.500000   \n",
       "max      9.000000  103.100000   68.600000   96.500000   43.000000   77.900000   \n",
       "\n",
       "         earconch         eye       chest       belly  \n",
       "count  104.000000  104.000000  104.000000  104.000000  \n",
       "mean    48.130769   15.046154   27.000000   32.586538  \n",
       "std      4.109380    1.050374    2.045597    2.761949  \n",
       "min     40.300000   12.800000   22.000000   25.000000  \n",
       "25%     44.800000   14.400000   25.500000   31.000000  \n",
       "50%     46.800000   14.900000   27.000000   32.500000  \n",
       "75%     52.000000   15.725000   28.000000   34.125000  \n",
       "max     56.200000   17.800000   32.000000   40.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the numerical attributes may be useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f8864898>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f80524e0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7ffa748>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7fa29b0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7fcbf28>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7f784e0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7f1ea58>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7f46fd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7f4f080>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7f1db00>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7ecb0b8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7e735f8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize=(12,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms show us that we shouldn't really be concerned about aspects such as: attributes of very different scales or tail heavy data. However, we will take a better look at these histograms later, during preprocessing process. Additionally, we can see that data doesn't contain outliers, what is one of the factors in favor of changing rmse to another performance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In column 'age' 2 entries are missing and in column footlngth 1 entry is missing. There are no missing values in other columns. Because the gaps in the data are insignificant, we are not doing anything about it at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Test set and training set </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check if any of attributes is highly correlated with dependent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         1.000000\n",
       "belly       0.354298\n",
       "chest       0.334209\n",
       "hdlngth     0.319022\n",
       "skullw      0.285107\n",
       "totlngth    0.260280\n",
       "eye         0.235553\n",
       "footlgth    0.126190\n",
       "taill       0.118241\n",
       "earconch    0.053405\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix[\"age\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, there is no high correlation, so we don't need to be aware of sampling bias using standard random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put test_set aside and start working on train_set only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Discover and visualize </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Histograms </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, let's deduce something from histograms of the train_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7a378d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7981320>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f795c898>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7d23e10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7d513c8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7cf8940>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7c9feb8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7cd04a8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7cd04e0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7c21f60>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7c51518>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7ff2f7bf9a58>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set.hist(figsize=(12,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasserstein distance is a metric in the space of probability measures, which can measure distance between histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  age  and  hdlngth Wasserstein distance is  nan\n",
      "For  age  and  skullw Wasserstein distance is  nan\n",
      "For  age  and  totlngth Wasserstein distance is  nan\n",
      "For  age  and  taill Wasserstein distance is  nan\n",
      "For  age  and  footlgth Wasserstein distance is  nan\n",
      "For  age  and  earconch Wasserstein distance is  nan\n",
      "For  age  and  eye Wasserstein distance is  nan\n",
      "For  age  and  chest Wasserstein distance is  nan\n",
      "For  age  and  belly Wasserstein distance is  nan\n",
      "For  hdlngth  and  skullw Wasserstein distance is  35.628915662650606\n",
      "For  hdlngth  and  totlngth Wasserstein distance is  5.381927710843373\n",
      "For  hdlngth  and  taill Wasserstein distance is  55.46265060240963\n",
      "For  hdlngth  and  footlgth Wasserstein distance is  nan\n",
      "For  hdlngth  and  earconch Wasserstein distance is  44.42168674698795\n",
      "For  hdlngth  and  eye Wasserstein distance is  77.43855421686749\n",
      "For  hdlngth  and  chest Wasserstein distance is  65.55903614457831\n",
      "For  hdlngth  and  belly Wasserstein distance is  60.046987951807225\n",
      "For  skullw  and  totlngth Wasserstein distance is  30.246987951807228\n",
      "For  skullw  and  taill Wasserstein distance is  19.83373493975904\n",
      "For  skullw  and  footlgth Wasserstein distance is  nan\n",
      "For  skullw  and  earconch Wasserstein distance is  8.79277108433735\n",
      "For  skullw  and  eye Wasserstein distance is  41.80963855421686\n",
      "For  skullw  and  chest Wasserstein distance is  29.93012048192771\n",
      "For  skullw  and  belly Wasserstein distance is  24.418072289156626\n",
      "For  totlngth  and  taill Wasserstein distance is  50.08072289156626\n",
      "For  totlngth  and  footlgth Wasserstein distance is  nan\n",
      "For  totlngth  and  earconch Wasserstein distance is  39.039759036144574\n",
      "For  totlngth  and  eye Wasserstein distance is  72.0566265060241\n",
      "For  totlngth  and  chest Wasserstein distance is  60.177108433734944\n",
      "For  totlngth  and  belly Wasserstein distance is  54.665060240963854\n",
      "For  taill  and  footlgth Wasserstein distance is  nan\n",
      "For  taill  and  earconch Wasserstein distance is  11.040963855421685\n",
      "For  taill  and  eye Wasserstein distance is  21.97590361445783\n",
      "For  taill  and  chest Wasserstein distance is  10.096385542168676\n",
      "For  taill  and  belly Wasserstein distance is  4.584337349397591\n",
      "For  footlgth  and  earconch Wasserstein distance is  nan\n",
      "For  footlgth  and  eye Wasserstein distance is  nan\n",
      "For  footlgth  and  chest Wasserstein distance is  nan\n",
      "For  footlgth  and  belly Wasserstein distance is  nan\n",
      "For  earconch  and  eye Wasserstein distance is  33.016867469879514\n",
      "For  earconch  and  chest Wasserstein distance is  21.137349397590363\n",
      "For  earconch  and  belly Wasserstein distance is  15.625301204819277\n",
      "For  eye  and  chest Wasserstein distance is  11.879518072289155\n",
      "For  eye  and  belly Wasserstein distance is  17.391566265060238\n",
      "For  chest  and  belly Wasserstein distance is  5.512048192771085\n"
     ]
    }
   ],
   "source": [
    "columns = train_set.columns\n",
    "\n",
    "for i in range(len(train_set.columns)):\n",
    "    if is_numeric_dtype(train_set[train_set.columns[i]]):\n",
    "        for j in range(i+1,len(train_set.columns)):\n",
    "            if is_numeric_dtype(train_set[train_set.columns[j]]):\n",
    "                print('For ', train_set.columns[i], ' and ', train_set.columns[j], 'Wasserstein distance is ', wasserstein_distance(train_set[train_set.columns[i]], train_set[train_set.columns[j]]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairs of histograms close to each other are: (hdlngth, totlngth), (taill, belly) and (chest, belly). Potentially we can use this information during feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Correlations </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check a correlation for numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         1.000000\n",
       "hdlngth     0.254740\n",
       "skullw      0.192840\n",
       "totlngth    0.244830\n",
       "taill       0.098013\n",
       "footlgth    0.045257\n",
       "earconch    0.037012\n",
       "eye         0.220969\n",
       "chest       0.204392\n",
       "belly       0.283273\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.corr()[\"age\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, correlation levels are very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check a correlation for categorical attributes (pop, sex, site). Function that we are going to use requires that data has no nans, so let's just drop them for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new = train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add binary columns that respond columns 'pop' and 'sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>pop</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "      <th>pop-bin</th>\n",
       "      <th>sex-bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>57.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>52.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.1</td>\n",
       "      <td>54.8</td>\n",
       "      <td>90.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>73.2</td>\n",
       "      <td>53.6</td>\n",
       "      <td>14.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>m</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.3</td>\n",
       "      <td>58.2</td>\n",
       "      <td>89.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site  pop sex  age  hdlngth  skullw  totlngth  taill  footlgth  earconch  \\\n",
       "1    1  Vic   f  6.0     92.5    57.6      91.5   36.5      72.5      51.2   \n",
       "2    1  Vic   f  6.0     94.0    60.0      95.5   39.0      75.4      51.9   \n",
       "3    1  Vic   f  6.0     93.2    57.1      92.0   38.0      76.1      52.2   \n",
       "5    1  Vic   f  1.0     93.1    54.8      90.5   35.5      73.2      53.6   \n",
       "6    1  Vic   m  2.0     95.3    58.2      89.5   36.0      71.5      52.0   \n",
       "\n",
       "    eye  chest  belly pop-bin sex-bin  \n",
       "1  16.0   28.5   33.0     1.0       1  \n",
       "2  15.5   30.0   34.0     1.0       1  \n",
       "3  15.2   28.0   34.0     1.0       1  \n",
       "5  14.2   30.0   32.0     1.0       1  \n",
       "6  14.2   30.0   34.5     1.0       0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = pd.get_dummies(train_set_new[\"pop\"])\n",
    "train_set_new = pd.concat((train_set_new, dummy), axis=1)\n",
    "del train_set_new[\"other\"]\n",
    "train_set_new = train_set_new.rename(columns={\"Vic\":\"pop-bin\"})\n",
    "\n",
    "dummy = pd.get_dummies(df[\"sex\"])\n",
    "train_set_new = pd.concat((train_set_new, dummy), axis=1)\n",
    "del train_set_new['m']\n",
    "train_set_new = train_set_new.rename(columns={\"f\":\"sex-bin\"})\n",
    "train_set_new.head()\n",
    "\n",
    "train_set_new[\"pop-bin\"] = train_set_new[\"pop-bin\"].astype('category')\n",
    "train_set_new[\"sex-bin\"] = train_set_new[\"sex-bin\"].astype('category')\n",
    "\n",
    "train_set_new = train_set_new.dropna()\n",
    "train_set_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointbiserialrResult(correlation=0.08370838421598424, pvalue=0.457499076789183)\n",
      "PointbiserialrResult(correlation=0.097489642593006, pvalue=0.3865809886184627)\n"
     ]
    }
   ],
   "source": [
    "print(stats.pointbiserialr(train_set_new[\"pop-bin\"], train_set_new[\"age\"]))\n",
    "print(stats.pointbiserialr(train_set_new[\"sex-bin\"], train_set_new[\"age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even if assumtions of this method are fulfilled, these correlations are not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a multi categorical attribute we will try ruskal-Wallis H-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25\n",
       "7    13\n",
       "6    11\n",
       "5    11\n",
       "2     9\n",
       "4     6\n",
       "3     6\n",
       "Name: site, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_new[\"site\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KruskalResult(statistic=0.3395172088593224, pvalue=0.5601080307426141)\n",
      "KruskalResult(statistic=0.1417795109924597, pvalue=0.7065183074614497)\n",
      "KruskalResult(statistic=0.561735433647231, pvalue=0.4535618539169247)\n",
      "KruskalResult(statistic=2.005456853621326, pvalue=0.15673406872991036)\n",
      "KruskalResult(statistic=1.2790622918879813, pvalue=0.2580734590616538)\n",
      "KruskalResult(statistic=0.008454874681601976, pvalue=0.9267374535850667)\n",
      "KruskalResult(statistic=1.136838159720179, pvalue=0.28632143298397716)\n"
     ]
    }
   ],
   "source": [
    "group = [None] * 7\n",
    "\n",
    "for i in range(1,8):\n",
    "    group[i-1] = train_set_new[[\"age\"]].where(train_set_new[\"site\"] == i).dropna()[\"age\"].tolist()\n",
    "    print(stats.kruskal(group[i-1], train_set_new[\"age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since for every group p-value is less than 0.05, we don't reject the null hypothesis that the median of group is same as in train_set for each group. So, we can expect that, site-grouping does not explain the variance to a great extent, hence correlation is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Attribute Combinations </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have only 9 attributes describing possums body, let's just compute ratios between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new = train_set.copy()\n",
    "\n",
    "body_columns = ['hdlngth', 'skullw', 'totlngth', 'taill', 'footlgth', 'earconch', 'eye', 'chest', 'belly']\n",
    "\n",
    "for i in range(9):\n",
    "    for j in range(i+1,9):\n",
    "        new_column = body_columns[i] + \" / \" + body_columns[j]\n",
    "        train_set_new[new_column] = train_set_new[body_columns[i]] / train_set_new[body_columns[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                    1.000000\n",
       "belly                  0.283273\n",
       "hdlngth                0.254740\n",
       "totlngth               0.244830\n",
       "eye                    0.220969\n",
       "chest                  0.204392\n",
       "skullw                 0.192840\n",
       "totlngth / footlgth    0.162309\n",
       "totlngth / taill       0.147566\n",
       "hdlngth / footlgth     0.141474\n",
       "skullw / footlgth      0.120056\n",
       "totlngth / earconch    0.099592\n",
       "taill                  0.098013\n",
       "hdlngth / earconch     0.087937\n",
       "skullw / earconch      0.084262\n",
       "hdlngth / taill        0.083814\n",
       "skullw / taill         0.081666\n",
       "footlgth               0.045257\n",
       "earconch               0.037012\n",
       "taill / footlgth       0.025634\n",
       "taill / earconch       0.018716\n",
       "hdlngth / skullw      -0.024388\n",
       "skullw / totlngth     -0.024991\n",
       "totlngth / eye        -0.027085\n",
       "eye / chest           -0.028092\n",
       "footlgth / earconch   -0.034156\n",
       "skullw / eye          -0.051047\n",
       "hdlngth / totlngth    -0.057181\n",
       "hdlngth / eye         -0.068390\n",
       "totlngth / chest      -0.074794\n",
       "eye / belly           -0.091034\n",
       "skullw / chest        -0.098670\n",
       "earconch / eye        -0.107609\n",
       "chest / belly         -0.110646\n",
       "hdlngth / chest       -0.111580\n",
       "taill / eye           -0.116237\n",
       "footlgth / eye        -0.125232\n",
       "taill / chest         -0.147681\n",
       "earconch / chest      -0.153394\n",
       "totlngth / belly      -0.163507\n",
       "skullw / belly        -0.167239\n",
       "hdlngth / belly       -0.198297\n",
       "footlgth / chest      -0.202875\n",
       "earconch / belly      -0.208473\n",
       "taill / belly         -0.218608\n",
       "footlgth / belly      -0.263342\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = train_set_new.corr()\n",
    "corr_matrix[\"age\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, correlations are on very low level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prepare the data for ML algorithms </h2>\n",
    "<h3> Data Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new = train_set.copy()\n",
    "train_set_new = train_set_new[train_set_new['age'].notna()]\n",
    "train_set_labels = train_set_new[\"age\"].copy()\n",
    "train_set_new = train_set_new.drop(\"age\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is only one nan label, we've just dropped it.\n",
    "\n",
    "Most ML algorithms cannot deal with missing values and we are not sure that there won't be any missing values in new data, let's take a stretegy to replace numerical missing instances with the median of an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "train_set_new_num = train_set_new.drop([\"site\", \"pop\", \"sex\"], axis=1)\n",
    "imputer.fit(train_set_new_num)\n",
    "X = imputer.transform(train_set_new_num)\n",
    "train_set_new_transformed = pd.DataFrame(X, columns=train_set_new_num.columns)\n",
    "\n",
    "train_set_new_transformed.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ML algorithms prefer to work with number rather than with categogorical attributes, we will convert them to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_new_cat = train_set_new[[\"site\", \"pop\", \"sex\"]]\n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "train_set_new_cat_encoded = cat_encoder.fit_transform(train_set_new_cat)\n",
    "\n",
    "train_set_new_cat_encoded = train_set_new_cat_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4, 5, 6, 7]),\n",
       " array(['Vic', 'other'], dtype=object),\n",
       " array(['f', 'm'], dtype=object)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Pipeline, to hold our transformations in more readable way. Despite the fact that, our data is very good scaled, we can additionaly do standarization, beacuse dataset is very small and it cost almost no time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "num_attribs = list(train_set_new_num.columns)\n",
    "cat_attribs = [\"site\", \"pop\", \"sex\"]\n",
    "\n",
    "pipeline = ColumnTransformer([\n",
    " (\"num\", num_pipeline, num_attribs),\n",
    " (\"cat\", OneHotEncoder(), cat_attribs),\n",
    " (\"r-skewed\", FunctionTransformer(func=np.log1p), ['totlngth', 'belly']),\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we did appropriate transformation to right skewed features. Now, we will use our transformated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 58)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_new_ready = pipeline.fit_transform(train_set_new)\n",
    "train_set_new_ready.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finished this section with set that contains 58 columns, ready to put into ML algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Select and train a model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn import ensemble\n",
    "from sklearn import isotonic\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plan is to test as many as possible models, with some different settings, in a short time, then choose a few most promising for hyperparameter tuning, based on rmse measure for training set and cross-validation.\n",
    "\n",
    "Let's calculate RMSE for training data and mean value of RMSE for Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Finding promising models </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Models </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARDRegression{}</th>\n",
       "      <th>BayesianRidge{}</th>\n",
       "      <th>ElasticNet{'selection': 'cyclic'}</th>\n",
       "      <th>ElasticNet{'selection': 'random'}</th>\n",
       "      <th>HuberRegressor{}</th>\n",
       "      <th>Lars{}</th>\n",
       "      <th>Lasso{'selection': 'cyclic'}</th>\n",
       "      <th>Lasso{'selection': 'random'}</th>\n",
       "      <th>LassoLars{}</th>\n",
       "      <th>LinearRegression{}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'saga'}</th>\n",
       "      <th>OrthogonalMatchingPursuit{}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>RANSACRegressor{}</th>\n",
       "      <th>Ridge{'solver': 'svd'}</th>\n",
       "      <th>Ridge{'solver': 'cholesky'}</th>\n",
       "      <th>Ridge{'solver': 'lsqr'}</th>\n",
       "      <th>Ridge{'solver': 'sparse_cg'}</th>\n",
       "      <th>Ridge{'solver': 'sag'}</th>\n",
       "      <th>Ridge{'solver': 'saga'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>TheilSenRegressor{}</th>\n",
       "      <th>TweedieRegressor{'link': 'identity'}</th>\n",
       "      <th>TweedieRegressor{'link': 'log'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.936501</td>\n",
       "      <td>1.849728</td>\n",
       "      <td>1.854198</td>\n",
       "      <td>1.854542</td>\n",
       "      <td>2.576841</td>\n",
       "      <td>337226.643178</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>8.022427</td>\n",
       "      <td>1.986954</td>\n",
       "      <td>2.064786</td>\n",
       "      <td>2.362686</td>\n",
       "      <td>2.362686</td>\n",
       "      <td>2.156346</td>\n",
       "      <td>2.246902</td>\n",
       "      <td>2.246902</td>\n",
       "      <td>2.179860</td>\n",
       "      <td>2.530378</td>\n",
       "      <td>2.357410</td>\n",
       "      <td>2.554081</td>\n",
       "      <td>2.393976</td>\n",
       "      <td>1.945627</td>\n",
       "      <td>2.294083</td>\n",
       "      <td>2.186708</td>\n",
       "      <td>15.167141</td>\n",
       "      <td>2.012011</td>\n",
       "      <td>2.012011</td>\n",
       "      <td>2.009916</td>\n",
       "      <td>2.012109</td>\n",
       "      <td>2.012058</td>\n",
       "      <td>2.009161</td>\n",
       "      <td>2.787248</td>\n",
       "      <td>1.011803e+14</td>\n",
       "      <td>1.948427</td>\n",
       "      <td>1.995468</td>\n",
       "      <td>2.293446</td>\n",
       "      <td>8.042401e+13</td>\n",
       "      <td>1.944068</td>\n",
       "      <td>1.950731</td>\n",
       "      <td>1.952146</td>\n",
       "      <td>8.693768</td>\n",
       "      <td>1.851942</td>\n",
       "      <td>2.114588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.500612</td>\n",
       "      <td>1.720985</td>\n",
       "      <td>1.807324</td>\n",
       "      <td>1.807324</td>\n",
       "      <td>1.275551</td>\n",
       "      <td>72.090142</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>0.850896</td>\n",
       "      <td>1.678414</td>\n",
       "      <td>1.728527</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.530184</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.649094</td>\n",
       "      <td>1.637964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594692</td>\n",
       "      <td>1.444080</td>\n",
       "      <td>1.485704</td>\n",
       "      <td>1.570558</td>\n",
       "      <td>2.043614</td>\n",
       "      <td>2.612285</td>\n",
       "      <td>2.601949</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>1.391946</td>\n",
       "      <td>1.390878</td>\n",
       "      <td>1.404288</td>\n",
       "      <td>1.417763</td>\n",
       "      <td>1.890971</td>\n",
       "      <td>4.681458e+13</td>\n",
       "      <td>1.587441</td>\n",
       "      <td>1.469083</td>\n",
       "      <td>2.353110</td>\n",
       "      <td>1.172988e+14</td>\n",
       "      <td>1.632409</td>\n",
       "      <td>1.497848</td>\n",
       "      <td>1.454201</td>\n",
       "      <td>1.070829</td>\n",
       "      <td>1.639399</td>\n",
       "      <td>1.524623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ARDRegression{}  BayesianRidge{}  \\\n",
       "rmse_cv               1.936501         1.849728   \n",
       "rmse_training         1.500612         1.720985   \n",
       "\n",
       "               ElasticNet{'selection': 'cyclic'}  \\\n",
       "rmse_cv                                 1.854198   \n",
       "rmse_training                           1.807324   \n",
       "\n",
       "               ElasticNet{'selection': 'random'}  HuberRegressor{}  \\\n",
       "rmse_cv                                 1.854542          2.576841   \n",
       "rmse_training                           1.807324          1.275551   \n",
       "\n",
       "                      Lars{}  Lasso{'selection': 'cyclic'}  \\\n",
       "rmse_cv        337226.643178                      1.844538   \n",
       "rmse_training      72.090142                      1.809692   \n",
       "\n",
       "               Lasso{'selection': 'random'}  LassoLars{}  LinearRegression{}  \\\n",
       "rmse_cv                            1.844538     1.844538            8.022427   \n",
       "rmse_training                      1.809692     1.809692            0.850896   \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}  \\\n",
       "rmse_cv                                                 1.986954            \n",
       "rmse_training                                           1.678414            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'saga'}  \\\n",
       "rmse_cv                                                 2.064786       \n",
       "rmse_training                                           1.728527       \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}  \\\n",
       "rmse_cv                                                 2.362686            \n",
       "rmse_training                                           1.542092            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.362686        \n",
       "rmse_training                                           1.542092        \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}  \\\n",
       "rmse_cv                                                 2.156346            \n",
       "rmse_training                                           1.530184            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'sag'}  \\\n",
       "rmse_cv                                                 2.246902      \n",
       "rmse_training                                           1.542092      \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'saga'}  \\\n",
       "rmse_cv                                                 2.246902       \n",
       "rmse_training                                           1.649094       \n",
       "\n",
       "               LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}  \\\n",
       "rmse_cv                                                 2.179860                                \n",
       "rmse_training                                           1.637964                                \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}  \\\n",
       "rmse_cv                                                 2.530378              \n",
       "rmse_training                                           0.000000              \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.357410          \n",
       "rmse_training                                           0.594692          \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'sag'}  \\\n",
       "rmse_cv                                                 2.554081        \n",
       "rmse_training                                           1.444080        \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'saga'}  \\\n",
       "rmse_cv                                                 2.393976         \n",
       "rmse_training                                           1.485704         \n",
       "\n",
       "               OrthogonalMatchingPursuit{}  \\\n",
       "rmse_cv                           1.945627   \n",
       "rmse_training                     1.570558   \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_cv                                                 2.294083           \n",
       "rmse_training                                           2.043614           \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_cv                                                 2.186708                   \n",
       "rmse_training                                           2.612285                   \n",
       "\n",
       "               RANSACRegressor{}  Ridge{'solver': 'svd'}  \\\n",
       "rmse_cv                15.167141                2.012011   \n",
       "rmse_training           2.601949                1.390836   \n",
       "\n",
       "               Ridge{'solver': 'cholesky'}  Ridge{'solver': 'lsqr'}  \\\n",
       "rmse_cv                           2.012011                 2.009916   \n",
       "rmse_training                     1.390836                 1.391946   \n",
       "\n",
       "               Ridge{'solver': 'sparse_cg'}  Ridge{'solver': 'sag'}  \\\n",
       "rmse_cv                            2.012109                2.012058   \n",
       "rmse_training                      1.390878                1.404288   \n",
       "\n",
       "               Ridge{'solver': 'saga'}  \\\n",
       "rmse_cv                       2.009161   \n",
       "rmse_training                 1.417763   \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}  \\\n",
       "rmse_cv                                                 2.787248            \n",
       "rmse_training                                           1.890971            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}  \\\n",
       "rmse_cv                                             1.011803e+14           \n",
       "rmse_training                                       4.681458e+13           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_cv                                                 1.948427              \n",
       "rmse_training                                           1.587441              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_cv                                                 1.995468            \n",
       "rmse_training                                           1.469083            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}  \\\n",
       "rmse_cv                                                 2.293446            \n",
       "rmse_training                                           2.353110            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}  \\\n",
       "rmse_cv                                             8.042401e+13           \n",
       "rmse_training                                       1.172988e+14           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_cv                                                 1.944068              \n",
       "rmse_training                                           1.632409              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_cv                                                 1.950731            \n",
       "rmse_training                                           1.497848            \n",
       "\n",
       "               SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_cv                                                 1.952146                    \n",
       "rmse_training                                           1.454201                    \n",
       "\n",
       "               TheilSenRegressor{}  TweedieRegressor{'link': 'identity'}  \\\n",
       "rmse_cv                   8.693768                              1.851942   \n",
       "rmse_training             1.070829                              1.639399   \n",
       "\n",
       "               TweedieRegressor{'link': 'log'}  \n",
       "rmse_cv                               2.114588  \n",
       "rmse_training                         1.524623  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_lm = regression_linear_models(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_lm = pd.DataFrame.from_dict(result_lm)\n",
    "result_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> KernelRidge </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KernelRidge 1**2</th>\n",
       "      <th>KernelRidge DotProduct(sigma_0=1)</th>\n",
       "      <th>KernelRidge ExpSineSquared(length_scale=1, periodicity=1)</th>\n",
       "      <th>KernelRidge Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>KernelRidge PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>KernelRidge RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>KernelRidge RBF(length_scale=1)</th>\n",
       "      <th>KernelRidge WhiteKernel(noise_level=1)</th>\n",
       "      <th>KernelRidge linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.842443</td>\n",
       "      <td>2.011974</td>\n",
       "      <td>15.776251</td>\n",
       "      <td>4.042328</td>\n",
       "      <td>2.011973</td>\n",
       "      <td>2.578366</td>\n",
       "      <td>4.083858</td>\n",
       "      <td>4.099670</td>\n",
       "      <td>2.011973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.810247</td>\n",
       "      <td>1.390653</td>\n",
       "      <td>3.318812</td>\n",
       "      <td>2.023938</td>\n",
       "      <td>1.390648</td>\n",
       "      <td>1.218348</td>\n",
       "      <td>2.055960</td>\n",
       "      <td>4.136394</td>\n",
       "      <td>1.390648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               KernelRidge 1**2  KernelRidge DotProduct(sigma_0=1)  \\\n",
       "rmse_cv                1.842443                           2.011974   \n",
       "rmse_training          1.810247                           1.390653   \n",
       "\n",
       "               KernelRidge ExpSineSquared(length_scale=1, periodicity=1)  \\\n",
       "rmse_cv                                                15.776251           \n",
       "rmse_training                                           3.318812           \n",
       "\n",
       "               KernelRidge Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_cv                                          4.042328   \n",
       "rmse_training                                    2.023938   \n",
       "\n",
       "               KernelRidge PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_cv                                                 2.011973      \n",
       "rmse_training                                           1.390648      \n",
       "\n",
       "               KernelRidge RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_cv                                                 2.578366        \n",
       "rmse_training                                           1.218348        \n",
       "\n",
       "               KernelRidge RBF(length_scale=1)  \\\n",
       "rmse_cv                               4.083858   \n",
       "rmse_training                         2.055960   \n",
       "\n",
       "               KernelRidge WhiteKernel(noise_level=1)  KernelRidge linear  \n",
       "rmse_cv                                      4.099670            2.011973  \n",
       "rmse_training                                4.136394            1.390648  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_kr = regression_kernelridge(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_kr = pd.DataFrame.from_dict(result_kr)\n",
    "result_kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> SVM </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearSVR{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>LinearSVR{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>NuSVR{'kernel': 'linear'}</th>\n",
       "      <th>NuSVR{'kernel': 'poly'}</th>\n",
       "      <th>NuSVR{'kernel': 'rbf'}</th>\n",
       "      <th>NuSVR{'kernel': 'sigmoid'}</th>\n",
       "      <th>SVR{'kernel': 'linear'}</th>\n",
       "      <th>SVR{'kernel': 'poly'}</th>\n",
       "      <th>SVR{'kernel': 'rbf'}</th>\n",
       "      <th>SVR{'kernel': 'sigmoid'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.167655</td>\n",
       "      <td>2.052190</td>\n",
       "      <td>1.916470</td>\n",
       "      <td>1.770307</td>\n",
       "      <td>1.742634</td>\n",
       "      <td>1.851783</td>\n",
       "      <td>2.133088</td>\n",
       "      <td>1.82145</td>\n",
       "      <td>1.720149</td>\n",
       "      <td>1.933953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.514513</td>\n",
       "      <td>1.343105</td>\n",
       "      <td>1.476317</td>\n",
       "      <td>1.377438</td>\n",
       "      <td>1.481749</td>\n",
       "      <td>1.837184</td>\n",
       "      <td>1.496323</td>\n",
       "      <td>1.43371</td>\n",
       "      <td>1.489761</td>\n",
       "      <td>1.877357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LinearSVR{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_cv                                        2.167655   \n",
       "rmse_training                                  1.514513   \n",
       "\n",
       "               LinearSVR{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_cv                                                2.052190   \n",
       "rmse_training                                          1.343105   \n",
       "\n",
       "               NuSVR{'kernel': 'linear'}  NuSVR{'kernel': 'poly'}  \\\n",
       "rmse_cv                         1.916470                 1.770307   \n",
       "rmse_training                   1.476317                 1.377438   \n",
       "\n",
       "               NuSVR{'kernel': 'rbf'}  NuSVR{'kernel': 'sigmoid'}  \\\n",
       "rmse_cv                      1.742634                    1.851783   \n",
       "rmse_training                1.481749                    1.837184   \n",
       "\n",
       "               SVR{'kernel': 'linear'}  SVR{'kernel': 'poly'}  \\\n",
       "rmse_cv                       2.133088                1.82145   \n",
       "rmse_training                 1.496323                1.43371   \n",
       "\n",
       "               SVR{'kernel': 'rbf'}  SVR{'kernel': 'sigmoid'}  \n",
       "rmse_cv                    1.720149                  1.933953  \n",
       "rmse_training              1.489761                  1.877357  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_svm = regression_svm(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_svm = pd.DataFrame.from_dict(result_svm)\n",
    "result_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Gaussian Process </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GaussianProcessRegressor 1**2</th>\n",
       "      <th>GaussianProcessRegressor DotProduct(sigma_0=1)</th>\n",
       "      <th>GaussianProcessRegressor Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor RBF(length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor WhiteKernel(noise_level=1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>3.456524</td>\n",
       "      <td>8.021744</td>\n",
       "      <td>1.773059e+00</td>\n",
       "      <td>8.021249</td>\n",
       "      <td>1.705117e+00</td>\n",
       "      <td>2.039888e+00</td>\n",
       "      <td>4.099670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.809692</td>\n",
       "      <td>0.850870</td>\n",
       "      <td>3.182821e-10</td>\n",
       "      <td>0.851026</td>\n",
       "      <td>2.213021e-10</td>\n",
       "      <td>4.607289e-10</td>\n",
       "      <td>4.136394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GaussianProcessRegressor 1**2  \\\n",
       "rmse_cv                             3.456524   \n",
       "rmse_training                       1.809692   \n",
       "\n",
       "               GaussianProcessRegressor DotProduct(sigma_0=1)  \\\n",
       "rmse_cv                                              8.021744   \n",
       "rmse_training                                        0.850870   \n",
       "\n",
       "               GaussianProcessRegressor Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_cv                                             1.773059e+00         \n",
       "rmse_training                                       3.182821e-10         \n",
       "\n",
       "               GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_cv                                                 8.021249                   \n",
       "rmse_training                                           0.851026                   \n",
       "\n",
       "               GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_cv                                             1.705117e+00                     \n",
       "rmse_training                                       2.213021e-10                     \n",
       "\n",
       "               GaussianProcessRegressor RBF(length_scale=1)  \\\n",
       "rmse_cv                                        2.039888e+00   \n",
       "rmse_training                                  4.607289e-10   \n",
       "\n",
       "               GaussianProcessRegressor WhiteKernel(noise_level=1)  \n",
       "rmse_cv                                                 4.099670    \n",
       "rmse_training                                           4.136394    "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_gpr = regression_gaussianprocess(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_gpr = pd.DataFrame.from_dict(result_gpr)\n",
    "result_gpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cross Decomposition </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCA{}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'nipals'}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'svd'}</th>\n",
       "      <th>PLSRegression{}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.841178</td>\n",
       "      <td>4.974416</td>\n",
       "      <td>4.974416</td>\n",
       "      <td>1.890073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.788298</td>\n",
       "      <td>4.701129</td>\n",
       "      <td>4.701129</td>\n",
       "      <td>1.586375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CCA{}  PLSCanonical{'algorithm': 'nipals'}  \\\n",
       "rmse_cv        1.841178                             4.974416   \n",
       "rmse_training  1.788298                             4.701129   \n",
       "\n",
       "               PLSCanonical{'algorithm': 'svd'}  PLSRegression{}  \n",
       "rmse_cv                                4.974416         1.890073  \n",
       "rmse_training                          4.701129         1.586375  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_cd = regression_crossdecomposition(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_cd = pd.DataFrame.from_dict(result_cd)\n",
    "result_cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Decision Tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.376388</td>\n",
       "      <td>2.177195</td>\n",
       "      <td>2.429694</td>\n",
       "      <td>2.537739</td>\n",
       "      <td>2.277032</td>\n",
       "      <td>2.44195</td>\n",
       "      <td>2.34612</td>\n",
       "      <td>2.582957</td>\n",
       "      <td>2.266488</td>\n",
       "      <td>2.338288</td>\n",
       "      <td>2.358372</td>\n",
       "      <td>2.115753</td>\n",
       "      <td>2.401824</td>\n",
       "      <td>2.474385</td>\n",
       "      <td>2.538839</td>\n",
       "      <td>2.350313</td>\n",
       "      <td>2.443885</td>\n",
       "      <td>2.256926</td>\n",
       "      <td>2.280453</td>\n",
       "      <td>2.495793</td>\n",
       "      <td>2.586878</td>\n",
       "      <td>2.333232</td>\n",
       "      <td>2.598571</td>\n",
       "      <td>2.536448</td>\n",
       "      <td>2.652689</td>\n",
       "      <td>2.405583</td>\n",
       "      <td>2.647083</td>\n",
       "      <td>2.639092</td>\n",
       "      <td>2.300325</td>\n",
       "      <td>2.405749</td>\n",
       "      <td>2.571787</td>\n",
       "      <td>2.468389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.376388                                      \n",
       "rmse_training                                           0.000000                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.177195                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.429694                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.537739                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.277032                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                  2.44195                                          \n",
       "rmse_training                                            0.00000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                  2.34612                                          \n",
       "rmse_training                                            0.00000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.582957                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.266488                                               \n",
       "rmse_training                                           0.000000                                               \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.338288                                                 \n",
       "rmse_training                                           0.000000                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.358372                                                 \n",
       "rmse_training                                           0.000000                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.115753                                                 \n",
       "rmse_training                                           0.000000                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.401824                                                 \n",
       "rmse_training                                           0.000000                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.474385                                                   \n",
       "rmse_training                                           0.000000                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.538839                                                   \n",
       "rmse_training                                           0.000000                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.350313                                                   \n",
       "rmse_training                                           0.000000                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.443885                                      \n",
       "rmse_training                                           0.000000                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.256926                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.280453                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.495793                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.586878                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.333232                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.598571                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.536448                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.652689                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.405583                                            \n",
       "rmse_training                                           0.000000                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.647083                                            \n",
       "rmse_training                                           0.000000                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.639092                                            \n",
       "rmse_training                                           0.000000                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.300325                                            \n",
       "rmse_training                                           0.000000                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.405749                                              \n",
       "rmse_training                                           0.000000                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.571787                                              \n",
       "rmse_training                                           0.000000                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}  \n",
       "rmse_cv                                                 2.468389                                             \n",
       "rmse_training                                           0.000000                                             "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tree = regression_decisiontree(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_tree = pd.DataFrame.from_dict(result_tree)\n",
    "result_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Ensemble Methods </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor{'loss': 'linear'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'square'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'exponential'}</th>\n",
       "      <th>BaggingRegressor{}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>IsolationForest{}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}</th>\n",
       "      <th>StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "      <th>VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.772216</td>\n",
       "      <td>1.904255</td>\n",
       "      <td>1.783083</td>\n",
       "      <td>1.801408</td>\n",
       "      <td>1.66617</td>\n",
       "      <td>1.70657</td>\n",
       "      <td>1.694374</td>\n",
       "      <td>1.705887</td>\n",
       "      <td>1.730025</td>\n",
       "      <td>1.745496</td>\n",
       "      <td>1.666103</td>\n",
       "      <td>1.653418</td>\n",
       "      <td>1.764701</td>\n",
       "      <td>1.746421</td>\n",
       "      <td>1.727822</td>\n",
       "      <td>1.687527</td>\n",
       "      <td>1.708785</td>\n",
       "      <td>1.718697</td>\n",
       "      <td>1.669033</td>\n",
       "      <td>1.643558</td>\n",
       "      <td>1.702957</td>\n",
       "      <td>1.710143</td>\n",
       "      <td>1.677468</td>\n",
       "      <td>1.656262</td>\n",
       "      <td>2.937517</td>\n",
       "      <td>2.938707</td>\n",
       "      <td>2.110567</td>\n",
       "      <td>2.135575</td>\n",
       "      <td>1.779361</td>\n",
       "      <td>1.774450</td>\n",
       "      <td>1.632296</td>\n",
       "      <td>1.707787</td>\n",
       "      <td>1.691127</td>\n",
       "      <td>1.673572</td>\n",
       "      <td>1.725870</td>\n",
       "      <td>1.718344</td>\n",
       "      <td>1.733118</td>\n",
       "      <td>1.727884</td>\n",
       "      <td>1.733573</td>\n",
       "      <td>1.765523</td>\n",
       "      <td>2.92387</td>\n",
       "      <td>2.907732</td>\n",
       "      <td>2.153590</td>\n",
       "      <td>2.100161</td>\n",
       "      <td>3.523848</td>\n",
       "      <td>1.688684</td>\n",
       "      <td>1.726894</td>\n",
       "      <td>1.702976</td>\n",
       "      <td>1.684268</td>\n",
       "      <td>1.699553</td>\n",
       "      <td>1.719358</td>\n",
       "      <td>1.741653</td>\n",
       "      <td>1.684139</td>\n",
       "      <td>2.05660</td>\n",
       "      <td>2.029211</td>\n",
       "      <td>2.195140</td>\n",
       "      <td>1.814501</td>\n",
       "      <td>1.836144</td>\n",
       "      <td>1.815186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>0.806614</td>\n",
       "      <td>0.705711</td>\n",
       "      <td>0.838255</td>\n",
       "      <td>0.723474</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>0.166830</td>\n",
       "      <td>0.189858</td>\n",
       "      <td>0.752142</td>\n",
       "      <td>0.834631</td>\n",
       "      <td>0.910696</td>\n",
       "      <td>0.864192</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.328811</td>\n",
       "      <td>0.398628</td>\n",
       "      <td>0.318355</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>1.914494</td>\n",
       "      <td>1.785579</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.153228</td>\n",
       "      <td>0.183809</td>\n",
       "      <td>0.806474</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.823607</td>\n",
       "      <td>0.981154</td>\n",
       "      <td>0.328811</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.327448</td>\n",
       "      <td>0.385011</td>\n",
       "      <td>2.90500</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>1.775542</td>\n",
       "      <td>1.772948</td>\n",
       "      <td>3.532083</td>\n",
       "      <td>0.602670</td>\n",
       "      <td>0.630745</td>\n",
       "      <td>0.619208</td>\n",
       "      <td>0.622092</td>\n",
       "      <td>0.643743</td>\n",
       "      <td>0.622298</td>\n",
       "      <td>0.613938</td>\n",
       "      <td>0.715906</td>\n",
       "      <td>0.76373</td>\n",
       "      <td>0.744245</td>\n",
       "      <td>0.791746</td>\n",
       "      <td>0.709642</td>\n",
       "      <td>2.022631</td>\n",
       "      <td>1.581238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AdaBoostRegressor{'loss': 'linear'}  \\\n",
       "rmse_cv                                   1.772216   \n",
       "rmse_training                             0.806614   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'square'}  \\\n",
       "rmse_cv                                   1.904255   \n",
       "rmse_training                             0.705711   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'exponential'}  BaggingRegressor{}  \\\n",
       "rmse_cv                                        1.783083            1.801408   \n",
       "rmse_training                                  0.838255            0.723474   \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                  1.66617                 \n",
       "rmse_training                                            0.00000                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                  1.70657                 \n",
       "rmse_training                                            0.00000                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.694374                 \n",
       "rmse_training                                           0.000000                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.705887                 \n",
       "rmse_training                                           0.000000                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.730025               \n",
       "rmse_training                                           0.000000               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.745496               \n",
       "rmse_training                                           0.000000               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.666103            \n",
       "rmse_training                                           0.027806            \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.653418            \n",
       "rmse_training                                           0.000000            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.764701                                            \n",
       "rmse_training                                           0.117268                                            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.746421                                              \n",
       "rmse_training                                           0.119379                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.727822                                              \n",
       "rmse_training                                           0.166830                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.687527                                              \n",
       "rmse_training                                           0.189858                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.708785                                             \n",
       "rmse_training                                           0.752142                                             \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.718697                                               \n",
       "rmse_training                                           0.834631                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.669033                                               \n",
       "rmse_training                                           0.910696                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.643558                                               \n",
       "rmse_training                                           0.864192                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.702957                                               \n",
       "rmse_training                                           0.344400                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.710143                                                 \n",
       "rmse_training                                           0.328811                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.677468                                                 \n",
       "rmse_training                                           0.398628                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.656262                                                 \n",
       "rmse_training                                           0.318355                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.937517                                                  \n",
       "rmse_training                                           2.905000                                                  \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.938707                                                    \n",
       "rmse_training                                           2.905000                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.110567                                                    \n",
       "rmse_training                                           1.914494                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.135575                                                    \n",
       "rmse_training                                           1.785579                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.779361                                   \n",
       "rmse_training                                           0.117268                                   \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.774450                                     \n",
       "rmse_training                                           0.117268                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.632296                                     \n",
       "rmse_training                                           0.153228                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.707787                                     \n",
       "rmse_training                                           0.183809                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.691127                                    \n",
       "rmse_training                                           0.806474                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.673572                                      \n",
       "rmse_training                                           0.784466                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.725870                                      \n",
       "rmse_training                                           0.823607                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.718344                                      \n",
       "rmse_training                                           0.981154                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.733118                                      \n",
       "rmse_training                                           0.328811                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.727884                                        \n",
       "rmse_training                                           0.344400                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.733573                                        \n",
       "rmse_training                                           0.327448                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.765523                                        \n",
       "rmse_training                                           0.385011                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_cv                                                  2.92387                                         \n",
       "rmse_training                                            2.90500                                         \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.907732                                           \n",
       "rmse_training                                           2.905000                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.153590                                           \n",
       "rmse_training                                           1.775542                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.100161                                           \n",
       "rmse_training                                           1.772948                                           \n",
       "\n",
       "               IsolationForest{}  \\\n",
       "rmse_cv                 3.523848   \n",
       "rmse_training           3.532083   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.688684                   \n",
       "rmse_training                                           0.602670                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.726894                   \n",
       "rmse_training                                           0.630745                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.702976                 \n",
       "rmse_training                                           0.619208                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.684268              \n",
       "rmse_training                                           0.622092              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.699553                   \n",
       "rmse_training                                           0.643743                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.719358                   \n",
       "rmse_training                                           0.622298                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.741653                 \n",
       "rmse_training                                           0.613938                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.684139              \n",
       "rmse_training                                           0.715906              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                  2.05660                       \n",
       "rmse_training                                            0.76373                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.029211                       \n",
       "rmse_training                                           0.744245                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.195140                     \n",
       "rmse_training                                           0.791746                     \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.814501                  \n",
       "rmse_training                                           0.709642                  \n",
       "\n",
       "               StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \\\n",
       "rmse_cv                                                 1.836144                                                                                                                                                \n",
       "rmse_training                                           2.022631                                                                                                                                                \n",
       "\n",
       "               VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \n",
       "rmse_cv                                                 1.815186                                                                                                                                             \n",
       "rmse_training                                           1.581238                                                                                                                                             "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "result_ens = regression_ensemble(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_ens = pd.DataFrame.from_dict(result_ens)\n",
    "result_ens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Neural Network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.685312</td>\n",
       "      <td>1.939891</td>\n",
       "      <td>2.039910</td>\n",
       "      <td>2.603890</td>\n",
       "      <td>1.962460</td>\n",
       "      <td>1.942471</td>\n",
       "      <td>2.532667</td>\n",
       "      <td>1.929567</td>\n",
       "      <td>2.089535</td>\n",
       "      <td>2.50669</td>\n",
       "      <td>1.969280</td>\n",
       "      <td>1.883001</td>\n",
       "      <td>2.211726</td>\n",
       "      <td>1.996911</td>\n",
       "      <td>1.882330</td>\n",
       "      <td>2.422484</td>\n",
       "      <td>1.849734</td>\n",
       "      <td>1.897464</td>\n",
       "      <td>2.301830</td>\n",
       "      <td>1.876582</td>\n",
       "      <td>2.055804</td>\n",
       "      <td>2.212011</td>\n",
       "      <td>1.936340</td>\n",
       "      <td>1.884506</td>\n",
       "      <td>2.451246</td>\n",
       "      <td>1.879909</td>\n",
       "      <td>2.077749</td>\n",
       "      <td>2.226337</td>\n",
       "      <td>1.829515</td>\n",
       "      <td>1.847804</td>\n",
       "      <td>2.379905</td>\n",
       "      <td>1.845045</td>\n",
       "      <td>1.795665</td>\n",
       "      <td>2.287506</td>\n",
       "      <td>1.785755</td>\n",
       "      <td>1.887604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.079619</td>\n",
       "      <td>1.518728</td>\n",
       "      <td>1.704454</td>\n",
       "      <td>1.112845</td>\n",
       "      <td>2.421541</td>\n",
       "      <td>1.725049</td>\n",
       "      <td>1.099303</td>\n",
       "      <td>1.535270</td>\n",
       "      <td>1.742883</td>\n",
       "      <td>0.00192</td>\n",
       "      <td>1.937167</td>\n",
       "      <td>1.472853</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>2.156948</td>\n",
       "      <td>1.485565</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>1.756306</td>\n",
       "      <td>1.482906</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>1.167922</td>\n",
       "      <td>0.764731</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>1.757511</td>\n",
       "      <td>0.854387</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>1.175869</td>\n",
       "      <td>0.820818</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>1.692572</td>\n",
       "      <td>0.771235</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>1.754491</td>\n",
       "      <td>0.713711</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>1.664385</td>\n",
       "      <td>0.551754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.685312                                         \n",
       "rmse_training                                           1.079619                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.939891                                       \n",
       "rmse_training                                           1.518728                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 2.039910                                        \n",
       "rmse_training                                           1.704454                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.603890                                           \n",
       "rmse_training                                           1.112845                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.962460                                         \n",
       "rmse_training                                           2.421541                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.942471                                          \n",
       "rmse_training                                           1.725049                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.532667                                         \n",
       "rmse_training                                           1.099303                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.929567                                       \n",
       "rmse_training                                           1.535270                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 2.089535                                        \n",
       "rmse_training                                           1.742883                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                  2.50669                                         \n",
       "rmse_training                                            0.00192                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.969280                                       \n",
       "rmse_training                                           1.937167                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.883001                                        \n",
       "rmse_training                                           1.472853                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.211726                                           \n",
       "rmse_training                                           0.001569                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.996911                                         \n",
       "rmse_training                                           2.156948                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.882330                                          \n",
       "rmse_training                                           1.485565                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.422484                                         \n",
       "rmse_training                                           0.001793                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.849734                                       \n",
       "rmse_training                                           1.756306                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.897464                                        \n",
       "rmse_training                                           1.482906                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.301830                                     \n",
       "rmse_training                                           0.000503                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.876582                                   \n",
       "rmse_training                                           1.167922                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 2.055804                                    \n",
       "rmse_training                                           0.764731                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.212011                                       \n",
       "rmse_training                                           0.000433                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.936340                                     \n",
       "rmse_training                                           1.757511                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.884506                                      \n",
       "rmse_training                                           0.854387                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.451246                                     \n",
       "rmse_training                                           0.000501                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.879909                                   \n",
       "rmse_training                                           1.175869                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 2.077749                                    \n",
       "rmse_training                                           0.820818                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.226337                                     \n",
       "rmse_training                                           0.001034                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.829515                                   \n",
       "rmse_training                                           1.692572                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.847804                                    \n",
       "rmse_training                                           0.771235                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.379905                                       \n",
       "rmse_training                                           0.000450                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.845045                                     \n",
       "rmse_training                                           1.754491                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.795665                                      \n",
       "rmse_training                                           0.713711                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.287506                                     \n",
       "rmse_training                                           0.000859                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.785755                                   \n",
       "rmse_training                                           1.664385                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}  \n",
       "rmse_cv                                                 1.887604                                   \n",
       "rmse_training                                           0.551754                                   "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "regression_neuralnetwork\n",
    "result_nn = regression_neuralnetwork(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_nn = pd.DataFrame.from_dict(result_nn)\n",
    "result_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Summary </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARDRegression{}</th>\n",
       "      <th>BayesianRidge{}</th>\n",
       "      <th>ElasticNet{'selection': 'cyclic'}</th>\n",
       "      <th>ElasticNet{'selection': 'random'}</th>\n",
       "      <th>HuberRegressor{}</th>\n",
       "      <th>Lars{}</th>\n",
       "      <th>Lasso{'selection': 'cyclic'}</th>\n",
       "      <th>Lasso{'selection': 'random'}</th>\n",
       "      <th>LassoLars{}</th>\n",
       "      <th>LinearRegression{}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'saga'}</th>\n",
       "      <th>OrthogonalMatchingPursuit{}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>RANSACRegressor{}</th>\n",
       "      <th>Ridge{'solver': 'svd'}</th>\n",
       "      <th>Ridge{'solver': 'cholesky'}</th>\n",
       "      <th>Ridge{'solver': 'lsqr'}</th>\n",
       "      <th>Ridge{'solver': 'sparse_cg'}</th>\n",
       "      <th>Ridge{'solver': 'sag'}</th>\n",
       "      <th>Ridge{'solver': 'saga'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>TheilSenRegressor{}</th>\n",
       "      <th>TweedieRegressor{'link': 'identity'}</th>\n",
       "      <th>TweedieRegressor{'link': 'log'}</th>\n",
       "      <th>KernelRidge 1**2</th>\n",
       "      <th>KernelRidge DotProduct(sigma_0=1)</th>\n",
       "      <th>KernelRidge ExpSineSquared(length_scale=1, periodicity=1)</th>\n",
       "      <th>KernelRidge Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>KernelRidge PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>KernelRidge RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>KernelRidge RBF(length_scale=1)</th>\n",
       "      <th>KernelRidge WhiteKernel(noise_level=1)</th>\n",
       "      <th>KernelRidge linear</th>\n",
       "      <th>LinearSVR{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>LinearSVR{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>NuSVR{'kernel': 'linear'}</th>\n",
       "      <th>NuSVR{'kernel': 'poly'}</th>\n",
       "      <th>NuSVR{'kernel': 'rbf'}</th>\n",
       "      <th>NuSVR{'kernel': 'sigmoid'}</th>\n",
       "      <th>SVR{'kernel': 'linear'}</th>\n",
       "      <th>SVR{'kernel': 'poly'}</th>\n",
       "      <th>SVR{'kernel': 'rbf'}</th>\n",
       "      <th>SVR{'kernel': 'sigmoid'}</th>\n",
       "      <th>GaussianProcessRegressor 1**2</th>\n",
       "      <th>GaussianProcessRegressor DotProduct(sigma_0=1)</th>\n",
       "      <th>GaussianProcessRegressor Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor RBF(length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor WhiteKernel(noise_level=1)</th>\n",
       "      <th>CCA{}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'nipals'}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'svd'}</th>\n",
       "      <th>PLSRegression{}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'linear'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'square'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'exponential'}</th>\n",
       "      <th>BaggingRegressor{}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>IsolationForest{}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}</th>\n",
       "      <th>StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "      <th>VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.936501</td>\n",
       "      <td>1.849728</td>\n",
       "      <td>1.854198</td>\n",
       "      <td>1.854542</td>\n",
       "      <td>2.576841</td>\n",
       "      <td>337226.643178</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>1.844538</td>\n",
       "      <td>8.022427</td>\n",
       "      <td>1.986954</td>\n",
       "      <td>2.064786</td>\n",
       "      <td>2.362686</td>\n",
       "      <td>2.362686</td>\n",
       "      <td>2.156346</td>\n",
       "      <td>2.246902</td>\n",
       "      <td>2.246902</td>\n",
       "      <td>2.179860</td>\n",
       "      <td>2.530378</td>\n",
       "      <td>2.357410</td>\n",
       "      <td>2.554081</td>\n",
       "      <td>2.393976</td>\n",
       "      <td>1.945627</td>\n",
       "      <td>2.294083</td>\n",
       "      <td>2.186708</td>\n",
       "      <td>15.167141</td>\n",
       "      <td>2.012011</td>\n",
       "      <td>2.012011</td>\n",
       "      <td>2.009916</td>\n",
       "      <td>2.012109</td>\n",
       "      <td>2.012058</td>\n",
       "      <td>2.009161</td>\n",
       "      <td>2.787248</td>\n",
       "      <td>1.011803e+14</td>\n",
       "      <td>1.948427</td>\n",
       "      <td>1.995468</td>\n",
       "      <td>2.293446</td>\n",
       "      <td>8.042401e+13</td>\n",
       "      <td>1.944068</td>\n",
       "      <td>1.950731</td>\n",
       "      <td>1.952146</td>\n",
       "      <td>8.693768</td>\n",
       "      <td>1.851942</td>\n",
       "      <td>2.114588</td>\n",
       "      <td>1.842443</td>\n",
       "      <td>2.011974</td>\n",
       "      <td>15.776251</td>\n",
       "      <td>4.042328</td>\n",
       "      <td>2.011973</td>\n",
       "      <td>2.578366</td>\n",
       "      <td>4.083858</td>\n",
       "      <td>4.099670</td>\n",
       "      <td>2.011973</td>\n",
       "      <td>2.167655</td>\n",
       "      <td>2.052190</td>\n",
       "      <td>1.916470</td>\n",
       "      <td>1.770307</td>\n",
       "      <td>1.742634</td>\n",
       "      <td>1.851783</td>\n",
       "      <td>2.133088</td>\n",
       "      <td>1.82145</td>\n",
       "      <td>1.720149</td>\n",
       "      <td>1.933953</td>\n",
       "      <td>3.456524</td>\n",
       "      <td>8.021744</td>\n",
       "      <td>1.773059e+00</td>\n",
       "      <td>8.021249</td>\n",
       "      <td>1.705117e+00</td>\n",
       "      <td>2.039888e+00</td>\n",
       "      <td>4.099670</td>\n",
       "      <td>1.841178</td>\n",
       "      <td>4.974416</td>\n",
       "      <td>4.974416</td>\n",
       "      <td>1.890073</td>\n",
       "      <td>2.376388</td>\n",
       "      <td>2.177195</td>\n",
       "      <td>2.429694</td>\n",
       "      <td>2.537739</td>\n",
       "      <td>2.277032</td>\n",
       "      <td>2.44195</td>\n",
       "      <td>2.34612</td>\n",
       "      <td>2.582957</td>\n",
       "      <td>2.266488</td>\n",
       "      <td>2.338288</td>\n",
       "      <td>2.358372</td>\n",
       "      <td>2.115753</td>\n",
       "      <td>2.401824</td>\n",
       "      <td>2.474385</td>\n",
       "      <td>2.538839</td>\n",
       "      <td>2.350313</td>\n",
       "      <td>2.443885</td>\n",
       "      <td>2.256926</td>\n",
       "      <td>2.280453</td>\n",
       "      <td>2.495793</td>\n",
       "      <td>2.586878</td>\n",
       "      <td>2.333232</td>\n",
       "      <td>2.598571</td>\n",
       "      <td>2.536448</td>\n",
       "      <td>2.652689</td>\n",
       "      <td>2.405583</td>\n",
       "      <td>2.647083</td>\n",
       "      <td>2.639092</td>\n",
       "      <td>2.300325</td>\n",
       "      <td>2.405749</td>\n",
       "      <td>2.571787</td>\n",
       "      <td>2.468389</td>\n",
       "      <td>1.772216</td>\n",
       "      <td>1.904255</td>\n",
       "      <td>1.783083</td>\n",
       "      <td>1.801408</td>\n",
       "      <td>1.66617</td>\n",
       "      <td>1.70657</td>\n",
       "      <td>1.694374</td>\n",
       "      <td>1.705887</td>\n",
       "      <td>1.730025</td>\n",
       "      <td>1.745496</td>\n",
       "      <td>1.666103</td>\n",
       "      <td>1.653418</td>\n",
       "      <td>1.764701</td>\n",
       "      <td>1.746421</td>\n",
       "      <td>1.727822</td>\n",
       "      <td>1.687527</td>\n",
       "      <td>1.708785</td>\n",
       "      <td>1.718697</td>\n",
       "      <td>1.669033</td>\n",
       "      <td>1.643558</td>\n",
       "      <td>1.702957</td>\n",
       "      <td>1.710143</td>\n",
       "      <td>1.677468</td>\n",
       "      <td>1.656262</td>\n",
       "      <td>2.937517</td>\n",
       "      <td>2.938707</td>\n",
       "      <td>2.110567</td>\n",
       "      <td>2.135575</td>\n",
       "      <td>1.779361</td>\n",
       "      <td>1.774450</td>\n",
       "      <td>1.632296</td>\n",
       "      <td>1.707787</td>\n",
       "      <td>1.691127</td>\n",
       "      <td>1.673572</td>\n",
       "      <td>1.725870</td>\n",
       "      <td>1.718344</td>\n",
       "      <td>1.733118</td>\n",
       "      <td>1.727884</td>\n",
       "      <td>1.733573</td>\n",
       "      <td>1.765523</td>\n",
       "      <td>2.92387</td>\n",
       "      <td>2.907732</td>\n",
       "      <td>2.153590</td>\n",
       "      <td>2.100161</td>\n",
       "      <td>3.523848</td>\n",
       "      <td>1.688684</td>\n",
       "      <td>1.726894</td>\n",
       "      <td>1.702976</td>\n",
       "      <td>1.684268</td>\n",
       "      <td>1.699553</td>\n",
       "      <td>1.719358</td>\n",
       "      <td>1.741653</td>\n",
       "      <td>1.684139</td>\n",
       "      <td>2.05660</td>\n",
       "      <td>2.029211</td>\n",
       "      <td>2.195140</td>\n",
       "      <td>1.814501</td>\n",
       "      <td>1.836144</td>\n",
       "      <td>1.815186</td>\n",
       "      <td>2.685312</td>\n",
       "      <td>1.939891</td>\n",
       "      <td>2.039910</td>\n",
       "      <td>2.603890</td>\n",
       "      <td>1.962460</td>\n",
       "      <td>1.942471</td>\n",
       "      <td>2.532667</td>\n",
       "      <td>1.929567</td>\n",
       "      <td>2.089535</td>\n",
       "      <td>2.50669</td>\n",
       "      <td>1.969280</td>\n",
       "      <td>1.883001</td>\n",
       "      <td>2.211726</td>\n",
       "      <td>1.996911</td>\n",
       "      <td>1.882330</td>\n",
       "      <td>2.422484</td>\n",
       "      <td>1.849734</td>\n",
       "      <td>1.897464</td>\n",
       "      <td>2.301830</td>\n",
       "      <td>1.876582</td>\n",
       "      <td>2.055804</td>\n",
       "      <td>2.212011</td>\n",
       "      <td>1.936340</td>\n",
       "      <td>1.884506</td>\n",
       "      <td>2.451246</td>\n",
       "      <td>1.879909</td>\n",
       "      <td>2.077749</td>\n",
       "      <td>2.226337</td>\n",
       "      <td>1.829515</td>\n",
       "      <td>1.847804</td>\n",
       "      <td>2.379905</td>\n",
       "      <td>1.845045</td>\n",
       "      <td>1.795665</td>\n",
       "      <td>2.287506</td>\n",
       "      <td>1.785755</td>\n",
       "      <td>1.887604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.500612</td>\n",
       "      <td>1.720985</td>\n",
       "      <td>1.807324</td>\n",
       "      <td>1.807324</td>\n",
       "      <td>1.275551</td>\n",
       "      <td>72.090142</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>0.850896</td>\n",
       "      <td>1.678414</td>\n",
       "      <td>1.728527</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.530184</td>\n",
       "      <td>1.542092</td>\n",
       "      <td>1.649094</td>\n",
       "      <td>1.637964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594692</td>\n",
       "      <td>1.444080</td>\n",
       "      <td>1.485704</td>\n",
       "      <td>1.570558</td>\n",
       "      <td>2.043614</td>\n",
       "      <td>2.612285</td>\n",
       "      <td>2.601949</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>1.390836</td>\n",
       "      <td>1.391946</td>\n",
       "      <td>1.390878</td>\n",
       "      <td>1.404288</td>\n",
       "      <td>1.417763</td>\n",
       "      <td>1.890971</td>\n",
       "      <td>4.681458e+13</td>\n",
       "      <td>1.587441</td>\n",
       "      <td>1.469083</td>\n",
       "      <td>2.353110</td>\n",
       "      <td>1.172988e+14</td>\n",
       "      <td>1.632409</td>\n",
       "      <td>1.497848</td>\n",
       "      <td>1.454201</td>\n",
       "      <td>1.070829</td>\n",
       "      <td>1.639399</td>\n",
       "      <td>1.524623</td>\n",
       "      <td>1.810247</td>\n",
       "      <td>1.390653</td>\n",
       "      <td>3.318812</td>\n",
       "      <td>2.023938</td>\n",
       "      <td>1.390648</td>\n",
       "      <td>1.218348</td>\n",
       "      <td>2.055960</td>\n",
       "      <td>4.136394</td>\n",
       "      <td>1.390648</td>\n",
       "      <td>1.514513</td>\n",
       "      <td>1.343105</td>\n",
       "      <td>1.476317</td>\n",
       "      <td>1.377438</td>\n",
       "      <td>1.481749</td>\n",
       "      <td>1.837184</td>\n",
       "      <td>1.496323</td>\n",
       "      <td>1.43371</td>\n",
       "      <td>1.489761</td>\n",
       "      <td>1.877357</td>\n",
       "      <td>1.809692</td>\n",
       "      <td>0.850870</td>\n",
       "      <td>3.182821e-10</td>\n",
       "      <td>0.851026</td>\n",
       "      <td>2.213021e-10</td>\n",
       "      <td>4.607289e-10</td>\n",
       "      <td>4.136394</td>\n",
       "      <td>1.788298</td>\n",
       "      <td>4.701129</td>\n",
       "      <td>4.701129</td>\n",
       "      <td>1.586375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806614</td>\n",
       "      <td>0.705711</td>\n",
       "      <td>0.838255</td>\n",
       "      <td>0.723474</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>0.166830</td>\n",
       "      <td>0.189858</td>\n",
       "      <td>0.752142</td>\n",
       "      <td>0.834631</td>\n",
       "      <td>0.910696</td>\n",
       "      <td>0.864192</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.328811</td>\n",
       "      <td>0.398628</td>\n",
       "      <td>0.318355</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>1.914494</td>\n",
       "      <td>1.785579</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.153228</td>\n",
       "      <td>0.183809</td>\n",
       "      <td>0.806474</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.823607</td>\n",
       "      <td>0.981154</td>\n",
       "      <td>0.328811</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>0.327448</td>\n",
       "      <td>0.385011</td>\n",
       "      <td>2.90500</td>\n",
       "      <td>2.905000</td>\n",
       "      <td>1.775542</td>\n",
       "      <td>1.772948</td>\n",
       "      <td>3.532083</td>\n",
       "      <td>0.602670</td>\n",
       "      <td>0.630745</td>\n",
       "      <td>0.619208</td>\n",
       "      <td>0.622092</td>\n",
       "      <td>0.643743</td>\n",
       "      <td>0.622298</td>\n",
       "      <td>0.613938</td>\n",
       "      <td>0.715906</td>\n",
       "      <td>0.76373</td>\n",
       "      <td>0.744245</td>\n",
       "      <td>0.791746</td>\n",
       "      <td>0.709642</td>\n",
       "      <td>2.022631</td>\n",
       "      <td>1.581238</td>\n",
       "      <td>1.079619</td>\n",
       "      <td>1.518728</td>\n",
       "      <td>1.704454</td>\n",
       "      <td>1.112845</td>\n",
       "      <td>2.421541</td>\n",
       "      <td>1.725049</td>\n",
       "      <td>1.099303</td>\n",
       "      <td>1.535270</td>\n",
       "      <td>1.742883</td>\n",
       "      <td>0.00192</td>\n",
       "      <td>1.937167</td>\n",
       "      <td>1.472853</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>2.156948</td>\n",
       "      <td>1.485565</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>1.756306</td>\n",
       "      <td>1.482906</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>1.167922</td>\n",
       "      <td>0.764731</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>1.757511</td>\n",
       "      <td>0.854387</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>1.175869</td>\n",
       "      <td>0.820818</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>1.692572</td>\n",
       "      <td>0.771235</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>1.754491</td>\n",
       "      <td>0.713711</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>1.664385</td>\n",
       "      <td>0.551754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ARDRegression{}  BayesianRidge{}  \\\n",
       "rmse_cv               1.936501         1.849728   \n",
       "rmse_training         1.500612         1.720985   \n",
       "\n",
       "               ElasticNet{'selection': 'cyclic'}  \\\n",
       "rmse_cv                                 1.854198   \n",
       "rmse_training                           1.807324   \n",
       "\n",
       "               ElasticNet{'selection': 'random'}  HuberRegressor{}  \\\n",
       "rmse_cv                                 1.854542          2.576841   \n",
       "rmse_training                           1.807324          1.275551   \n",
       "\n",
       "                      Lars{}  Lasso{'selection': 'cyclic'}  \\\n",
       "rmse_cv        337226.643178                      1.844538   \n",
       "rmse_training      72.090142                      1.809692   \n",
       "\n",
       "               Lasso{'selection': 'random'}  LassoLars{}  LinearRegression{}  \\\n",
       "rmse_cv                            1.844538     1.844538            8.022427   \n",
       "rmse_training                      1.809692     1.809692            0.850896   \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}  \\\n",
       "rmse_cv                                                 1.986954            \n",
       "rmse_training                                           1.678414            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'saga'}  \\\n",
       "rmse_cv                                                 2.064786       \n",
       "rmse_training                                           1.728527       \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}  \\\n",
       "rmse_cv                                                 2.362686            \n",
       "rmse_training                                           1.542092            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.362686        \n",
       "rmse_training                                           1.542092        \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}  \\\n",
       "rmse_cv                                                 2.156346            \n",
       "rmse_training                                           1.530184            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'sag'}  \\\n",
       "rmse_cv                                                 2.246902      \n",
       "rmse_training                                           1.542092      \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'saga'}  \\\n",
       "rmse_cv                                                 2.246902       \n",
       "rmse_training                                           1.649094       \n",
       "\n",
       "               LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}  \\\n",
       "rmse_cv                                                 2.179860                                \n",
       "rmse_training                                           1.637964                                \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}  \\\n",
       "rmse_cv                                                 2.530378              \n",
       "rmse_training                                           0.000000              \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.357410          \n",
       "rmse_training                                           0.594692          \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'sag'}  \\\n",
       "rmse_cv                                                 2.554081        \n",
       "rmse_training                                           1.444080        \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'saga'}  \\\n",
       "rmse_cv                                                 2.393976         \n",
       "rmse_training                                           1.485704         \n",
       "\n",
       "               OrthogonalMatchingPursuit{}  \\\n",
       "rmse_cv                           1.945627   \n",
       "rmse_training                     1.570558   \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_cv                                                 2.294083           \n",
       "rmse_training                                           2.043614           \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_cv                                                 2.186708                   \n",
       "rmse_training                                           2.612285                   \n",
       "\n",
       "               RANSACRegressor{}  Ridge{'solver': 'svd'}  \\\n",
       "rmse_cv                15.167141                2.012011   \n",
       "rmse_training           2.601949                1.390836   \n",
       "\n",
       "               Ridge{'solver': 'cholesky'}  Ridge{'solver': 'lsqr'}  \\\n",
       "rmse_cv                           2.012011                 2.009916   \n",
       "rmse_training                     1.390836                 1.391946   \n",
       "\n",
       "               Ridge{'solver': 'sparse_cg'}  Ridge{'solver': 'sag'}  \\\n",
       "rmse_cv                            2.012109                2.012058   \n",
       "rmse_training                      1.390878                1.404288   \n",
       "\n",
       "               Ridge{'solver': 'saga'}  \\\n",
       "rmse_cv                       2.009161   \n",
       "rmse_training                 1.417763   \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}  \\\n",
       "rmse_cv                                                 2.787248            \n",
       "rmse_training                                           1.890971            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}  \\\n",
       "rmse_cv                                             1.011803e+14           \n",
       "rmse_training                                       4.681458e+13           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_cv                                                 1.948427              \n",
       "rmse_training                                           1.587441              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_cv                                                 1.995468            \n",
       "rmse_training                                           1.469083            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}  \\\n",
       "rmse_cv                                                 2.293446            \n",
       "rmse_training                                           2.353110            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}  \\\n",
       "rmse_cv                                             8.042401e+13           \n",
       "rmse_training                                       1.172988e+14           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_cv                                                 1.944068              \n",
       "rmse_training                                           1.632409              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_cv                                                 1.950731            \n",
       "rmse_training                                           1.497848            \n",
       "\n",
       "               SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_cv                                                 1.952146                    \n",
       "rmse_training                                           1.454201                    \n",
       "\n",
       "               TheilSenRegressor{}  TweedieRegressor{'link': 'identity'}  \\\n",
       "rmse_cv                   8.693768                              1.851942   \n",
       "rmse_training             1.070829                              1.639399   \n",
       "\n",
       "               TweedieRegressor{'link': 'log'}  KernelRidge 1**2  \\\n",
       "rmse_cv                               2.114588          1.842443   \n",
       "rmse_training                         1.524623          1.810247   \n",
       "\n",
       "               KernelRidge DotProduct(sigma_0=1)  \\\n",
       "rmse_cv                                 2.011974   \n",
       "rmse_training                           1.390653   \n",
       "\n",
       "               KernelRidge ExpSineSquared(length_scale=1, periodicity=1)  \\\n",
       "rmse_cv                                                15.776251           \n",
       "rmse_training                                           3.318812           \n",
       "\n",
       "               KernelRidge Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_cv                                          4.042328   \n",
       "rmse_training                                    2.023938   \n",
       "\n",
       "               KernelRidge PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_cv                                                 2.011973      \n",
       "rmse_training                                           1.390648      \n",
       "\n",
       "               KernelRidge RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_cv                                                 2.578366        \n",
       "rmse_training                                           1.218348        \n",
       "\n",
       "               KernelRidge RBF(length_scale=1)  \\\n",
       "rmse_cv                               4.083858   \n",
       "rmse_training                         2.055960   \n",
       "\n",
       "               KernelRidge WhiteKernel(noise_level=1)  KernelRidge linear  \\\n",
       "rmse_cv                                      4.099670            2.011973   \n",
       "rmse_training                                4.136394            1.390648   \n",
       "\n",
       "               LinearSVR{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_cv                                        2.167655   \n",
       "rmse_training                                  1.514513   \n",
       "\n",
       "               LinearSVR{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_cv                                                2.052190   \n",
       "rmse_training                                          1.343105   \n",
       "\n",
       "               NuSVR{'kernel': 'linear'}  NuSVR{'kernel': 'poly'}  \\\n",
       "rmse_cv                         1.916470                 1.770307   \n",
       "rmse_training                   1.476317                 1.377438   \n",
       "\n",
       "               NuSVR{'kernel': 'rbf'}  NuSVR{'kernel': 'sigmoid'}  \\\n",
       "rmse_cv                      1.742634                    1.851783   \n",
       "rmse_training                1.481749                    1.837184   \n",
       "\n",
       "               SVR{'kernel': 'linear'}  SVR{'kernel': 'poly'}  \\\n",
       "rmse_cv                       2.133088                1.82145   \n",
       "rmse_training                 1.496323                1.43371   \n",
       "\n",
       "               SVR{'kernel': 'rbf'}  SVR{'kernel': 'sigmoid'}  \\\n",
       "rmse_cv                    1.720149                  1.933953   \n",
       "rmse_training              1.489761                  1.877357   \n",
       "\n",
       "               GaussianProcessRegressor 1**2  \\\n",
       "rmse_cv                             3.456524   \n",
       "rmse_training                       1.809692   \n",
       "\n",
       "               GaussianProcessRegressor DotProduct(sigma_0=1)  \\\n",
       "rmse_cv                                              8.021744   \n",
       "rmse_training                                        0.850870   \n",
       "\n",
       "               GaussianProcessRegressor Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_cv                                             1.773059e+00         \n",
       "rmse_training                                       3.182821e-10         \n",
       "\n",
       "               GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_cv                                                 8.021249                   \n",
       "rmse_training                                           0.851026                   \n",
       "\n",
       "               GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_cv                                             1.705117e+00                     \n",
       "rmse_training                                       2.213021e-10                     \n",
       "\n",
       "               GaussianProcessRegressor RBF(length_scale=1)  \\\n",
       "rmse_cv                                        2.039888e+00   \n",
       "rmse_training                                  4.607289e-10   \n",
       "\n",
       "               GaussianProcessRegressor WhiteKernel(noise_level=1)     CCA{}  \\\n",
       "rmse_cv                                                 4.099670    1.841178   \n",
       "rmse_training                                           4.136394    1.788298   \n",
       "\n",
       "               PLSCanonical{'algorithm': 'nipals'}  \\\n",
       "rmse_cv                                   4.974416   \n",
       "rmse_training                             4.701129   \n",
       "\n",
       "               PLSCanonical{'algorithm': 'svd'}  PLSRegression{}  \\\n",
       "rmse_cv                                4.974416         1.890073   \n",
       "rmse_training                          4.701129         1.586375   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.376388                                      \n",
       "rmse_training                                           0.000000                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.177195                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.429694                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.537739                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.277032                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                  2.44195                                          \n",
       "rmse_training                                            0.00000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                  2.34612                                          \n",
       "rmse_training                                            0.00000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.582957                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.266488                                               \n",
       "rmse_training                                           0.000000                                               \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.338288                                                 \n",
       "rmse_training                                           0.000000                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.358372                                                 \n",
       "rmse_training                                           0.000000                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.115753                                                 \n",
       "rmse_training                                           0.000000                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.401824                                                 \n",
       "rmse_training                                           0.000000                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.474385                                                   \n",
       "rmse_training                                           0.000000                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.538839                                                   \n",
       "rmse_training                                           0.000000                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.350313                                                   \n",
       "rmse_training                                           0.000000                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.443885                                      \n",
       "rmse_training                                           0.000000                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.256926                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.280453                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.495793                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.586878                                        \n",
       "rmse_training                                           0.000000                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.333232                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.598571                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.536448                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.652689                                          \n",
       "rmse_training                                           0.000000                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.405583                                            \n",
       "rmse_training                                           0.000000                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.647083                                            \n",
       "rmse_training                                           0.000000                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.639092                                            \n",
       "rmse_training                                           0.000000                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.300325                                            \n",
       "rmse_training                                           0.000000                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.405749                                              \n",
       "rmse_training                                           0.000000                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.571787                                              \n",
       "rmse_training                                           0.000000                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.468389                                              \n",
       "rmse_training                                           0.000000                                              \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'linear'}  \\\n",
       "rmse_cv                                   1.772216   \n",
       "rmse_training                             0.806614   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'square'}  \\\n",
       "rmse_cv                                   1.904255   \n",
       "rmse_training                             0.705711   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'exponential'}  BaggingRegressor{}  \\\n",
       "rmse_cv                                        1.783083            1.801408   \n",
       "rmse_training                                  0.838255            0.723474   \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                  1.66617                 \n",
       "rmse_training                                            0.00000                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                  1.70657                 \n",
       "rmse_training                                            0.00000                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.694374                 \n",
       "rmse_training                                           0.000000                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.705887                 \n",
       "rmse_training                                           0.000000                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.730025               \n",
       "rmse_training                                           0.000000               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.745496               \n",
       "rmse_training                                           0.000000               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.666103            \n",
       "rmse_training                                           0.027806            \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.653418            \n",
       "rmse_training                                           0.000000            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.764701                                            \n",
       "rmse_training                                           0.117268                                            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.746421                                              \n",
       "rmse_training                                           0.119379                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.727822                                              \n",
       "rmse_training                                           0.166830                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.687527                                              \n",
       "rmse_training                                           0.189858                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.708785                                             \n",
       "rmse_training                                           0.752142                                             \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.718697                                               \n",
       "rmse_training                                           0.834631                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.669033                                               \n",
       "rmse_training                                           0.910696                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.643558                                               \n",
       "rmse_training                                           0.864192                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.702957                                               \n",
       "rmse_training                                           0.344400                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.710143                                                 \n",
       "rmse_training                                           0.328811                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.677468                                                 \n",
       "rmse_training                                           0.398628                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.656262                                                 \n",
       "rmse_training                                           0.318355                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.937517                                                  \n",
       "rmse_training                                           2.905000                                                  \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.938707                                                    \n",
       "rmse_training                                           2.905000                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.110567                                                    \n",
       "rmse_training                                           1.914494                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.135575                                                    \n",
       "rmse_training                                           1.785579                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.779361                                   \n",
       "rmse_training                                           0.117268                                   \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.774450                                     \n",
       "rmse_training                                           0.117268                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.632296                                     \n",
       "rmse_training                                           0.153228                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.707787                                     \n",
       "rmse_training                                           0.183809                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.691127                                    \n",
       "rmse_training                                           0.806474                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.673572                                      \n",
       "rmse_training                                           0.784466                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.725870                                      \n",
       "rmse_training                                           0.823607                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.718344                                      \n",
       "rmse_training                                           0.981154                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.733118                                      \n",
       "rmse_training                                           0.328811                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 1.727884                                        \n",
       "rmse_training                                           0.344400                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.733573                                        \n",
       "rmse_training                                           0.327448                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.765523                                        \n",
       "rmse_training                                           0.385011                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_cv                                                  2.92387                                         \n",
       "rmse_training                                            2.90500                                         \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_cv                                                 2.907732                                           \n",
       "rmse_training                                           2.905000                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 2.153590                                           \n",
       "rmse_training                                           1.775542                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.100161                                           \n",
       "rmse_training                                           1.772948                                           \n",
       "\n",
       "               IsolationForest{}  \\\n",
       "rmse_cv                 3.523848   \n",
       "rmse_training           3.532083   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.688684                   \n",
       "rmse_training                                           0.602670                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.726894                   \n",
       "rmse_training                                           0.630745                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.702976                 \n",
       "rmse_training                                           0.619208                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.684268              \n",
       "rmse_training                                           0.622092              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                 1.699553                   \n",
       "rmse_training                                           0.643743                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 1.719358                   \n",
       "rmse_training                                           0.622298                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_cv                                                 1.741653                 \n",
       "rmse_training                                           0.613938                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.684139              \n",
       "rmse_training                                           0.715906              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}  \\\n",
       "rmse_cv                                                  2.05660                       \n",
       "rmse_training                                            0.76373                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}  \\\n",
       "rmse_cv                                                 2.029211                       \n",
       "rmse_training                                           0.744245                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': None}  \\\n",
       "rmse_cv                                                 2.195140                     \n",
       "rmse_training                                           0.791746                     \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}  \\\n",
       "rmse_cv                                                 1.814501                  \n",
       "rmse_training                                           0.709642                  \n",
       "\n",
       "               StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \\\n",
       "rmse_cv                                                 1.836144                                                                                                                                                \n",
       "rmse_training                                           2.022631                                                                                                                                                \n",
       "\n",
       "               VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \\\n",
       "rmse_cv                                                 1.815186                                                                                                                                              \n",
       "rmse_training                                           1.581238                                                                                                                                              \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.685312                                         \n",
       "rmse_training                                           1.079619                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.939891                                       \n",
       "rmse_training                                           1.518728                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 2.039910                                        \n",
       "rmse_training                                           1.704454                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.603890                                           \n",
       "rmse_training                                           1.112845                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.962460                                         \n",
       "rmse_training                                           2.421541                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.942471                                          \n",
       "rmse_training                                           1.725049                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.532667                                         \n",
       "rmse_training                                           1.099303                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.929567                                       \n",
       "rmse_training                                           1.535270                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 2.089535                                        \n",
       "rmse_training                                           1.742883                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                  2.50669                                         \n",
       "rmse_training                                            0.00192                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.969280                                       \n",
       "rmse_training                                           1.937167                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.883001                                        \n",
       "rmse_training                                           1.472853                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.211726                                           \n",
       "rmse_training                                           0.001569                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.996911                                         \n",
       "rmse_training                                           2.156948                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.882330                                          \n",
       "rmse_training                                           1.485565                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.422484                                         \n",
       "rmse_training                                           0.001793                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.849734                                       \n",
       "rmse_training                                           1.756306                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.897464                                        \n",
       "rmse_training                                           1.482906                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.301830                                     \n",
       "rmse_training                                           0.000503                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.876582                                   \n",
       "rmse_training                                           1.167922                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 2.055804                                    \n",
       "rmse_training                                           0.764731                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.212011                                       \n",
       "rmse_training                                           0.000433                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.936340                                     \n",
       "rmse_training                                           1.757511                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.884506                                      \n",
       "rmse_training                                           0.854387                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.451246                                     \n",
       "rmse_training                                           0.000501                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.879909                                   \n",
       "rmse_training                                           1.175869                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 2.077749                                    \n",
       "rmse_training                                           0.820818                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.226337                                     \n",
       "rmse_training                                           0.001034                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.829515                                   \n",
       "rmse_training                                           1.692572                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.847804                                    \n",
       "rmse_training                                           0.771235                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.379905                                       \n",
       "rmse_training                                           0.000450                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.845045                                     \n",
       "rmse_training                                           1.754491                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_cv                                                 1.795665                                      \n",
       "rmse_training                                           0.713711                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_cv                                                 2.287506                                     \n",
       "rmse_training                                           0.000859                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_cv                                                 1.785755                                   \n",
       "rmse_training                                           1.664385                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}  \n",
       "rmse_cv                                                 1.887604                                   \n",
       "rmse_training                                           0.551754                                   "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "result = pd.concat([result_lm, result_kr, result_svm, result_gpr, result_cd, result_tree, result_ens, result_nn] , axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow we have to decide to continue working with a few models. The models aren't good at the moment. Some of them overfits (cv error is high, training error low), when others underfit (validation and training error high) data. In fact, we don't want to prevent underfitting yet. To do it we should select model with more parameters (we've tested a lot of models), find better features (we've done some attribute combinations) or reduce regularization hyperparameter, what is harder than try to prevent overfitting in other models. At first, we will prevent oferfitting by reducing the number of attributes in the training data for a few models with best rmse_cv result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}                1.632296\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}      1.643558\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}                                         1.653418\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}    1.656262\n",
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}                                         1.666103\n",
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}                                    1.666170\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}      1.669033\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}               1.673572\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}    1.677468\n",
       "RandomForestRegressor{'criterion': 'mae', 'max_features': 1}                                       1.684139\n",
       "RandomForestRegressor{'criterion': 'mse', 'max_features': 1}                                       1.684268\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}       1.687527\n",
       "RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}                                  1.688684\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}                 1.691127\n",
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}                                    1.694374\n",
       "RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}                                  1.699553\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}      1.702957\n",
       "RandomForestRegressor{'criterion': 'mse', 'max_features': None}                                    1.702976\n",
       "GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)                                1.705117\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}                                    1.705887\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}                                    1.706570\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}                1.707787\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}        1.708785\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}    1.710143\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}               1.718344\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}      1.718697\n",
       "RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}                                  1.719358\n",
       "SVR{'kernel': 'rbf'}                                                                               1.720149\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}               1.725870\n",
       "RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}                                  1.726894\n",
       "Name: rmse_cv, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc['rmse_cv'].sort_values().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming our approach, let's prevent overfitting for GradientBoostingRegressor, ExtraTreesRegressor and RandomForestRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Fine-tuning </h2>\n",
    "\n",
    "<h3> This chapter has been moved to fine_tuning.ipynb. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> Evaluate on the test set </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_set_new_ready, train_set_labels\n",
    "\n",
    "test_set_new = test_set.copy()\n",
    "test_set_new = test_set_new[test_set_new['age'].notna()]\n",
    "test_set_labels = test_set_new[\"age\"].copy()\n",
    "test_set_new = test_set_new.drop(\"age\", axis=1)\n",
    "\n",
    "test_set_new_ready = pipeline.transform(test_set_new)\n",
    "test_set_new_ready.shape\n",
    "\n",
    "X_test, y_test = test_set_new_ready, test_set_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0231537698587716"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributions = { 'learning_rate':[0.1], # fixed\n",
    "                  'n_estimators': [49], # tuned x2\n",
    "                  'max_depth': [1], # tuned\n",
    "                  'min_child_weight': [4], # tuned\n",
    "                  'gamma': [0.51], # tuned\n",
    "                  'subsample': [0.8], # tuned\n",
    "                  'colsample_bytree': [0.68], # tuned\n",
    "                  'reg_alpha': [0.0005], # tuned\n",
    "                  'reg_lambda': [3.62], # tuned\n",
    "                }\n",
    "\n",
    "XGBRegressor = RandomizedSearchCV(XGBRegressor(), distributions, n_iter=1, random_state=42)\n",
    "\n",
    "XGBRegressor.fit(X, y)\n",
    "\n",
    "final_predictions = XGBRegressor.predict(X_test)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1801542933938376"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributions = { 'n_estimators': [21], # tuning x2\n",
    "                  'max_features': [6], # tuned\n",
    "                  'min_samples_split': [8], # tuned\n",
    "                  'max_depth': [9], # tuned \n",
    "                  'max_leaf_nodes': [None], # tuned \n",
    "                  'max_samples': [None], # tuned \n",
    "                }\n",
    "\n",
    "XGBRegressor = RandomizedSearchCV(ensemble.ExtraTreesRegressor(), distributions, n_iter=1, random_state=42)\n",
    "\n",
    "XGBRegressor.fit(X, y)\n",
    "\n",
    "final_predictions = XGBRegressor.predict(X_test)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.973687952605298"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributions = { 'n_estimators': [43], # tuned\n",
    "                  'max_features': [4], # tuned\n",
    "                  'max_depth': [5], # tuned\n",
    "                  'max_leaf_nodes': [4], # tuning \n",
    "                  'max_samples': [0.9], # tuning \n",
    "                }\n",
    "\n",
    "XGBRegressor = RandomizedSearchCV(ensemble.RandomForestRegressor(), distributions, n_iter=1, random_state=42)\n",
    "\n",
    "XGBRegressor.fit(X, y)\n",
    "\n",
    "final_predictions = XGBRegressor.predict(X_test)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Bibliography </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@outside2SDs/an-overview-of-correlation-measures-between-categorical-and-continuous-variables-4c7f85610365\n",
    "\n",
    "https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "https://stats.stackexchange.com/questions/187335/validation-error-less-than-training-error\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/05/feature-transformations-in-data-science-a-detailed-walkthrough/\n",
    "\n",
    "https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
