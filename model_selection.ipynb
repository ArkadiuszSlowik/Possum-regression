{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7237f604-7251-4ade-95ba-260a12f89663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn import ensemble\n",
    "from sklearn import isotonic\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "751606bb-0bb0-48df-a3ee-1ab638219d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ml_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c04b8-534f-4581-9ea4-c23d16a68198",
   "metadata": {},
   "source": [
    "Our plan is to test as many as possible models, with some different settings, in a short time, then choose a few most promising for hyperparameter tuning, based on rmse measure for training set and cross-validation.\n",
    "\n",
    "Let's calculate RMSE for training data and mean value of RMSE for Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeeeeaf-c117-4926-8b64-9d64521b0a0b",
   "metadata": {},
   "source": [
    "<h2> Finding promising models </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650ecc5-6436-4849-9e8e-b9cfd9399b37",
   "metadata": {},
   "source": [
    "<h3> Linear Models </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "d97523a7-ad4e-4833-bf03-a27c9ee1eedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARDRegression{}</th>\n",
       "      <th>BayesianRidge{}</th>\n",
       "      <th>ElasticNet{'selection': 'cyclic'}</th>\n",
       "      <th>ElasticNet{'selection': 'random'}</th>\n",
       "      <th>HuberRegressor{}</th>\n",
       "      <th>Lars{}</th>\n",
       "      <th>Lasso{'selection': 'cyclic'}</th>\n",
       "      <th>Lasso{'selection': 'random'}</th>\n",
       "      <th>LassoLars{}</th>\n",
       "      <th>LinearRegression{}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'saga'}</th>\n",
       "      <th>OrthogonalMatchingPursuit{}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>RANSACRegressor{}</th>\n",
       "      <th>Ridge{'solver': 'svd'}</th>\n",
       "      <th>Ridge{'solver': 'cholesky'}</th>\n",
       "      <th>Ridge{'solver': 'lsqr'}</th>\n",
       "      <th>Ridge{'solver': 'sparse_cg'}</th>\n",
       "      <th>Ridge{'solver': 'sag'}</th>\n",
       "      <th>Ridge{'solver': 'saga'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>TheilSenRegressor{}</th>\n",
       "      <th>TweedieRegressor{'link': 'identity'}</th>\n",
       "      <th>TweedieRegressor{'link': 'log'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.506267</td>\n",
       "      <td>1.715081</td>\n",
       "      <td>1.797770</td>\n",
       "      <td>1.797770</td>\n",
       "      <td>1.252213</td>\n",
       "      <td>151.759964</td>\n",
       "      <td>1.800469</td>\n",
       "      <td>1.800469</td>\n",
       "      <td>1.800469</td>\n",
       "      <td>0.939249</td>\n",
       "      <td>1.689799</td>\n",
       "      <td>1.711055</td>\n",
       "      <td>1.532774</td>\n",
       "      <td>1.532774</td>\n",
       "      <td>1.686231</td>\n",
       "      <td>1.532774</td>\n",
       "      <td>1.594418</td>\n",
       "      <td>1.642801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.439545</td>\n",
       "      <td>1.370955</td>\n",
       "      <td>1.569185</td>\n",
       "      <td>2.500821</td>\n",
       "      <td>1.726135</td>\n",
       "      <td>3.010502</td>\n",
       "      <td>1.391042</td>\n",
       "      <td>1.391042</td>\n",
       "      <td>1.392067</td>\n",
       "      <td>1.391138</td>\n",
       "      <td>1.404622</td>\n",
       "      <td>1.418174</td>\n",
       "      <td>1.799081</td>\n",
       "      <td>5.343158e+13</td>\n",
       "      <td>1.529367</td>\n",
       "      <td>1.469588</td>\n",
       "      <td>1.653560</td>\n",
       "      <td>5.249754e+13</td>\n",
       "      <td>1.499131</td>\n",
       "      <td>1.455185</td>\n",
       "      <td>1.455261</td>\n",
       "      <td>1.224849</td>\n",
       "      <td>1.637558</td>\n",
       "      <td>1.520938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.952275</td>\n",
       "      <td>1.842220</td>\n",
       "      <td>1.856344</td>\n",
       "      <td>1.856345</td>\n",
       "      <td>2.604354</td>\n",
       "      <td>2732.996970</td>\n",
       "      <td>1.848290</td>\n",
       "      <td>1.848290</td>\n",
       "      <td>1.848290</td>\n",
       "      <td>7.029047</td>\n",
       "      <td>2.082422</td>\n",
       "      <td>2.163032</td>\n",
       "      <td>2.337529</td>\n",
       "      <td>2.337529</td>\n",
       "      <td>2.233059</td>\n",
       "      <td>2.376075</td>\n",
       "      <td>2.369071</td>\n",
       "      <td>2.163365</td>\n",
       "      <td>2.697142</td>\n",
       "      <td>2.676737</td>\n",
       "      <td>2.468347</td>\n",
       "      <td>2.428084</td>\n",
       "      <td>1.881482</td>\n",
       "      <td>2.612527</td>\n",
       "      <td>2.416350</td>\n",
       "      <td>11.230984</td>\n",
       "      <td>2.005982</td>\n",
       "      <td>2.005982</td>\n",
       "      <td>2.003769</td>\n",
       "      <td>2.006426</td>\n",
       "      <td>2.007351</td>\n",
       "      <td>2.004973</td>\n",
       "      <td>2.101843</td>\n",
       "      <td>8.007630e+13</td>\n",
       "      <td>1.941779</td>\n",
       "      <td>2.009306</td>\n",
       "      <td>1.985288</td>\n",
       "      <td>9.025170e+13</td>\n",
       "      <td>1.961738</td>\n",
       "      <td>1.995042</td>\n",
       "      <td>1.992949</td>\n",
       "      <td>7.631957</td>\n",
       "      <td>1.849276</td>\n",
       "      <td>2.088724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ARDRegression{}  BayesianRidge{}  \\\n",
       "rmse_training         1.506267         1.715081   \n",
       "rmse_cv               1.952275         1.842220   \n",
       "\n",
       "               ElasticNet{'selection': 'cyclic'}  \\\n",
       "rmse_training                           1.797770   \n",
       "rmse_cv                                 1.856344   \n",
       "\n",
       "               ElasticNet{'selection': 'random'}  HuberRegressor{}  \\\n",
       "rmse_training                           1.797770          1.252213   \n",
       "rmse_cv                                 1.856345          2.604354   \n",
       "\n",
       "                    Lars{}  Lasso{'selection': 'cyclic'}  \\\n",
       "rmse_training   151.759964                      1.800469   \n",
       "rmse_cv        2732.996970                      1.848290   \n",
       "\n",
       "               Lasso{'selection': 'random'}  LassoLars{}  LinearRegression{}  \\\n",
       "rmse_training                      1.800469     1.800469            0.939249   \n",
       "rmse_cv                            1.848290     1.848290            7.029047   \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}  \\\n",
       "rmse_training                                           1.689799            \n",
       "rmse_cv                                                 2.082422            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.711055       \n",
       "rmse_cv                                                 2.163032       \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}  \\\n",
       "rmse_training                                           1.532774            \n",
       "rmse_cv                                                 2.337529            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.532774        \n",
       "rmse_cv                                                 2.337529        \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}  \\\n",
       "rmse_training                                           1.686231            \n",
       "rmse_cv                                                 2.233059            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'sag'}  \\\n",
       "rmse_training                                           1.532774      \n",
       "rmse_cv                                                 2.376075      \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.594418       \n",
       "rmse_cv                                                 2.369071       \n",
       "\n",
       "               LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}  \\\n",
       "rmse_training                                           1.642801                                \n",
       "rmse_cv                                                 2.163365                                \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}  \\\n",
       "rmse_training                                           0.000000              \n",
       "rmse_cv                                                 2.697142              \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000000          \n",
       "rmse_cv                                                 2.676737          \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'sag'}  \\\n",
       "rmse_training                                           1.439545        \n",
       "rmse_cv                                                 2.468347        \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.370955         \n",
       "rmse_cv                                                 2.428084         \n",
       "\n",
       "               OrthogonalMatchingPursuit{}  \\\n",
       "rmse_training                     1.569185   \n",
       "rmse_cv                           1.881482   \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_training                                           2.500821           \n",
       "rmse_cv                                                 2.612527           \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_training                                           1.726135                   \n",
       "rmse_cv                                                 2.416350                   \n",
       "\n",
       "               RANSACRegressor{}  Ridge{'solver': 'svd'}  \\\n",
       "rmse_training           3.010502                1.391042   \n",
       "rmse_cv                11.230984                2.005982   \n",
       "\n",
       "               Ridge{'solver': 'cholesky'}  Ridge{'solver': 'lsqr'}  \\\n",
       "rmse_training                     1.391042                 1.392067   \n",
       "rmse_cv                           2.005982                 2.003769   \n",
       "\n",
       "               Ridge{'solver': 'sparse_cg'}  Ridge{'solver': 'sag'}  \\\n",
       "rmse_training                      1.391138                1.404622   \n",
       "rmse_cv                            2.006426                2.007351   \n",
       "\n",
       "               Ridge{'solver': 'saga'}  \\\n",
       "rmse_training                 1.418174   \n",
       "rmse_cv                       2.004973   \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}  \\\n",
       "rmse_training                                           1.799081            \n",
       "rmse_cv                                                 2.101843            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}  \\\n",
       "rmse_training                                       5.343158e+13           \n",
       "rmse_cv                                             8.007630e+13           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_training                                           1.529367              \n",
       "rmse_cv                                                 1.941779              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.469588            \n",
       "rmse_cv                                                 2.009306            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}  \\\n",
       "rmse_training                                           1.653560            \n",
       "rmse_cv                                                 1.985288            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}  \\\n",
       "rmse_training                                       5.249754e+13           \n",
       "rmse_cv                                             9.025170e+13           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_training                                           1.499131              \n",
       "rmse_cv                                                 1.961738              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.455185            \n",
       "rmse_cv                                                 1.995042            \n",
       "\n",
       "               SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.455261                    \n",
       "rmse_cv                                                 1.992949                    \n",
       "\n",
       "               TheilSenRegressor{}  TweedieRegressor{'link': 'identity'}  \\\n",
       "rmse_training             1.224849                              1.637558   \n",
       "rmse_cv                   7.631957                              1.849276   \n",
       "\n",
       "               TweedieRegressor{'link': 'log'}  \n",
       "rmse_training                         1.520938  \n",
       "rmse_cv                               2.088724  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_lm = regression_linear_models(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_lm = pd.DataFrame.from_dict(result_lm)\n",
    "result_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6352e-6f70-4c3e-acb2-471ebaf2525a",
   "metadata": {},
   "source": [
    "<h3> KernelRidge </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "83ee33e7-ca74-40b5-aa14-d91c40acd73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KernelRidge 1**2</th>\n",
       "      <th>KernelRidge DotProduct(sigma_0=1)</th>\n",
       "      <th>KernelRidge ExpSineSquared(length_scale=1, periodicity=1)</th>\n",
       "      <th>KernelRidge Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>KernelRidge PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>KernelRidge RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>KernelRidge RBF(length_scale=1)</th>\n",
       "      <th>KernelRidge WhiteKernel(noise_level=1)</th>\n",
       "      <th>KernelRidge linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.801011</td>\n",
       "      <td>1.391189</td>\n",
       "      <td>3.937000</td>\n",
       "      <td>2.016854</td>\n",
       "      <td>1.391596</td>\n",
       "      <td>1.210426</td>\n",
       "      <td>2.049545</td>\n",
       "      <td>4.124566</td>\n",
       "      <td>1.391596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.846172</td>\n",
       "      <td>2.009819</td>\n",
       "      <td>16.794263</td>\n",
       "      <td>4.033453</td>\n",
       "      <td>2.013866</td>\n",
       "      <td>2.560905</td>\n",
       "      <td>4.076433</td>\n",
       "      <td>4.092971</td>\n",
       "      <td>2.013866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               KernelRidge 1**2  KernelRidge DotProduct(sigma_0=1)  \\\n",
       "rmse_training          1.801011                           1.391189   \n",
       "rmse_cv                1.846172                           2.009819   \n",
       "\n",
       "               KernelRidge ExpSineSquared(length_scale=1, periodicity=1)  \\\n",
       "rmse_training                                           3.937000           \n",
       "rmse_cv                                                16.794263           \n",
       "\n",
       "               KernelRidge Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_training                                    2.016854   \n",
       "rmse_cv                                          4.033453   \n",
       "\n",
       "               KernelRidge PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_training                                           1.391596      \n",
       "rmse_cv                                                 2.013866      \n",
       "\n",
       "               KernelRidge RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_training                                           1.210426        \n",
       "rmse_cv                                                 2.560905        \n",
       "\n",
       "               KernelRidge RBF(length_scale=1)  \\\n",
       "rmse_training                         2.049545   \n",
       "rmse_cv                               4.076433   \n",
       "\n",
       "               KernelRidge WhiteKernel(noise_level=1)  KernelRidge linear  \n",
       "rmse_training                                4.124566            1.391596  \n",
       "rmse_cv                                      4.092971            2.013866  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_kr = regression_kernelridge(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_kr = pd.DataFrame.from_dict(result_kr)\n",
    "result_kr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f6f79-ccf8-4df4-9eb6-81c351a570fd",
   "metadata": {},
   "source": [
    "<h3> SVM </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "f440fa9e-ddf1-4e36-8e75-afa04f0bccc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearSVR{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>LinearSVR{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>NuSVR{'kernel': 'linear'}</th>\n",
       "      <th>NuSVR{'kernel': 'poly'}</th>\n",
       "      <th>NuSVR{'kernel': 'rbf'}</th>\n",
       "      <th>NuSVR{'kernel': 'sigmoid'}</th>\n",
       "      <th>SVR{'kernel': 'linear'}</th>\n",
       "      <th>SVR{'kernel': 'poly'}</th>\n",
       "      <th>SVR{'kernel': 'rbf'}</th>\n",
       "      <th>SVR{'kernel': 'sigmoid'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.480311</td>\n",
       "      <td>1.341842</td>\n",
       "      <td>1.469541</td>\n",
       "      <td>1.402183</td>\n",
       "      <td>1.357156</td>\n",
       "      <td>1.804950</td>\n",
       "      <td>1.478599</td>\n",
       "      <td>1.399200</td>\n",
       "      <td>1.368489</td>\n",
       "      <td>1.838272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.118779</td>\n",
       "      <td>2.045137</td>\n",
       "      <td>1.883343</td>\n",
       "      <td>1.912191</td>\n",
       "      <td>1.717408</td>\n",
       "      <td>1.794709</td>\n",
       "      <td>2.105593</td>\n",
       "      <td>1.982141</td>\n",
       "      <td>1.689241</td>\n",
       "      <td>1.841976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LinearSVR{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_training                                  1.480311   \n",
       "rmse_cv                                        2.118779   \n",
       "\n",
       "               LinearSVR{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_training                                          1.341842   \n",
       "rmse_cv                                                2.045137   \n",
       "\n",
       "               NuSVR{'kernel': 'linear'}  NuSVR{'kernel': 'poly'}  \\\n",
       "rmse_training                   1.469541                 1.402183   \n",
       "rmse_cv                         1.883343                 1.912191   \n",
       "\n",
       "               NuSVR{'kernel': 'rbf'}  NuSVR{'kernel': 'sigmoid'}  \\\n",
       "rmse_training                1.357156                    1.804950   \n",
       "rmse_cv                      1.717408                    1.794709   \n",
       "\n",
       "               SVR{'kernel': 'linear'}  SVR{'kernel': 'poly'}  \\\n",
       "rmse_training                 1.478599               1.399200   \n",
       "rmse_cv                       2.105593               1.982141   \n",
       "\n",
       "               SVR{'kernel': 'rbf'}  SVR{'kernel': 'sigmoid'}  \n",
       "rmse_training              1.368489                  1.838272  \n",
       "rmse_cv                    1.689241                  1.841976  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_svm = regression_svm(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_svm = pd.DataFrame.from_dict(result_svm)\n",
    "result_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49175068-199e-4768-8a6c-986d13ce4566",
   "metadata": {},
   "source": [
    "<h3> Gaussian Process </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "60c911a3-c2ec-4dde-be08-2425a0ef2be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GaussianProcessRegressor 1**2</th>\n",
       "      <th>GaussianProcessRegressor DotProduct(sigma_0=1)</th>\n",
       "      <th>GaussianProcessRegressor Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor RBF(length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor WhiteKernel(noise_level=1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.800469</td>\n",
       "      <td>0.939318</td>\n",
       "      <td>3.179704e-10</td>\n",
       "      <td>0.939254</td>\n",
       "      <td>2.202329e-10</td>\n",
       "      <td>4.608834e-10</td>\n",
       "      <td>4.124566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.047075</td>\n",
       "      <td>7.028944</td>\n",
       "      <td>1.778222e+00</td>\n",
       "      <td>7.028837</td>\n",
       "      <td>1.706544e+00</td>\n",
       "      <td>2.044975e+00</td>\n",
       "      <td>4.092971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GaussianProcessRegressor 1**2  \\\n",
       "rmse_training                       1.800469   \n",
       "rmse_cv                             2.047075   \n",
       "\n",
       "               GaussianProcessRegressor DotProduct(sigma_0=1)  \\\n",
       "rmse_training                                        0.939318   \n",
       "rmse_cv                                              7.028944   \n",
       "\n",
       "               GaussianProcessRegressor Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_training                                       3.179704e-10         \n",
       "rmse_cv                                             1.778222e+00         \n",
       "\n",
       "               GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_training                                           0.939254                   \n",
       "rmse_cv                                                 7.028837                   \n",
       "\n",
       "               GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_training                                       2.202329e-10                     \n",
       "rmse_cv                                             1.706544e+00                     \n",
       "\n",
       "               GaussianProcessRegressor RBF(length_scale=1)  \\\n",
       "rmse_training                                  4.608834e-10   \n",
       "rmse_cv                                        2.044975e+00   \n",
       "\n",
       "               GaussianProcessRegressor WhiteKernel(noise_level=1)  \n",
       "rmse_training                                           4.124566    \n",
       "rmse_cv                                                 4.092971    "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_gpr = regression_gaussianprocess(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_gpr = pd.DataFrame.from_dict(result_gpr)\n",
    "result_gpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde995b8-1dfb-4efb-853b-00d86bca1adb",
   "metadata": {},
   "source": [
    "<h3> Cross Decomposition </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "f4ea3aa9-fd7b-4d7e-9647-75f8e993228f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCA{}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'nipals'}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'svd'}</th>\n",
       "      <th>PLSRegression{}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.782026</td>\n",
       "      <td>4.551446</td>\n",
       "      <td>4.551446</td>\n",
       "      <td>1.600774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.846478</td>\n",
       "      <td>4.881097</td>\n",
       "      <td>4.881097</td>\n",
       "      <td>1.862992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CCA{}  PLSCanonical{'algorithm': 'nipals'}  \\\n",
       "rmse_training  1.782026                             4.551446   \n",
       "rmse_cv        1.846478                             4.881097   \n",
       "\n",
       "               PLSCanonical{'algorithm': 'svd'}  PLSRegression{}  \n",
       "rmse_training                          4.551446         1.600774  \n",
       "rmse_cv                                4.881097         1.862992  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "result_cd = regression_crossdecomposition(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_cd = pd.DataFrame.from_dict(result_cd)\n",
    "result_cd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed659eb-c00e-4596-aa4b-78184cfb79bb",
   "metadata": {},
   "source": [
    "<h3> Decision Tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e68b4c47-2b63-4cb8-b993-d861e9aaa615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.398237</td>\n",
       "      <td>2.182826</td>\n",
       "      <td>2.455718</td>\n",
       "      <td>2.273129</td>\n",
       "      <td>2.4001</td>\n",
       "      <td>2.490975</td>\n",
       "      <td>2.468168</td>\n",
       "      <td>2.092402</td>\n",
       "      <td>2.285991</td>\n",
       "      <td>2.226256</td>\n",
       "      <td>2.073593</td>\n",
       "      <td>2.275142</td>\n",
       "      <td>1.972787</td>\n",
       "      <td>2.403307</td>\n",
       "      <td>2.393248</td>\n",
       "      <td>2.118974</td>\n",
       "      <td>2.639041</td>\n",
       "      <td>2.382275</td>\n",
       "      <td>2.300437</td>\n",
       "      <td>2.199273</td>\n",
       "      <td>2.38598</td>\n",
       "      <td>2.20776</td>\n",
       "      <td>2.26037</td>\n",
       "      <td>2.271676</td>\n",
       "      <td>2.424684</td>\n",
       "      <td>2.578855</td>\n",
       "      <td>2.727583</td>\n",
       "      <td>2.747981</td>\n",
       "      <td>2.361932</td>\n",
       "      <td>2.670653</td>\n",
       "      <td>2.418606</td>\n",
       "      <td>2.750076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                      \n",
       "rmse_cv                                                 2.398237                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.182826                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.455718                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.273129                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                             0.0000                                        \n",
       "rmse_cv                                                   2.4001                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.490975                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.468168                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.092402                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                               \n",
       "rmse_cv                                                 2.285991                                               \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.226256                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.073593                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.275142                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 1.972787                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.403307                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.393248                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.118974                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                      \n",
       "rmse_cv                                                 2.639041                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.382275                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.300437                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.199273                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                            0.00000                                        \n",
       "rmse_cv                                                  2.38598                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                            0.00000                                          \n",
       "rmse_cv                                                  2.20776                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                            0.00000                                          \n",
       "rmse_cv                                                  2.26037                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.271676                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.424684                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.578855                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.727583                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.747981                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.361932                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.670653                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.418606                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}  \n",
       "rmse_training                                           0.000000                                             \n",
       "rmse_cv                                                 2.750076                                             "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tree = regression_decisiontree(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_tree = pd.DataFrame.from_dict(result_tree)\n",
    "result_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117510b-7933-4422-ae87-6affab9e4607",
   "metadata": {},
   "source": [
    "<h3> Ensemble Methods </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "7bbd4dd0-3314-46b5-9a7b-a5991db3cb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoostRegressor{'loss': 'linear'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'square'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'exponential'}</th>\n",
       "      <th>BaggingRegressor{}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>IsolationForest{}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}</th>\n",
       "      <th>StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "      <th>VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>0.800904</td>\n",
       "      <td>0.741088</td>\n",
       "      <td>0.821008</td>\n",
       "      <td>0.796226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144608</td>\n",
       "      <td>0.134223</td>\n",
       "      <td>0.171387</td>\n",
       "      <td>0.180109</td>\n",
       "      <td>0.820328</td>\n",
       "      <td>0.777557</td>\n",
       "      <td>0.759549</td>\n",
       "      <td>0.884338</td>\n",
       "      <td>0.336477</td>\n",
       "      <td>0.338897</td>\n",
       "      <td>0.362962</td>\n",
       "      <td>0.363317</td>\n",
       "      <td>2.906163</td>\n",
       "      <td>2.906163</td>\n",
       "      <td>1.839171</td>\n",
       "      <td>1.763750</td>\n",
       "      <td>0.136624</td>\n",
       "      <td>0.136624</td>\n",
       "      <td>0.136538</td>\n",
       "      <td>0.196127</td>\n",
       "      <td>0.815084</td>\n",
       "      <td>0.767027</td>\n",
       "      <td>0.777966</td>\n",
       "      <td>0.821566</td>\n",
       "      <td>0.338897</td>\n",
       "      <td>0.336477</td>\n",
       "      <td>0.374930</td>\n",
       "      <td>0.388329</td>\n",
       "      <td>2.906163</td>\n",
       "      <td>2.906163</td>\n",
       "      <td>1.845535</td>\n",
       "      <td>1.849931</td>\n",
       "      <td>3.462362</td>\n",
       "      <td>0.615450</td>\n",
       "      <td>0.617170</td>\n",
       "      <td>0.643708</td>\n",
       "      <td>0.606385</td>\n",
       "      <td>0.635773</td>\n",
       "      <td>0.666565</td>\n",
       "      <td>0.662488</td>\n",
       "      <td>0.758665</td>\n",
       "      <td>0.771422</td>\n",
       "      <td>0.733582</td>\n",
       "      <td>0.784405</td>\n",
       "      <td>0.658957</td>\n",
       "      <td>1.887090</td>\n",
       "      <td>1.587453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.702421</td>\n",
       "      <td>1.762869</td>\n",
       "      <td>1.739804</td>\n",
       "      <td>1.773814</td>\n",
       "      <td>1.682685</td>\n",
       "      <td>1.669763</td>\n",
       "      <td>1.671785</td>\n",
       "      <td>1.687687</td>\n",
       "      <td>1.711171</td>\n",
       "      <td>1.774179</td>\n",
       "      <td>1.638060</td>\n",
       "      <td>1.678239</td>\n",
       "      <td>1.792816</td>\n",
       "      <td>1.817878</td>\n",
       "      <td>1.687886</td>\n",
       "      <td>1.748724</td>\n",
       "      <td>1.669946</td>\n",
       "      <td>1.670978</td>\n",
       "      <td>1.687426</td>\n",
       "      <td>1.734935</td>\n",
       "      <td>1.757310</td>\n",
       "      <td>1.747601</td>\n",
       "      <td>1.729637</td>\n",
       "      <td>1.699685</td>\n",
       "      <td>2.929725</td>\n",
       "      <td>2.931719</td>\n",
       "      <td>2.165518</td>\n",
       "      <td>2.105323</td>\n",
       "      <td>1.758464</td>\n",
       "      <td>1.772547</td>\n",
       "      <td>1.772940</td>\n",
       "      <td>1.789259</td>\n",
       "      <td>1.701586</td>\n",
       "      <td>1.724474</td>\n",
       "      <td>1.733565</td>\n",
       "      <td>1.688764</td>\n",
       "      <td>1.745741</td>\n",
       "      <td>1.761079</td>\n",
       "      <td>1.760658</td>\n",
       "      <td>1.749004</td>\n",
       "      <td>2.907193</td>\n",
       "      <td>2.912386</td>\n",
       "      <td>2.325858</td>\n",
       "      <td>2.105851</td>\n",
       "      <td>3.682053</td>\n",
       "      <td>1.716237</td>\n",
       "      <td>1.730185</td>\n",
       "      <td>1.722134</td>\n",
       "      <td>1.702816</td>\n",
       "      <td>1.708977</td>\n",
       "      <td>1.735513</td>\n",
       "      <td>1.749481</td>\n",
       "      <td>1.731926</td>\n",
       "      <td>1.988778</td>\n",
       "      <td>1.986559</td>\n",
       "      <td>2.146736</td>\n",
       "      <td>1.847229</td>\n",
       "      <td>1.838392</td>\n",
       "      <td>1.808560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AdaBoostRegressor{'loss': 'linear'}  \\\n",
       "rmse_training                             0.800904   \n",
       "rmse_cv                                   1.702421   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'square'}  \\\n",
       "rmse_training                             0.741088   \n",
       "rmse_cv                                   1.762869   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'exponential'}  BaggingRegressor{}  \\\n",
       "rmse_training                                  0.821008            0.796226   \n",
       "rmse_cv                                        1.739804            1.773814   \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.682685                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.669763                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.671785                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.687687                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000               \n",
       "rmse_cv                                                 1.711171               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000               \n",
       "rmse_cv                                                 1.774179               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_training                                           0.017966            \n",
       "rmse_cv                                                 1.638060            \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_training                                           0.000000            \n",
       "rmse_cv                                                 1.678239            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_training                                           0.144608                                            \n",
       "rmse_cv                                                 1.792816                                            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.134223                                              \n",
       "rmse_cv                                                 1.817878                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.171387                                              \n",
       "rmse_cv                                                 1.687886                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.180109                                              \n",
       "rmse_cv                                                 1.748724                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_training                                           0.820328                                             \n",
       "rmse_cv                                                 1.669946                                             \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.777557                                               \n",
       "rmse_cv                                                 1.670978                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.759549                                               \n",
       "rmse_cv                                                 1.687426                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.884338                                               \n",
       "rmse_cv                                                 1.734935                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_training                                           0.336477                                               \n",
       "rmse_cv                                                 1.757310                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.338897                                                 \n",
       "rmse_cv                                                 1.747601                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.362962                                                 \n",
       "rmse_cv                                                 1.729637                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.363317                                                 \n",
       "rmse_cv                                                 1.699685                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_training                                           2.906163                                                  \n",
       "rmse_cv                                                 2.929725                                                  \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           2.906163                                                    \n",
       "rmse_cv                                                 2.931719                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           1.839171                                                    \n",
       "rmse_cv                                                 2.165518                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           1.763750                                                    \n",
       "rmse_cv                                                 2.105323                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_training                                           0.136624                                   \n",
       "rmse_cv                                                 1.758464                                   \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.136624                                     \n",
       "rmse_cv                                                 1.772547                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.136538                                     \n",
       "rmse_cv                                                 1.772940                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.196127                                     \n",
       "rmse_cv                                                 1.789259                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_training                                           0.815084                                    \n",
       "rmse_cv                                                 1.701586                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.767027                                      \n",
       "rmse_cv                                                 1.724474                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.777966                                      \n",
       "rmse_cv                                                 1.733565                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.821566                                      \n",
       "rmse_cv                                                 1.688764                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_training                                           0.338897                                      \n",
       "rmse_cv                                                 1.745741                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.336477                                        \n",
       "rmse_cv                                                 1.761079                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.374930                                        \n",
       "rmse_cv                                                 1.760658                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.388329                                        \n",
       "rmse_cv                                                 1.749004                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_training                                           2.906163                                         \n",
       "rmse_cv                                                 2.907193                                         \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           2.906163                                           \n",
       "rmse_cv                                                 2.912386                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           1.845535                                           \n",
       "rmse_cv                                                 2.325858                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           1.849931                                           \n",
       "rmse_cv                                                 2.105851                                           \n",
       "\n",
       "               IsolationForest{}  \\\n",
       "rmse_training           3.462362   \n",
       "rmse_cv                 3.682053   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.615450                   \n",
       "rmse_cv                                                 1.716237                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.617170                   \n",
       "rmse_cv                                                 1.730185                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_training                                           0.643708                 \n",
       "rmse_cv                                                 1.722134                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_training                                           0.606385              \n",
       "rmse_cv                                                 1.702816              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.635773                   \n",
       "rmse_cv                                                 1.708977                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.666565                   \n",
       "rmse_cv                                                 1.735513                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_training                                           0.662488                 \n",
       "rmse_cv                                                 1.749481                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_training                                           0.758665              \n",
       "rmse_cv                                                 1.731926              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.771422                       \n",
       "rmse_cv                                                 1.988778                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.733582                       \n",
       "rmse_cv                                                 1.986559                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': None}  \\\n",
       "rmse_training                                           0.784405                     \n",
       "rmse_cv                                                 2.146736                     \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}  \\\n",
       "rmse_training                                           0.658957                  \n",
       "rmse_cv                                                 1.847229                  \n",
       "\n",
       "               StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \\\n",
       "rmse_training                                           1.887090                                                                                                                                                \n",
       "rmse_cv                                                 1.838392                                                                                                                                                \n",
       "\n",
       "               VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \n",
       "rmse_training                                           1.587453                                                                                                                                             \n",
       "rmse_cv                                                 1.808560                                                                                                                                             "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "result_ens = regression_ensemble(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_ens = pd.DataFrame.from_dict(result_ens)\n",
    "result_ens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068051b-3db8-40dc-94ff-31df09352304",
   "metadata": {},
   "source": [
    "<h3> Neural Network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "7048625b-fe17-4b60-b313-aa922357eea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.066022</td>\n",
       "      <td>1.707228</td>\n",
       "      <td>1.415089</td>\n",
       "      <td>1.072823</td>\n",
       "      <td>3.213425</td>\n",
       "      <td>1.400224</td>\n",
       "      <td>1.060216</td>\n",
       "      <td>1.581346</td>\n",
       "      <td>1.414240</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>2.000409</td>\n",
       "      <td>1.520794</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>2.317426</td>\n",
       "      <td>1.486634</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>1.779521</td>\n",
       "      <td>1.529210</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>1.190643</td>\n",
       "      <td>0.912254</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>2.649068</td>\n",
       "      <td>0.955634</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>1.209457</td>\n",
       "      <td>0.830502</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>1.269244</td>\n",
       "      <td>0.717584</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>3.602525</td>\n",
       "      <td>0.548023</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>1.219141</td>\n",
       "      <td>0.695148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>2.541616</td>\n",
       "      <td>1.954613</td>\n",
       "      <td>1.918820</td>\n",
       "      <td>2.646424</td>\n",
       "      <td>3.319871</td>\n",
       "      <td>1.958899</td>\n",
       "      <td>2.618470</td>\n",
       "      <td>1.921839</td>\n",
       "      <td>1.948187</td>\n",
       "      <td>2.398623</td>\n",
       "      <td>1.993739</td>\n",
       "      <td>1.935536</td>\n",
       "      <td>2.390509</td>\n",
       "      <td>2.053392</td>\n",
       "      <td>1.928757</td>\n",
       "      <td>2.504979</td>\n",
       "      <td>1.823137</td>\n",
       "      <td>1.930169</td>\n",
       "      <td>2.401614</td>\n",
       "      <td>2.075526</td>\n",
       "      <td>2.214715</td>\n",
       "      <td>2.391421</td>\n",
       "      <td>2.622750</td>\n",
       "      <td>2.138458</td>\n",
       "      <td>2.604508</td>\n",
       "      <td>2.055719</td>\n",
       "      <td>2.151523</td>\n",
       "      <td>2.440299</td>\n",
       "      <td>1.891807</td>\n",
       "      <td>1.911085</td>\n",
       "      <td>2.164162</td>\n",
       "      <td>3.791083</td>\n",
       "      <td>1.891257</td>\n",
       "      <td>2.380486</td>\n",
       "      <td>1.830540</td>\n",
       "      <td>1.946403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.066022                                         \n",
       "rmse_cv                                                 2.541616                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.707228                                       \n",
       "rmse_cv                                                 1.954613                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.415089                                        \n",
       "rmse_cv                                                 1.918820                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.072823                                           \n",
       "rmse_cv                                                 2.646424                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           3.213425                                         \n",
       "rmse_cv                                                 3.319871                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.400224                                          \n",
       "rmse_cv                                                 1.958899                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.060216                                         \n",
       "rmse_cv                                                 2.618470                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.581346                                       \n",
       "rmse_cv                                                 1.921839                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.414240                                        \n",
       "rmse_cv                                                 1.948187                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.002077                                         \n",
       "rmse_cv                                                 2.398623                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.000409                                       \n",
       "rmse_cv                                                 1.993739                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.520794                                        \n",
       "rmse_cv                                                 1.935536                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001808                                           \n",
       "rmse_cv                                                 2.390509                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.317426                                         \n",
       "rmse_cv                                                 2.053392                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.486634                                          \n",
       "rmse_cv                                                 1.928757                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001674                                         \n",
       "rmse_cv                                                 2.504979                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.779521                                       \n",
       "rmse_cv                                                 1.823137                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.529210                                        \n",
       "rmse_cv                                                 1.930169                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000582                                     \n",
       "rmse_cv                                                 2.401614                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.190643                                   \n",
       "rmse_cv                                                 2.075526                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.912254                                    \n",
       "rmse_cv                                                 2.214715                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000510                                       \n",
       "rmse_cv                                                 2.391421                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.649068                                     \n",
       "rmse_cv                                                 2.622750                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.955634                                      \n",
       "rmse_cv                                                 2.138458                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000994                                     \n",
       "rmse_cv                                                 2.604508                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.209457                                   \n",
       "rmse_cv                                                 2.055719                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.830502                                    \n",
       "rmse_cv                                                 2.151523                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000690                                     \n",
       "rmse_cv                                                 2.440299                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.269244                                   \n",
       "rmse_cv                                                 1.891807                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.717584                                    \n",
       "rmse_cv                                                 1.911085                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001057                                       \n",
       "rmse_cv                                                 2.164162                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           3.602525                                     \n",
       "rmse_cv                                                 3.791083                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.548023                                      \n",
       "rmse_cv                                                 1.891257                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001004                                     \n",
       "rmse_cv                                                 2.380486                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.219141                                   \n",
       "rmse_cv                                                 1.830540                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}  \n",
       "rmse_training                                           0.695148                                   \n",
       "rmse_cv                                                 1.946403                                   "
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "regression_neuralnetwork\n",
    "result_nn = regression_neuralnetwork(train_set_new_ready, train_set_labels, cv=4)\n",
    "result_nn = pd.DataFrame.from_dict(result_nn)\n",
    "result_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271653d-8a2d-481f-a20f-453fff4b1eb9",
   "metadata": {},
   "source": [
    "<h3> Summary </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "08690e00-c3d7-4dbd-8a8f-07b10bfe2657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARDRegression{}</th>\n",
       "      <th>BayesianRidge{}</th>\n",
       "      <th>ElasticNet{'selection': 'cyclic'}</th>\n",
       "      <th>ElasticNet{'selection': 'random'}</th>\n",
       "      <th>HuberRegressor{}</th>\n",
       "      <th>Lars{}</th>\n",
       "      <th>Lasso{'selection': 'cyclic'}</th>\n",
       "      <th>Lasso{'selection': 'random'}</th>\n",
       "      <th>LassoLars{}</th>\n",
       "      <th>LinearRegression{}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l1', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'l2', 'solver': 'saga'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'sag'}</th>\n",
       "      <th>LogisticRegression{'penalty': 'none', 'solver': 'saga'}</th>\n",
       "      <th>OrthogonalMatchingPursuit{}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>RANSACRegressor{}</th>\n",
       "      <th>Ridge{'solver': 'svd'}</th>\n",
       "      <th>Ridge{'solver': 'cholesky'}</th>\n",
       "      <th>Ridge{'solver': 'lsqr'}</th>\n",
       "      <th>Ridge{'solver': 'sparse_cg'}</th>\n",
       "      <th>Ridge{'solver': 'sag'}</th>\n",
       "      <th>Ridge{'solver': 'saga'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}</th>\n",
       "      <th>TheilSenRegressor{}</th>\n",
       "      <th>TweedieRegressor{'link': 'identity'}</th>\n",
       "      <th>TweedieRegressor{'link': 'log'}</th>\n",
       "      <th>KernelRidge 1**2</th>\n",
       "      <th>KernelRidge DotProduct(sigma_0=1)</th>\n",
       "      <th>KernelRidge ExpSineSquared(length_scale=1, periodicity=1)</th>\n",
       "      <th>KernelRidge Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>KernelRidge PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>KernelRidge RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>KernelRidge RBF(length_scale=1)</th>\n",
       "      <th>KernelRidge WhiteKernel(noise_level=1)</th>\n",
       "      <th>KernelRidge linear</th>\n",
       "      <th>LinearSVR{'loss': 'epsilon_insensitive'}</th>\n",
       "      <th>LinearSVR{'loss': 'squared_epsilon_insensitive'}</th>\n",
       "      <th>NuSVR{'kernel': 'linear'}</th>\n",
       "      <th>NuSVR{'kernel': 'poly'}</th>\n",
       "      <th>NuSVR{'kernel': 'rbf'}</th>\n",
       "      <th>NuSVR{'kernel': 'sigmoid'}</th>\n",
       "      <th>SVR{'kernel': 'linear'}</th>\n",
       "      <th>SVR{'kernel': 'poly'}</th>\n",
       "      <th>SVR{'kernel': 'rbf'}</th>\n",
       "      <th>SVR{'kernel': 'sigmoid'}</th>\n",
       "      <th>GaussianProcessRegressor 1**2</th>\n",
       "      <th>GaussianProcessRegressor DotProduct(sigma_0=1)</th>\n",
       "      <th>GaussianProcessRegressor Matern(length_scale=1, nu=1.5)</th>\n",
       "      <th>GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)</th>\n",
       "      <th>GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor RBF(length_scale=1)</th>\n",
       "      <th>GaussianProcessRegressor WhiteKernel(noise_level=1)</th>\n",
       "      <th>CCA{}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'nipals'}</th>\n",
       "      <th>PLSCanonical{'algorithm': 'svd'}</th>\n",
       "      <th>PLSRegression{}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}</th>\n",
       "      <th>DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'linear'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'square'}</th>\n",
       "      <th>AdaBoostRegressor{'loss': 'exponential'}</th>\n",
       "      <th>BaggingRegressor{}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}</th>\n",
       "      <th>GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}</th>\n",
       "      <th>IsolationForest{}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mse', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'mae', 'max_features': 1}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': None}</th>\n",
       "      <th>RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}</th>\n",
       "      <th>StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "      <th>VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}</th>\n",
       "      <th>MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse_training</th>\n",
       "      <td>1.506267</td>\n",
       "      <td>1.715081</td>\n",
       "      <td>1.797770</td>\n",
       "      <td>1.797770</td>\n",
       "      <td>1.252213</td>\n",
       "      <td>151.759964</td>\n",
       "      <td>1.800469</td>\n",
       "      <td>1.800469</td>\n",
       "      <td>1.800469</td>\n",
       "      <td>0.939249</td>\n",
       "      <td>1.689799</td>\n",
       "      <td>1.711055</td>\n",
       "      <td>1.532774</td>\n",
       "      <td>1.532774</td>\n",
       "      <td>1.686231</td>\n",
       "      <td>1.532774</td>\n",
       "      <td>1.594418</td>\n",
       "      <td>1.642801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.439545</td>\n",
       "      <td>1.370955</td>\n",
       "      <td>1.569185</td>\n",
       "      <td>2.500821</td>\n",
       "      <td>1.726135</td>\n",
       "      <td>3.010502</td>\n",
       "      <td>1.391042</td>\n",
       "      <td>1.391042</td>\n",
       "      <td>1.392067</td>\n",
       "      <td>1.391138</td>\n",
       "      <td>1.404622</td>\n",
       "      <td>1.418174</td>\n",
       "      <td>1.799081</td>\n",
       "      <td>5.343158e+13</td>\n",
       "      <td>1.529367</td>\n",
       "      <td>1.469588</td>\n",
       "      <td>1.653560</td>\n",
       "      <td>5.249754e+13</td>\n",
       "      <td>1.499131</td>\n",
       "      <td>1.455185</td>\n",
       "      <td>1.455261</td>\n",
       "      <td>1.224849</td>\n",
       "      <td>1.637558</td>\n",
       "      <td>1.520938</td>\n",
       "      <td>1.801011</td>\n",
       "      <td>1.391189</td>\n",
       "      <td>3.937000</td>\n",
       "      <td>2.016854</td>\n",
       "      <td>1.391596</td>\n",
       "      <td>1.210426</td>\n",
       "      <td>2.049545</td>\n",
       "      <td>4.124566</td>\n",
       "      <td>1.391596</td>\n",
       "      <td>1.480311</td>\n",
       "      <td>1.341842</td>\n",
       "      <td>1.469541</td>\n",
       "      <td>1.402183</td>\n",
       "      <td>1.357156</td>\n",
       "      <td>1.804950</td>\n",
       "      <td>1.478599</td>\n",
       "      <td>1.399200</td>\n",
       "      <td>1.368489</td>\n",
       "      <td>1.838272</td>\n",
       "      <td>1.800469</td>\n",
       "      <td>0.939318</td>\n",
       "      <td>3.179704e-10</td>\n",
       "      <td>0.939254</td>\n",
       "      <td>2.202329e-10</td>\n",
       "      <td>4.608834e-10</td>\n",
       "      <td>4.124566</td>\n",
       "      <td>1.782026</td>\n",
       "      <td>4.551446</td>\n",
       "      <td>4.551446</td>\n",
       "      <td>1.600774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800904</td>\n",
       "      <td>0.741088</td>\n",
       "      <td>0.821008</td>\n",
       "      <td>0.796226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144608</td>\n",
       "      <td>0.134223</td>\n",
       "      <td>0.171387</td>\n",
       "      <td>0.180109</td>\n",
       "      <td>0.820328</td>\n",
       "      <td>0.777557</td>\n",
       "      <td>0.759549</td>\n",
       "      <td>0.884338</td>\n",
       "      <td>0.336477</td>\n",
       "      <td>0.338897</td>\n",
       "      <td>0.362962</td>\n",
       "      <td>0.363317</td>\n",
       "      <td>2.906163</td>\n",
       "      <td>2.906163</td>\n",
       "      <td>1.839171</td>\n",
       "      <td>1.763750</td>\n",
       "      <td>0.136624</td>\n",
       "      <td>0.136624</td>\n",
       "      <td>0.136538</td>\n",
       "      <td>0.196127</td>\n",
       "      <td>0.815084</td>\n",
       "      <td>0.767027</td>\n",
       "      <td>0.777966</td>\n",
       "      <td>0.821566</td>\n",
       "      <td>0.338897</td>\n",
       "      <td>0.336477</td>\n",
       "      <td>0.374930</td>\n",
       "      <td>0.388329</td>\n",
       "      <td>2.906163</td>\n",
       "      <td>2.906163</td>\n",
       "      <td>1.845535</td>\n",
       "      <td>1.849931</td>\n",
       "      <td>3.462362</td>\n",
       "      <td>0.615450</td>\n",
       "      <td>0.617170</td>\n",
       "      <td>0.643708</td>\n",
       "      <td>0.606385</td>\n",
       "      <td>0.635773</td>\n",
       "      <td>0.666565</td>\n",
       "      <td>0.662488</td>\n",
       "      <td>0.758665</td>\n",
       "      <td>0.771422</td>\n",
       "      <td>0.733582</td>\n",
       "      <td>0.784405</td>\n",
       "      <td>0.658957</td>\n",
       "      <td>1.887090</td>\n",
       "      <td>1.587453</td>\n",
       "      <td>1.066022</td>\n",
       "      <td>1.707228</td>\n",
       "      <td>1.415089</td>\n",
       "      <td>1.072823</td>\n",
       "      <td>3.213425</td>\n",
       "      <td>1.400224</td>\n",
       "      <td>1.060216</td>\n",
       "      <td>1.581346</td>\n",
       "      <td>1.414240</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>2.000409</td>\n",
       "      <td>1.520794</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>2.317426</td>\n",
       "      <td>1.486634</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>1.779521</td>\n",
       "      <td>1.529210</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>1.190643</td>\n",
       "      <td>0.912254</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>2.649068</td>\n",
       "      <td>0.955634</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>1.209457</td>\n",
       "      <td>0.830502</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>1.269244</td>\n",
       "      <td>0.717584</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>3.602525</td>\n",
       "      <td>0.548023</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>1.219141</td>\n",
       "      <td>0.695148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_cv</th>\n",
       "      <td>1.952275</td>\n",
       "      <td>1.842220</td>\n",
       "      <td>1.856344</td>\n",
       "      <td>1.856345</td>\n",
       "      <td>2.604354</td>\n",
       "      <td>2732.996970</td>\n",
       "      <td>1.848290</td>\n",
       "      <td>1.848290</td>\n",
       "      <td>1.848290</td>\n",
       "      <td>7.029047</td>\n",
       "      <td>2.082422</td>\n",
       "      <td>2.163032</td>\n",
       "      <td>2.337529</td>\n",
       "      <td>2.337529</td>\n",
       "      <td>2.233059</td>\n",
       "      <td>2.376075</td>\n",
       "      <td>2.369071</td>\n",
       "      <td>2.163365</td>\n",
       "      <td>2.697142</td>\n",
       "      <td>2.676737</td>\n",
       "      <td>2.468347</td>\n",
       "      <td>2.428084</td>\n",
       "      <td>1.881482</td>\n",
       "      <td>2.612527</td>\n",
       "      <td>2.416350</td>\n",
       "      <td>11.230984</td>\n",
       "      <td>2.005982</td>\n",
       "      <td>2.005982</td>\n",
       "      <td>2.003769</td>\n",
       "      <td>2.006426</td>\n",
       "      <td>2.007351</td>\n",
       "      <td>2.004973</td>\n",
       "      <td>2.101843</td>\n",
       "      <td>8.007630e+13</td>\n",
       "      <td>1.941779</td>\n",
       "      <td>2.009306</td>\n",
       "      <td>1.985288</td>\n",
       "      <td>9.025170e+13</td>\n",
       "      <td>1.961738</td>\n",
       "      <td>1.995042</td>\n",
       "      <td>1.992949</td>\n",
       "      <td>7.631957</td>\n",
       "      <td>1.849276</td>\n",
       "      <td>2.088724</td>\n",
       "      <td>1.846172</td>\n",
       "      <td>2.009819</td>\n",
       "      <td>16.794263</td>\n",
       "      <td>4.033453</td>\n",
       "      <td>2.013866</td>\n",
       "      <td>2.560905</td>\n",
       "      <td>4.076433</td>\n",
       "      <td>4.092971</td>\n",
       "      <td>2.013866</td>\n",
       "      <td>2.118779</td>\n",
       "      <td>2.045137</td>\n",
       "      <td>1.883343</td>\n",
       "      <td>1.912191</td>\n",
       "      <td>1.717408</td>\n",
       "      <td>1.794709</td>\n",
       "      <td>2.105593</td>\n",
       "      <td>1.982141</td>\n",
       "      <td>1.689241</td>\n",
       "      <td>1.841976</td>\n",
       "      <td>2.047075</td>\n",
       "      <td>7.028944</td>\n",
       "      <td>1.778222e+00</td>\n",
       "      <td>7.028837</td>\n",
       "      <td>1.706544e+00</td>\n",
       "      <td>2.044975e+00</td>\n",
       "      <td>4.092971</td>\n",
       "      <td>1.846478</td>\n",
       "      <td>4.881097</td>\n",
       "      <td>4.881097</td>\n",
       "      <td>1.862992</td>\n",
       "      <td>2.398237</td>\n",
       "      <td>2.182826</td>\n",
       "      <td>2.455718</td>\n",
       "      <td>2.273129</td>\n",
       "      <td>2.4001</td>\n",
       "      <td>2.490975</td>\n",
       "      <td>2.468168</td>\n",
       "      <td>2.092402</td>\n",
       "      <td>2.285991</td>\n",
       "      <td>2.226256</td>\n",
       "      <td>2.073593</td>\n",
       "      <td>2.275142</td>\n",
       "      <td>1.972787</td>\n",
       "      <td>2.403307</td>\n",
       "      <td>2.393248</td>\n",
       "      <td>2.118974</td>\n",
       "      <td>2.639041</td>\n",
       "      <td>2.382275</td>\n",
       "      <td>2.300437</td>\n",
       "      <td>2.199273</td>\n",
       "      <td>2.38598</td>\n",
       "      <td>2.20776</td>\n",
       "      <td>2.26037</td>\n",
       "      <td>2.271676</td>\n",
       "      <td>2.424684</td>\n",
       "      <td>2.578855</td>\n",
       "      <td>2.727583</td>\n",
       "      <td>2.747981</td>\n",
       "      <td>2.361932</td>\n",
       "      <td>2.670653</td>\n",
       "      <td>2.418606</td>\n",
       "      <td>2.750076</td>\n",
       "      <td>1.702421</td>\n",
       "      <td>1.762869</td>\n",
       "      <td>1.739804</td>\n",
       "      <td>1.773814</td>\n",
       "      <td>1.682685</td>\n",
       "      <td>1.669763</td>\n",
       "      <td>1.671785</td>\n",
       "      <td>1.687687</td>\n",
       "      <td>1.711171</td>\n",
       "      <td>1.774179</td>\n",
       "      <td>1.638060</td>\n",
       "      <td>1.678239</td>\n",
       "      <td>1.792816</td>\n",
       "      <td>1.817878</td>\n",
       "      <td>1.687886</td>\n",
       "      <td>1.748724</td>\n",
       "      <td>1.669946</td>\n",
       "      <td>1.670978</td>\n",
       "      <td>1.687426</td>\n",
       "      <td>1.734935</td>\n",
       "      <td>1.757310</td>\n",
       "      <td>1.747601</td>\n",
       "      <td>1.729637</td>\n",
       "      <td>1.699685</td>\n",
       "      <td>2.929725</td>\n",
       "      <td>2.931719</td>\n",
       "      <td>2.165518</td>\n",
       "      <td>2.105323</td>\n",
       "      <td>1.758464</td>\n",
       "      <td>1.772547</td>\n",
       "      <td>1.772940</td>\n",
       "      <td>1.789259</td>\n",
       "      <td>1.701586</td>\n",
       "      <td>1.724474</td>\n",
       "      <td>1.733565</td>\n",
       "      <td>1.688764</td>\n",
       "      <td>1.745741</td>\n",
       "      <td>1.761079</td>\n",
       "      <td>1.760658</td>\n",
       "      <td>1.749004</td>\n",
       "      <td>2.907193</td>\n",
       "      <td>2.912386</td>\n",
       "      <td>2.325858</td>\n",
       "      <td>2.105851</td>\n",
       "      <td>3.682053</td>\n",
       "      <td>1.716237</td>\n",
       "      <td>1.730185</td>\n",
       "      <td>1.722134</td>\n",
       "      <td>1.702816</td>\n",
       "      <td>1.708977</td>\n",
       "      <td>1.735513</td>\n",
       "      <td>1.749481</td>\n",
       "      <td>1.731926</td>\n",
       "      <td>1.988778</td>\n",
       "      <td>1.986559</td>\n",
       "      <td>2.146736</td>\n",
       "      <td>1.847229</td>\n",
       "      <td>1.838392</td>\n",
       "      <td>1.808560</td>\n",
       "      <td>2.541616</td>\n",
       "      <td>1.954613</td>\n",
       "      <td>1.918820</td>\n",
       "      <td>2.646424</td>\n",
       "      <td>3.319871</td>\n",
       "      <td>1.958899</td>\n",
       "      <td>2.618470</td>\n",
       "      <td>1.921839</td>\n",
       "      <td>1.948187</td>\n",
       "      <td>2.398623</td>\n",
       "      <td>1.993739</td>\n",
       "      <td>1.935536</td>\n",
       "      <td>2.390509</td>\n",
       "      <td>2.053392</td>\n",
       "      <td>1.928757</td>\n",
       "      <td>2.504979</td>\n",
       "      <td>1.823137</td>\n",
       "      <td>1.930169</td>\n",
       "      <td>2.401614</td>\n",
       "      <td>2.075526</td>\n",
       "      <td>2.214715</td>\n",
       "      <td>2.391421</td>\n",
       "      <td>2.622750</td>\n",
       "      <td>2.138458</td>\n",
       "      <td>2.604508</td>\n",
       "      <td>2.055719</td>\n",
       "      <td>2.151523</td>\n",
       "      <td>2.440299</td>\n",
       "      <td>1.891807</td>\n",
       "      <td>1.911085</td>\n",
       "      <td>2.164162</td>\n",
       "      <td>3.791083</td>\n",
       "      <td>1.891257</td>\n",
       "      <td>2.380486</td>\n",
       "      <td>1.830540</td>\n",
       "      <td>1.946403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ARDRegression{}  BayesianRidge{}  \\\n",
       "rmse_training         1.506267         1.715081   \n",
       "rmse_cv               1.952275         1.842220   \n",
       "\n",
       "               ElasticNet{'selection': 'cyclic'}  \\\n",
       "rmse_training                           1.797770   \n",
       "rmse_cv                                 1.856344   \n",
       "\n",
       "               ElasticNet{'selection': 'random'}  HuberRegressor{}  \\\n",
       "rmse_training                           1.797770          1.252213   \n",
       "rmse_cv                                 1.856345          2.604354   \n",
       "\n",
       "                    Lars{}  Lasso{'selection': 'cyclic'}  \\\n",
       "rmse_training   151.759964                      1.800469   \n",
       "rmse_cv        2732.996970                      1.848290   \n",
       "\n",
       "               Lasso{'selection': 'random'}  LassoLars{}  LinearRegression{}  \\\n",
       "rmse_training                      1.800469     1.800469            0.939249   \n",
       "rmse_cv                            1.848290     1.848290            7.029047   \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'liblinear'}  \\\n",
       "rmse_training                                           1.689799            \n",
       "rmse_cv                                                 2.082422            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l1', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.711055       \n",
       "rmse_cv                                                 2.163032       \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'newton-cg'}  \\\n",
       "rmse_training                                           1.532774            \n",
       "rmse_cv                                                 2.337529            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.532774        \n",
       "rmse_cv                                                 2.337529        \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'liblinear'}  \\\n",
       "rmse_training                                           1.686231            \n",
       "rmse_cv                                                 2.233059            \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'sag'}  \\\n",
       "rmse_training                                           1.532774      \n",
       "rmse_cv                                                 2.376075      \n",
       "\n",
       "               LogisticRegression{'penalty': 'l2', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.594418       \n",
       "rmse_cv                                                 2.369071       \n",
       "\n",
       "               LogisticRegression{'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.5}  \\\n",
       "rmse_training                                           1.642801                                \n",
       "rmse_cv                                                 2.163365                                \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'newton-cg'}  \\\n",
       "rmse_training                                           0.000000              \n",
       "rmse_cv                                                 2.697142              \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000000          \n",
       "rmse_cv                                                 2.676737          \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'sag'}  \\\n",
       "rmse_training                                           1.439545        \n",
       "rmse_cv                                                 2.468347        \n",
       "\n",
       "               LogisticRegression{'penalty': 'none', 'solver': 'saga'}  \\\n",
       "rmse_training                                           1.370955         \n",
       "rmse_cv                                                 2.428084         \n",
       "\n",
       "               OrthogonalMatchingPursuit{}  \\\n",
       "rmse_training                     1.569185   \n",
       "rmse_cv                           1.881482   \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_training                                           2.500821           \n",
       "rmse_cv                                                 2.612527           \n",
       "\n",
       "               PassiveAggressiveRegressor{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_training                                           1.726135                   \n",
       "rmse_cv                                                 2.416350                   \n",
       "\n",
       "               RANSACRegressor{}  Ridge{'solver': 'svd'}  \\\n",
       "rmse_training           3.010502                1.391042   \n",
       "rmse_cv                11.230984                2.005982   \n",
       "\n",
       "               Ridge{'solver': 'cholesky'}  Ridge{'solver': 'lsqr'}  \\\n",
       "rmse_training                     1.391042                 1.392067   \n",
       "rmse_cv                           2.005982                 2.003769   \n",
       "\n",
       "               Ridge{'solver': 'sparse_cg'}  Ridge{'solver': 'sag'}  \\\n",
       "rmse_training                      1.391138                1.404622   \n",
       "rmse_cv                            2.006426                2.007351   \n",
       "\n",
       "               Ridge{'solver': 'saga'}  \\\n",
       "rmse_training                 1.418174   \n",
       "rmse_cv                       2.004973   \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'constant'}  \\\n",
       "rmse_training                                           1.799081            \n",
       "rmse_cv                                                 2.101843            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'optimal'}  \\\n",
       "rmse_training                                       5.343158e+13           \n",
       "rmse_cv                                             8.007630e+13           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_training                                           1.529367              \n",
       "rmse_cv                                                 1.941779              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l1', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.469588            \n",
       "rmse_cv                                                 2.009306            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'constant'}  \\\n",
       "rmse_training                                           1.653560            \n",
       "rmse_cv                                                 1.985288            \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'optimal'}  \\\n",
       "rmse_training                                       5.249754e+13           \n",
       "rmse_cv                                             9.025170e+13           \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'invscaling'}  \\\n",
       "rmse_training                                           1.499131              \n",
       "rmse_cv                                                 1.961738              \n",
       "\n",
       "               SGDRegressor{'penalty': 'l2', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.455185            \n",
       "rmse_cv                                                 1.995042            \n",
       "\n",
       "               SGDRegressor{'penalty': 'elasticnet', 'learning_rate': 'adaptive'}  \\\n",
       "rmse_training                                           1.455261                    \n",
       "rmse_cv                                                 1.992949                    \n",
       "\n",
       "               TheilSenRegressor{}  TweedieRegressor{'link': 'identity'}  \\\n",
       "rmse_training             1.224849                              1.637558   \n",
       "rmse_cv                   7.631957                              1.849276   \n",
       "\n",
       "               TweedieRegressor{'link': 'log'}  KernelRidge 1**2  \\\n",
       "rmse_training                         1.520938          1.801011   \n",
       "rmse_cv                               2.088724          1.846172   \n",
       "\n",
       "               KernelRidge DotProduct(sigma_0=1)  \\\n",
       "rmse_training                           1.391189   \n",
       "rmse_cv                                 2.009819   \n",
       "\n",
       "               KernelRidge ExpSineSquared(length_scale=1, periodicity=1)  \\\n",
       "rmse_training                                           3.937000           \n",
       "rmse_cv                                                16.794263           \n",
       "\n",
       "               KernelRidge Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_training                                    2.016854   \n",
       "rmse_cv                                          4.033453   \n",
       "\n",
       "               KernelRidge PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_training                                           1.391596      \n",
       "rmse_cv                                                 2.013866      \n",
       "\n",
       "               KernelRidge RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_training                                           1.210426        \n",
       "rmse_cv                                                 2.560905        \n",
       "\n",
       "               KernelRidge RBF(length_scale=1)  \\\n",
       "rmse_training                         2.049545   \n",
       "rmse_cv                               4.076433   \n",
       "\n",
       "               KernelRidge WhiteKernel(noise_level=1)  KernelRidge linear  \\\n",
       "rmse_training                                4.124566            1.391596   \n",
       "rmse_cv                                      4.092971            2.013866   \n",
       "\n",
       "               LinearSVR{'loss': 'epsilon_insensitive'}  \\\n",
       "rmse_training                                  1.480311   \n",
       "rmse_cv                                        2.118779   \n",
       "\n",
       "               LinearSVR{'loss': 'squared_epsilon_insensitive'}  \\\n",
       "rmse_training                                          1.341842   \n",
       "rmse_cv                                                2.045137   \n",
       "\n",
       "               NuSVR{'kernel': 'linear'}  NuSVR{'kernel': 'poly'}  \\\n",
       "rmse_training                   1.469541                 1.402183   \n",
       "rmse_cv                         1.883343                 1.912191   \n",
       "\n",
       "               NuSVR{'kernel': 'rbf'}  NuSVR{'kernel': 'sigmoid'}  \\\n",
       "rmse_training                1.357156                    1.804950   \n",
       "rmse_cv                      1.717408                    1.794709   \n",
       "\n",
       "               SVR{'kernel': 'linear'}  SVR{'kernel': 'poly'}  \\\n",
       "rmse_training                 1.478599               1.399200   \n",
       "rmse_cv                       2.105593               1.982141   \n",
       "\n",
       "               SVR{'kernel': 'rbf'}  SVR{'kernel': 'sigmoid'}  \\\n",
       "rmse_training              1.368489                  1.838272   \n",
       "rmse_cv                    1.689241                  1.841976   \n",
       "\n",
       "               GaussianProcessRegressor 1**2  \\\n",
       "rmse_training                       1.800469   \n",
       "rmse_cv                             2.047075   \n",
       "\n",
       "               GaussianProcessRegressor DotProduct(sigma_0=1)  \\\n",
       "rmse_training                                        0.939318   \n",
       "rmse_cv                                              7.028944   \n",
       "\n",
       "               GaussianProcessRegressor Matern(length_scale=1, nu=1.5)  \\\n",
       "rmse_training                                       3.179704e-10         \n",
       "rmse_cv                                             1.778222e+00         \n",
       "\n",
       "               GaussianProcessRegressor PairwiseKernel(gamma=1.0, metric=linear)  \\\n",
       "rmse_training                                           0.939254                   \n",
       "rmse_cv                                                 7.028837                   \n",
       "\n",
       "               GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)  \\\n",
       "rmse_training                                       2.202329e-10                     \n",
       "rmse_cv                                             1.706544e+00                     \n",
       "\n",
       "               GaussianProcessRegressor RBF(length_scale=1)  \\\n",
       "rmse_training                                  4.608834e-10   \n",
       "rmse_cv                                        2.044975e+00   \n",
       "\n",
       "               GaussianProcessRegressor WhiteKernel(noise_level=1)     CCA{}  \\\n",
       "rmse_training                                           4.124566    1.782026   \n",
       "rmse_cv                                                 4.092971    1.846478   \n",
       "\n",
       "               PLSCanonical{'algorithm': 'nipals'}  \\\n",
       "rmse_training                             4.551446   \n",
       "rmse_cv                                   4.881097   \n",
       "\n",
       "               PLSCanonical{'algorithm': 'svd'}  PLSRegression{}  \\\n",
       "rmse_training                          4.551446         1.600774   \n",
       "rmse_cv                                4.881097         1.862992   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                      \n",
       "rmse_cv                                                 2.398237                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.182826                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.455718                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.273129                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                             0.0000                                        \n",
       "rmse_cv                                                   2.4001                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.490975                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.468168                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.092402                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                               \n",
       "rmse_cv                                                 2.285991                                               \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.226256                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.073593                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 2.275142                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                                 \n",
       "rmse_cv                                                 1.972787                                                 \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.403307                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.393248                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                                   \n",
       "rmse_cv                                                 2.118974                                                   \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                      \n",
       "rmse_cv                                                 2.639041                                      \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.382275                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.300437                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                        \n",
       "rmse_cv                                                 2.199273                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                            0.00000                                        \n",
       "rmse_cv                                                  2.38598                                        \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                            0.00000                                          \n",
       "rmse_cv                                                  2.20776                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                            0.00000                                          \n",
       "rmse_cv                                                  2.26037                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'mae', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.271676                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                          \n",
       "rmse_cv                                                 2.424684                                          \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.578855                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.727583                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'best', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.747981                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000                                            \n",
       "rmse_cv                                                 2.361932                                            \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.670653                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.418606                                              \n",
       "\n",
       "               DecisionTreeRegressor {'criterion': 'poisson', 'splitter': 'random', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                                              \n",
       "rmse_cv                                                 2.750076                                              \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'linear'}  \\\n",
       "rmse_training                             0.800904   \n",
       "rmse_cv                                   1.702421   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'square'}  \\\n",
       "rmse_training                             0.741088   \n",
       "rmse_cv                                   1.762869   \n",
       "\n",
       "               AdaBoostRegressor{'loss': 'exponential'}  BaggingRegressor{}  \\\n",
       "rmse_training                                  0.821008            0.796226   \n",
       "rmse_cv                                        1.739804            1.773814   \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.682685                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.669763                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.671785                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.000000                 \n",
       "rmse_cv                                                 1.687687                 \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000               \n",
       "rmse_cv                                                 1.711171               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_training                                           0.000000               \n",
       "rmse_cv                                                 1.774179               \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_training                                           0.017966            \n",
       "rmse_cv                                                 1.638060            \n",
       "\n",
       "               ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_training                                           0.000000            \n",
       "rmse_cv                                                 1.678239            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_training                                           0.144608                                            \n",
       "rmse_cv                                                 1.792816                                            \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.134223                                              \n",
       "rmse_cv                                                 1.817878                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.171387                                              \n",
       "rmse_cv                                                 1.687886                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.180109                                              \n",
       "rmse_cv                                                 1.748724                                              \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_training                                           0.820328                                             \n",
       "rmse_cv                                                 1.669946                                             \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.777557                                               \n",
       "rmse_cv                                                 1.670978                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.759549                                               \n",
       "rmse_cv                                                 1.687426                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.884338                                               \n",
       "rmse_cv                                                 1.734935                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_training                                           0.336477                                               \n",
       "rmse_cv                                                 1.757310                                               \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.338897                                                 \n",
       "rmse_cv                                                 1.747601                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.362962                                                 \n",
       "rmse_cv                                                 1.729637                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.363317                                                 \n",
       "rmse_cv                                                 1.699685                                                 \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_training                                           2.906163                                                  \n",
       "rmse_cv                                                 2.929725                                                  \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           2.906163                                                    \n",
       "rmse_cv                                                 2.931719                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           1.839171                                                    \n",
       "rmse_cv                                                 2.165518                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           1.763750                                                    \n",
       "rmse_cv                                                 2.105323                                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}  \\\n",
       "rmse_training                                           0.136624                                   \n",
       "rmse_cv                                                 1.758464                                   \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.136624                                     \n",
       "rmse_cv                                                 1.772547                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.136538                                     \n",
       "rmse_cv                                                 1.772940                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.196127                                     \n",
       "rmse_cv                                                 1.789259                                     \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': None}  \\\n",
       "rmse_training                                           0.815084                                    \n",
       "rmse_cv                                                 1.701586                                    \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.767027                                      \n",
       "rmse_cv                                                 1.724474                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.777966                                      \n",
       "rmse_cv                                                 1.733565                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'lad', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.821566                                      \n",
       "rmse_cv                                                 1.688764                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}  \\\n",
       "rmse_training                                           0.338897                                      \n",
       "rmse_cv                                                 1.745741                                      \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           0.336477                                        \n",
       "rmse_cv                                                 1.761079                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.374930                                        \n",
       "rmse_cv                                                 1.760658                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.388329                                        \n",
       "rmse_cv                                                 1.749004                                        \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': None}  \\\n",
       "rmse_training                                           2.906163                                         \n",
       "rmse_cv                                                 2.907193                                         \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'auto'}  \\\n",
       "rmse_training                                           2.906163                                           \n",
       "rmse_cv                                                 2.912386                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           1.845535                                           \n",
       "rmse_cv                                                 2.325858                                           \n",
       "\n",
       "               GradientBoostingRegressor{'criterion': 'mse', 'loss': 'quantile', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           1.849931                                           \n",
       "rmse_cv                                                 2.105851                                           \n",
       "\n",
       "               IsolationForest{}  \\\n",
       "rmse_training           3.462362   \n",
       "rmse_cv                 3.682053   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.615450                   \n",
       "rmse_cv                                                 1.716237                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.617170                   \n",
       "rmse_cv                                                 1.730185                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': None}  \\\n",
       "rmse_training                                           0.643708                 \n",
       "rmse_cv                                                 1.722134                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mse', 'max_features': 1}  \\\n",
       "rmse_training                                           0.606385              \n",
       "rmse_cv                                                 1.702816              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.635773                   \n",
       "rmse_cv                                                 1.708977                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.666565                   \n",
       "rmse_cv                                                 1.735513                   \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': None}  \\\n",
       "rmse_training                                           0.662488                 \n",
       "rmse_cv                                                 1.749481                 \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'mae', 'max_features': 1}  \\\n",
       "rmse_training                                           0.758665              \n",
       "rmse_cv                                                 1.731926              \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'sqrt'}  \\\n",
       "rmse_training                                           0.771422                       \n",
       "rmse_cv                                                 1.988778                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 'log2'}  \\\n",
       "rmse_training                                           0.733582                       \n",
       "rmse_cv                                                 1.986559                       \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': None}  \\\n",
       "rmse_training                                           0.784405                     \n",
       "rmse_cv                                                 2.146736                     \n",
       "\n",
       "               RandomForestRegressor{'criterion': 'poisson', 'max_features': 1}  \\\n",
       "rmse_training                                           0.658957                  \n",
       "rmse_cv                                                 1.847229                  \n",
       "\n",
       "               StackingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \\\n",
       "rmse_training                                           1.887090                                                                                                                                                \n",
       "rmse_cv                                                 1.838392                                                                                                                                                \n",
       "\n",
       "               VotingRegressor{'estimators': [('ridge', RidgeCV(alphas=array([ 0.1,  1. , 10. ]))), ('lasso', LassoCV(random_state=42)), ('knr', KNeighborsRegressor(metric='euclidean', n_neighbors=20))]}  \\\n",
       "rmse_training                                           1.587453                                                                                                                                              \n",
       "rmse_cv                                                 1.808560                                                                                                                                              \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.066022                                         \n",
       "rmse_cv                                                 2.541616                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.707228                                       \n",
       "rmse_cv                                                 1.954613                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.415089                                        \n",
       "rmse_cv                                                 1.918820                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.072823                                           \n",
       "rmse_cv                                                 2.646424                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           3.213425                                         \n",
       "rmse_cv                                                 3.319871                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.400224                                          \n",
       "rmse_cv                                                 1.958899                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           1.060216                                         \n",
       "rmse_cv                                                 2.618470                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.581346                                       \n",
       "rmse_cv                                                 1.921839                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'identity', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.414240                                        \n",
       "rmse_cv                                                 1.948187                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.002077                                         \n",
       "rmse_cv                                                 2.398623                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.000409                                       \n",
       "rmse_cv                                                 1.993739                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.520794                                        \n",
       "rmse_cv                                                 1.935536                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001808                                           \n",
       "rmse_cv                                                 2.390509                                           \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.317426                                         \n",
       "rmse_cv                                                 2.053392                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.486634                                          \n",
       "rmse_cv                                                 1.928757                                          \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001674                                         \n",
       "rmse_cv                                                 2.504979                                         \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.779521                                       \n",
       "rmse_cv                                                 1.823137                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'logistic', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           1.529210                                        \n",
       "rmse_cv                                                 1.930169                                        \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000582                                     \n",
       "rmse_cv                                                 2.401614                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.190643                                   \n",
       "rmse_cv                                                 2.075526                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.912254                                    \n",
       "rmse_cv                                                 2.214715                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000510                                       \n",
       "rmse_cv                                                 2.391421                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           2.649068                                     \n",
       "rmse_cv                                                 2.622750                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.955634                                      \n",
       "rmse_cv                                                 2.138458                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000994                                     \n",
       "rmse_cv                                                 2.604508                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.209457                                   \n",
       "rmse_cv                                                 2.055719                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.830502                                    \n",
       "rmse_cv                                                 2.151523                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.000690                                     \n",
       "rmse_cv                                                 2.440299                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.269244                                   \n",
       "rmse_cv                                                 1.891807                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.717584                                    \n",
       "rmse_cv                                                 1.911085                                    \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001057                                       \n",
       "rmse_cv                                                 2.164162                                       \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           3.602525                                     \n",
       "rmse_cv                                                 3.791083                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'invscaling', 'solver': 'adam'}  \\\n",
       "rmse_training                                           0.548023                                      \n",
       "rmse_cv                                                 1.891257                                      \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'lbfgs'}  \\\n",
       "rmse_training                                           0.001004                                     \n",
       "rmse_cv                                                 2.380486                                     \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'}  \\\n",
       "rmse_training                                           1.219141                                   \n",
       "rmse_cv                                                 1.830540                                   \n",
       "\n",
       "               MLPRegressor {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'adam'}  \n",
       "rmse_training                                           0.695148                                   \n",
       "rmse_cv                                                 1.946403                                   "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "result = pd.concat([result_lm, result_kr, result_svm, result_gpr, result_cd, result_tree, result_ens, result_nn] , axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f744aa5-8620-43ed-a77a-198c926c2fa1",
   "metadata": {},
   "source": [
    "Somehow we have to decide to continue working with a few models. I have decided to choose the best models by taking the average of the DataFrame's rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "3a949693-dd20-4180-bd94-04e6188dce06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': 1}                                           0.828013\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'sqrt'}                                      0.834882\n",
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'log2'}                                      0.835892\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': 1}                                           0.839119\n",
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': 'sqrt'}                                      0.841343\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': 'log2'}                                      0.843843\n",
       "GaussianProcessRegressor RationalQuadratic(alpha=1, length_scale=1)                                  0.853272\n",
       "ExtraTreesRegressor{'criterion': 'mse', 'max_features': None}                                        0.855586\n",
       "ExtraTreesRegressor{'criterion': 'mae', 'max_features': None}                                        0.887090\n",
       "GaussianProcessRegressor Matern(length_scale=1, nu=1.5)                                              0.889111\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'sqrt'}         0.929637\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': None}                    0.947544\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'auto'}                  0.954586\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'sqrt'}                  0.954739\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'log2'}         0.964416\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': None}           0.968712\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'ls', 'max_features': 'auto'}         0.976051\n",
       "DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': None}      0.986393\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'ls', 'max_features': 'log2'}                  0.992693\n",
       "GaussianProcessRegressor RBF(length_scale=1)                                                         1.022488\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'log2'}      1.031501\n",
       "DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'best', 'max_features': 'sqrt'}      1.036796\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': None}                 1.042319\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'auto'}      1.043249\n",
       "DecisionTreeRegressor {'criterion': 'mse', 'splitter': 'random', 'max_features': 'log2'}             1.046201\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': 'sqrt'}      1.046299\n",
       "GradientBoostingRegressor{'criterion': 'friedman_mse', 'loss': 'huber', 'max_features': None}        1.046894\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'auto'}               1.048778\n",
       "DecisionTreeRegressor {'criterion': 'friedman_mse', 'splitter': 'random', 'max_features': 'log2'}    1.059487\n",
       "GradientBoostingRegressor{'criterion': 'mse', 'loss': 'huber', 'max_features': 'sqrt'}               1.067794\n",
       "dtype: float64"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean().sort_values().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b92a058-4fbe-4ad6-bcd8-36ed78a07b25",
   "metadata": {},
   "source": [
    "Assuming our approach is correct, we should definetely choose models such as ExtraTreesRegressor or GradientBoostingRegressor for a fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e3dab-4771-4a50-a4d9-fa1004e02359",
   "metadata": {},
   "source": [
    "<h2> Fine-tuning </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9823f-e591-442e-ae26-ee9dfdf04098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0f53e-e266-4f3b-aa30-9162c008756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1ce21-46a6-4f01-a940-48b6ec53356f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
